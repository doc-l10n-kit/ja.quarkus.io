msgid ""
msgstr ""
"Language: ja_JP\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"X-Generator: doc-l10n-kit"

#. This guide is maintained in the main Quarkus repository
#. and pull requests should be submitted there:
#. https://github.com/quarkusio/quarkus/tree/main/docs/src/main/asciidoc
#. type: Title =
#: upstream/_versions/3.0/guides/kafka.adoc:6
#, no-wrap
msgid "Apache Kafka Reference Guide"
msgstr "Apache Kafka リファレンスガイド"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:15
msgid "This reference guide demonstrates how your Quarkus application can utilize SmallRye Reactive Messaging to interact with Apache Kafka."
msgstr "このガイドでは、Quarkus アプリケーションが SmallRye Reactive Messaging を利用して Apache Kafka とやりとりする仕組みを説明します。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:16
#, no-wrap
msgid "Introduction"
msgstr "はじめに"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:21
msgid "https://kafka.apache.org[Apache Kafka] is a popular open-source distributed event streaming platform.  It is used commonly for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.  Similar to a message queue, or an enterprise messaging platform, it lets you:"
msgstr "link:https://kafka.apache.org[Apache Kafka]は、人気の高いオープンソースの分散型イベントストリーミングプラットフォームです。高性能なデータパイプライン、ストリーミング分析、データ統合、ミッションクリティカルなアプリケーションなどによく利用されています。メッセージキューやエンタープライズメッセージングプラットフォームに似ており、以下のことが可能です。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:23
#, no-wrap
msgid "*publish* (write) and *subscribe* to (read) streams of events, called _records_.\n"
msgstr "_レコード_ と呼ばれるイベントのストリームを *発行* （書き込み）したり、 *購読* （読み込み）したりすることができます。\n"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:24
#, no-wrap
msgid "*store* streams of records durably and reliably inside _topics_.\n"
msgstr "記録のストリームを _トピック_ 内に永続的かつ確実に *保存* します。\n"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:25
#, no-wrap
msgid "*process* streams of records as they occur or retrospectively.\n"
msgstr "記録のストリームを発生時または遡及的に *処理* します。\n"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:27
msgid "And all this functionality is provided in a distributed, highly scalable, elastic, fault-tolerant, and secure manner."
msgstr "そして、これらの機能はすべて、分散型で、拡張性が高く、弾力性があり、耐障害性があり、安全な方法で提供されます。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:28
#, no-wrap
msgid "Quarkus Extension for Apache Kafka"
msgstr "Apache Kafka のための Quarkus エクステンション"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:32
msgid "Quarkus provides support for Apache Kafka through https://smallrye.io/smallrye-reactive-messaging/[SmallRye Reactive Messaging] framework.  Based on Eclipse MicroProfile Reactive Messaging specification 2.0, it proposes a flexible programming model bridging CDI and event-driven."
msgstr "Quarkus は、 https://smallrye.io/smallrye-reactive-messaging/[SmallRye Reactive Messaging] フレームワークを通じて Apache Kafka のサポートを提供します。Eclipse MicroProfile Reactive Messaging 仕様 2.0 に基づいて、CDI とイベント駆動型を橋渡しする柔軟なプログラミングモデルを提案します。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:37
msgid "This guide provides an in-depth look on Apache Kafka and SmallRye Reactive Messaging framework.  For a quick start take a look at xref:kafka-reactive-getting-started.adoc[Getting Started to SmallRye Reactive Messaging with Apache Kafka]."
msgstr "このガイドでは、Apache Kafka および SmallRye Reactive Messaging フレームワークについて詳しく説明します。クイックスタートについては、xref:kafka-reactive-getting-started.adoc[Apache Kafka を使用した SmallRye Reactive Messaging の概要] を参照してください。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:40
msgid "You can add the `smallrye-reactive-messaging-kafka` extensions to your project by running the following command in your project base directory:"
msgstr "プロジェクトのベースディレクトリーで以下のコマンドを実行すると、`smallrye-reactive-messaging-kafka` エクステンションをプロジェクトに追加することができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:45
msgid "This will add the following to your build file:"
msgstr "これにより、 `pom.xml` に以下が追加されます:"

#. type: Block title
#: upstream/_versions/3.0/guides/kafka.adoc:47
#: upstream/_versions/3.0/guides/kafka.adoc:1650
#: upstream/_versions/3.0/guides/kafka.adoc:1899
#: upstream/_versions/3.0/guides/kafka.adoc:1967
#, no-wrap
msgid "pom.xml"
msgstr "pom.xml"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:53
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: Block title
#: upstream/_versions/3.0/guides/kafka.adoc:56
#: upstream/_versions/3.0/guides/kafka.adoc:1659
#: upstream/_versions/3.0/guides/kafka.adoc:1908
#: upstream/_versions/3.0/guides/kafka.adoc:1977
#, no-wrap
msgid "build.gradle"
msgstr "build.gradle"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:59
#, no-wrap
msgid "implementation(\"io.quarkus:quarkus-smallrye-reactive-messaging-kafka\")\n"
msgstr ""

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:64
msgid "The extension includes `kafka-clients` version 3.2.1 as a transitive dependency and is compatible with Kafka brokers version 2.x."
msgstr "このエクステンションには、`kafka-clients` バージョン 3.2.1 が推移的依存関係として含まれており、Kafka ブローカーバージョン 2.x と互換性があります。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:66
#, no-wrap
msgid "Configuring Smallrye Kafka Connector"
msgstr "Smallrye Kafka コネクターの設定"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:69
msgid "Because Smallrye Reactive Messaging framework supports different messaging backends like Apache Kafka, AMQP, Apache Camel, JMS, MQTT, etc., it employs a generic vocabulary:"
msgstr "Smallrye Reactive Messaging フレームワークは、Apache Kafka、AMQP、Apache Camel、JMS、MQTT など、さまざまなメッセージングバックエンドをサポートしているため、汎用的な語彙を使用しています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:71
msgid "Applications send and receive *messages*. A message wraps a _payload_ and can be extended with some _metadata_. With the Kafka connector, a _message_ corresponds to a Kafka _record_."
msgstr "アプリケーションは *メッセージ* を送受信します。メッセージは _payload_ をラップし、いくつかの _metadata_ で拡張できます。Kafka コネクターを使用すると、_メッセージ_ は Kafka _レコード_ に対応します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:72
msgid "Messages transit on *channels*. Application components connect to channels to publish and consume messages. The Kafka connector maps _channels_ to Kafka _topics_."
msgstr "メッセージは *チャネル* を通過します。アプリケーションコンポーネントはチャネルに接続して、メッセージを公開および消費します。Kafka コネクターは _チャネル_ を Kafka _トピック_ にマップします。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:73
msgid "Channels are connected to message backends using *connectors*. Connectors are configured to map incoming messages to a specific channel (consumed by the application) and collect outgoing messages sent to a specific channel. Each connector is dedicated to a specific messaging technology. For example, the connector dealing with Kafka is named `smallrye-kafka`."
msgstr "チャネルは、 *コネクター* を使用してメッセージバックエンドに接続されます。コネクターは、着信メッセージを特定のチャネル (アプリケーションによって消費される) にマッピングし、特定のチャネルに送信された発信メッセージを収集するように設定されています。各コネクターは、特定のメッセージングテクノロジーに特化しています。たとえば、Kafka を処理するコネクターの名前は `smallrye-kafka` となっています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:75
msgid "A minimal configuration for the Kafka connector with an incoming channel looks like the following:"
msgstr "着信チャンネルを持つ Kafka コネクターの最小設定は次のようになります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:80
#, no-wrap
msgid ""
"%prod.kafka.bootstrap.servers=kafka:9092 <1>\n"
"mp.messaging.incoming.prices.connector=smallrye-kafka <2>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:84
msgid "Configure the broker location for the production profile. You can configure it globally or per channel using `mp.messaging.incoming.$channel.bootstrap.servers` property.  In dev mode and when running tests, <<kafka-dev-services>> automatically starts a Kafka broker.  When not provided this property defaults to `localhost:9092`."
msgstr "プロダクションプロファイルのブローカーの場所を設定します。`mp.messaging.incoming.$channel.bootstrap.servers` プロパティーを使用して、グローバルまたはチャネルごとに設定できます。dev モードとテスト実行時には、<<kafka-dev-services>> が自動的に Kafka ブローカーを開始します。指定しない場合、このプロパティーのデフォルトは `localhost:9092` になります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:85
msgid "Configure the connector to manage the prices channel. By default, the topic name is same as the channel name. You can configure the topic attribute to override it."
msgstr "prices チャネルを管理するようにコネクターを設定します。デフォルトでは、トピック名はチャネル名と同じです。トピック属性を設定することで、それを上書きすることができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:87
msgid "The `%prod` prefix indicates that the property is only used when the application runs in prod mode (so not in dev or test). Refer to the xref:config-reference.adoc#profiles[Profile documentation] for further details."
msgstr "`%prod` 接頭辞は、アプリケーションが prod モードで実行されている場合にのみプロパティーが使用されることを示します (つまり、dev または test モードでは使用されません)。詳細は、xref:config-reference.adoc#profiles[プロファイルに関するドキュメント] を参照してください。"

#. type: Block title
#: upstream/_versions/3.0/guides/kafka.adoc:89
#, no-wrap
msgid "Connector auto-attachment"
msgstr "コネクターの自動アタッチ"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:94
msgid "If you have a single connector on your classpath, you can omit the `connector` attribute configuration.  Quarkus automatically associates _orphan_ channels to the (unique) connector found on the classpath.  _Orphans_ channels are outgoing channels without a downstream consumer or incoming channels without an upstream producer."
msgstr "クラスパスに単一のコネクターがある場合は、`connector` 属性の設定を省略できます。Quarkus は、_orphan_ チャネルをクラスパスにある (一意の) コネクターに自動的に関連付けます。_orphan_ チャネルは、ダウンストリームコンシューマーのない outgoing チャネル、またはアップストリームプロデューサーのない incoming チャネルです。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:96
msgid "This auto-attachment can be disabled using:"
msgstr "この自動アタッチは、以下を使用して無効にできます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:100
#, no-wrap
msgid "quarkus.reactive-messaging.auto-connector-attachment=false\n"
msgstr ""

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:103
#, no-wrap
msgid "Receiving messages from Kafka"
msgstr "Kafka からのメッセージの受信"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:106
msgid "Continuing from the previous minimal configuration, your Quarkus application can receive message payload directly:"
msgstr "直前の最小設定によって、Quarkus アプリケーションはすぐにメッセージペイロードを受信できます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:110
#: upstream/_versions/3.0/guides/kafka.adoc:2437
#: upstream/_versions/3.0/guides/kafka.adoc:2518
#, no-wrap
msgid "import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:112
#: upstream/_versions/3.0/guides/kafka.adoc:728
#: upstream/_versions/3.0/guides/kafka.adoc:1205
#: upstream/_versions/3.0/guides/kafka.adoc:1250
#: upstream/_versions/3.0/guides/kafka.adoc:1321
#: upstream/_versions/3.0/guides/kafka.adoc:1344
#: upstream/_versions/3.0/guides/kafka.adoc:1386
#: upstream/_versions/3.0/guides/kafka.adoc:1556
#, no-wrap
msgid "import jakarta.enterprise.context.ApplicationScoped;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:115
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class PriceConsumer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:120
#, no-wrap
msgid ""
"    @Incoming(\"prices\")\n"
"    public void consume(double price) {\n"
"        // process your price.\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:122
#: upstream/_versions/3.0/guides/kafka.adoc:268
#: upstream/_versions/3.0/guides/kafka.adoc:596
#: upstream/_versions/3.0/guides/kafka.adoc:622
#: upstream/_versions/3.0/guides/kafka.adoc:913
#: upstream/_versions/3.0/guides/kafka.adoc:1273
#: upstream/_versions/3.0/guides/kafka.adoc:1334
#: upstream/_versions/3.0/guides/kafka.adoc:1362
#: upstream/_versions/3.0/guides/kafka.adoc:1414
#: upstream/_versions/3.0/guides/kafka.adoc:1517
#: upstream/_versions/3.0/guides/kafka.adoc:1575
#: upstream/_versions/3.0/guides/kafka.adoc:1962
#: upstream/_versions/3.0/guides/kafka.adoc:2042
#: upstream/_versions/3.0/guides/kafka.adoc:2425
#: upstream/_versions/3.0/guides/kafka.adoc:2505
#: upstream/_versions/3.0/guides/kafka.adoc:2538
#, no-wrap
msgid "}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:125
msgid "There are several other ways your application can consume incoming messages:"
msgstr "アプリケーションが受信したメッセージを消費する方法は、他にもいくつかあります。"

#. type: Block title
#: upstream/_versions/3.0/guides/kafka.adoc:126
#, no-wrap
msgid "Message"
msgstr "Message"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:138
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public CompletionStage<Void> consume(Message<Double> msg) {\n"
"    // access record metadata\n"
"    var metadata = msg.getMetadata(IncomingKafkaRecordMetadata.class).orElseThrow();\n"
"    // process the message payload.\n"
"    double price = msg.getPayload();\n"
"    // Acknowledge the incoming message (commit the offset)\n"
"    return msg.ack();\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:142
msgid "The `Message` type lets the consuming method access the incoming message metadata and handle the acknowledgment manually.  We'll explore different acknowledgment strategies in <<commit-strategies>>."
msgstr "`Message` タイプを使用すると、消費するメソッドは着信メッセージのメタデータにアクセスし、確認応答を手動で処理することができます。<<commit-strategies>> で、さまざまな確認応答ストラテジーを検討します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:144
msgid "If you want to access the Kafka record objects directly, use:"
msgstr "Kafka レコードオブジェクトに直接アクセスする場合は、次を使用します。"

#. type: Block title
#: upstream/_versions/3.0/guides/kafka.adoc:145
#, no-wrap
msgid "ConsumerRecord"
msgstr "ConsumerRecord"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:156
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public void consume(ConsumerRecord<String, Double> record) {\n"
"    String key = record.key(); // Can be `null` if the incoming record has no key\n"
"    String value = record.value(); // Can be `null` if the incoming record has no value\n"
"    String topic = record.topic();\n"
"    int partition = record.partition();\n"
"    // ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:160
msgid "`ConsumerRecord` is provided by the underlying Kafka client and can be injected directly to the consumer method.  Another simpler approach consists in using `Record`:"
msgstr "`ConsumerRecord` は、基盤となる Kafka クライアントによって提供され、コンシューマーメソッドに直接注入することができます。`Record` の使用に際して、以下のような別の簡単なアプローチがあります。"

#. type: Block title
#: upstream/_versions/3.0/guides/kafka.adoc:161
#, no-wrap
msgid "Record"
msgstr "Record"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:169
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public void consume(Record<String, Double> record) {\n"
"    String key = record.key(); // Can be `null` if the incoming record has no key\n"
"    String value = record.value(); // Can be `null` if the incoming record has no value\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:172
msgid "`Record` is a simple wrapper around key and payload of the incoming Kafka record."
msgstr "`Record` は、着信 Kafka レコードのキーとペイロードの単純なラッパーです。"

#. type: Block title
#: upstream/_versions/3.0/guides/kafka.adoc:173
#, no-wrap
msgid "@Channel"
msgstr "@Channel"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:176
msgid "Alternatively, your application can inject a `Multi` in your bean and subscribe to its events as the following example:"
msgstr "または、以下の例のように、アプリケーションで Bean に `Multi` を注入し、そのイベントをサブスクライブすることもできます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:181
#, no-wrap
msgid ""
"import io.smallrye.mutiny.Multi;\n"
"import io.smallrye.reactive.messaging.annotations.Channel;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:188
#, no-wrap
msgid ""
"import jakarta.inject.Inject;\n"
"import jakarta.ws.rs.GET;\n"
"import jakarta.ws.rs.Path;\n"
"import jakarta.ws.rs.Produces;\n"
"import jakarta.ws.rs.core.MediaType;\n"
"import org.jboss.resteasy.reactive.RestStreamElementType;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:191
#: upstream/_versions/3.0/guides/kafka.adoc:994
#: upstream/_versions/3.0/guides/kafka.adoc:1039
#: upstream/_versions/3.0/guides/kafka.adoc:1075
#, no-wrap
msgid ""
"@Path(\"/prices\")\n"
"public class PriceResource {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:195
#, no-wrap
msgid ""
"    @Inject\n"
"    @Channel(\"prices\")\n"
"    Multi<Double> prices;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:203
#, no-wrap
msgid ""
"    @GET\n"
"    @Path(\"/prices\")\n"
"    @RestStreamElementType(MediaType.TEXT_PLAIN)\n"
"    public Multi<Double> stream() {\n"
"        return prices;\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:207
msgid "This is a good example of how to integrate a Kafka consumer with another downstream, in this example exposing it as a Server-Sent Events endpoint."
msgstr "これは、Kafka コンシューマーを別のダウンストリームと統合する方法の良い例で、この例では Server-Sent Events エンドポイントとして公開しています。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:213
msgid "When consuming messages with `@Channel`, the application code is responsible for the subscription.  In the example above, the RESTEasy Reactive endpoint handles that for you."
msgstr "`@Channel` でメッセージを消費する場合、アプリケーションコードがサブスクリプションを行います。上記の例では、RESTEasy Reactive エンドポイントが処理します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:216
msgid "Following types can be injected as channels:"
msgstr "チャンネルとして注入できるのは、以下のタイプです。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:220
#, no-wrap
msgid "@Inject @Channel(\"prices\") Multi<Double> streamOfPayloads;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:222
#, no-wrap
msgid "@Inject @Channel(\"prices\") Multi<Message<Double>> streamOfMessages;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:224
#, no-wrap
msgid "@Inject @Channel(\"prices\") Publisher<Double> publisherOfPayloads;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:226
#, no-wrap
msgid "@Inject @Channel(\"prices\") Publisher<Message<Double>> publisherOfMessages;\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:231
msgid "As with the previous `Message` example, if your injected channel receives payloads (`Multi<T>`), it acknowledges the message automatically, and support multiple subscribers.  If you injected channel receives Message (`Multi<Message<T>>`), you will be responsible for the acknowledgment and broadcasting.  We will explore sending broadcast messages in <<broadcasting-messages-on-multiple-consumers>>."
msgstr "前出の `Message` の例と同様に、注入されたチャネルがペイロードを受信した場合 (`Multi<T>`)、メッセージを自動的に確認応答し、複数のサブスクライバーをサポートします。注入したチャネルが Message (`Multi<Message<T>>`) を受信した場合は、確認応答とブロードキャストを行う必要があります。ブロードキャストメッセージの送信については、<<broadcasting-messages-on-multiple-consumers>> で説明します。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:236
msgid "Injecting `@Channel(\"prices\")` or having `@Incoming(\"prices\")` does not automatically configure the application to consume messages from Kafka.  You need to configure an inbound connector with `mp.messaging.incoming.prices\\...` or have an `@Outgoing(\"prices\")` method somewhere in your application (in which case, `prices` will be an in-memory channel)."
msgstr "`@Channel(\"prices\")` を注入したり、`@Incoming(\"prices\")` を持っていたりしても、Kafka からのメッセージを消費するようにアプリケーションが自動的に設定されるわけではありません。`mp.messaging.incoming.prices\\...` を使用してインバウンドコネクターを設定するか、アプリケーションのどこかに `@Outgoing(\"prices\")` メソッドを持っている必要があります (その場合、`prices` はインメモリーチャネルになります)。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:239
#, no-wrap
msgid "Blocking processing"
msgstr "ブロッキング処理"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:245
msgid "Reactive Messaging invokes your method on an I/O thread.  See the xref:quarkus-reactive-architecture.adoc[Quarkus Reactive Architecture documentation] for further details on this topic.  But, you often need to combine Reactive Messaging with blocking processing such as database interactions.  For this, you need to use the `@Blocking` annotation indicating that the processing is _blocking_ and should not be run on the caller thread."
msgstr "リアクティブメッセージングは、I/O スレッドでメソッドを呼び出します。このトピックの詳細については、xxref:quarkus-reactive-architecture.adoc[Quarkus リアクティブアーキテクチャーのドキュメント] を参照してください。ただし、多くの場合、リアクティブメッセージングとデータベースインタラクションなどのブロック処理を組み合わせる必要があります。このためには、処理が _ブロッキング_ であり、呼び出し元のスレッドで実行するべきではないことを示す `@Blocking` アノテーションを使用する必要があります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:247
msgid "For example, The following code illustrates how you can store incoming payloads to a database using Hibernate with Panache:"
msgstr "例えば、以下のコードは、Hibernate with Panacheを 使用してデータベースに受信ペイロードを格納する方法を示しています。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:252
#, no-wrap
msgid ""
"import io.smallrye.reactive.messaging.annotations.Blocking;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:255
#: upstream/_versions/3.0/guides/kafka.adoc:2435
#, no-wrap
msgid ""
"import jakarta.enterprise.context.ApplicationScoped;\n"
"import jakarta.transaction.Transactional;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:258
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class PriceStorage {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:266
#, no-wrap
msgid ""
"    @Incoming(\"prices\")\n"
"    @Transactional\n"
"    public void store(int priceInUsd) {\n"
"        Price price = new Price();\n"
"        price.value = priceInUsd;\n"
"        price.persist();\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:271
msgid "The complete example is available in the `kafka-panache-quickstart` {quickstarts-tree-url}/kafka-panache-quickstart[directory]."
msgstr "完全な例は、`kafka-panache-quickstart` {quickstarts-tree-url}/kafka-panache-quickstart[ディレクトリ] にあります。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:275
msgid "There are 2 `@Blocking` annotations:"
msgstr "`@Blocking` アノテーションは 2 つあります。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:277
msgid "`io.smallrye.reactive.messaging.annotations.Blocking`"
msgstr "`io.smallrye.reactive.messaging.annotations.Blocking`"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:278
msgid "`io.smallrye.common.annotation.Blocking`"
msgstr "`io.smallrye.common.annotation.Blocking`"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:283
msgid "They have the same effect.  Thus, you can use both.  The first one provides more fine-grained tuning such as the worker pool to use and whether it preserves the order.  The second one, used also with other reactive features of Quarkus, uses the default worker pool and preserves the order."
msgstr "効果はどちらも同じです。したがって、両方を使うことができます。最初のものは、使用するワーカープールや順序を保持するかどうかなど、より細かい調整が可能です。2 番目のものは、Quarkus の他のリアクティブ機能でも使用され、デフォルトのワーカープールを使用し、順序を保持します。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:285
msgid "Detailed information on the usage of `@Blocking` annotation can be found in https://smallrye.io/smallrye-reactive-messaging/latest/concepts/blocking/[SmallRye Reactive Messaging – Handling blocking execution]."
msgstr "`@Blocking` アノテーションの使用法の詳細については、 https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/3.1/advanced/blocking.html[SmallRye Reactive Messaging – Handling blocking execution] を参照してください。"

#. type: Block title
#: upstream/_versions/3.0/guides/kafka.adoc:288
#, no-wrap
msgid "@Transactional"
msgstr "@Transactional"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:291
msgid "If your method is annotated with `@Transactional`, it will be considered _blocking_ automatically, even if the method is not annotated with `@Blocking`."
msgstr "メソッドに `@Transactional` アノテーションが付けられている場合、メソッドに `@Blocking` アノテーションが付けられていなくても、自動的に _blocking_ と見なされます。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:293
#, no-wrap
msgid "Acknowledgment Strategies"
msgstr "確認応答ストラテジー"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:301
msgid "All messages received by a consumer must be acknowledged.  In the absence of acknowledgment, the processing is considered in error.  If the consumer method receives a `Record` or a payload, the message will be acked on method return, also known as `Strategy.POST_PROCESSING`.  If the consumer method returns another reactive stream or `CompletionStage`, the message will be acked when the downstream message is acked.  You can override the default behavior to ack the message on arrival (`Strategy.PRE_PROCESSING`), or do not ack the message at all (`Strategy.NONE`) on the consumer method as in the following example:"
msgstr "コンシューマーが受信したすべてのメッセージは確認応答する必要があります。確認応答されない場合、処理はエラーと見なされます。コンシューマーメソッドが `Record` またはペイロードを受信した場合、メッセージはメソッドの戻り時に確認応答されます。これは、`Strategy.POST_PROCESSING` としても知られています。コンシューマーメソッドが別のリアクティブストリームまたは `CompletionStage` を返す場合、ダウンストリームメッセージが確認応答されたときにメッセージが確認応答されます。以下の例のように、デフォルトの動作をオーバーライドして、到着時にメッセージを確認応答する (`Strategy.PRE_PROCESSING`) か、コンシューマーメソッドでメッセージをまったく確認応答しない (`Strategy.NONE`) ことができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:309
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"@Acknowledgment(Acknowledgment.Strategy.PRE_PROCESSING)\n"
"public void process(double price) {\n"
"    // process price\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:313
msgid "If the consumer method receives a `Message`, the acknowledgment strategy is `Strategy.MANUAL` and the consumer method is in charge of ack/nack the message."
msgstr "コンシューマーメソッドが `Message` を受信した場合、確認応答ストラテジーは `Strategy.MANUAL` で、コンシューマーメソッドがメッセージの ack/nack を行います。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:321
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public CompletionStage<Void> process(Message<Double> msg) {\n"
"    // process price\n"
"    return msg.ack();\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:324
msgid "As mentioned above, the method can also override the acknowledgment strategy to `PRE_PROCESSING` or `NONE`."
msgstr "前述のように、このメソッドは確認応答ストラテジーを `PRE_PROCESSING` または `NONE` にオーバーライドすることも可能です。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:326
#, no-wrap
msgid "Commit Strategies"
msgstr "コミットストラテジー"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:332
msgid "When a message produced from a Kafka record is acknowledged, the connector invokes a commit strategy.  These strategies decide when the consumer offset for a specific topic/partition is committed.  Committing an offset indicates that all previous records have been processed.  It is also the position where the application would restart the processing after a crash recovery or a restart."
msgstr "Kafka レコードから生成されたメッセージが確認応答されると、コネクターはコミットストラテジーを呼び出します。これらのストラテジーは、特定のトピック/パーティションのコンシューマーオフセットがいつコミットされるかを決定します。オフセットをコミットすると、以前のすべてのレコードが処理されたことを示します。また、これは、クラッシュリカバリーまたは再起動後にアプリケーションが処理を再開する位置でもあります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:335
msgid "Committing every offset has performance penalties as Kafka offset management can be slow.  However, not committing the offset often enough may lead to message duplication if the application crashes between two commits."
msgstr "オフセットを毎回コミットすることは、Kafkaのオフセット管理のオーバーヘッドを増やすため、パフォーマンスペナルティにつながります。ただし、オフセットを十分な頻度でコミットしないと、2 つのコミットの間にアプリケーションがクラッシュした場合に、メッセージが重複する可能性があります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:337
msgid "The Kafka connector supports three strategies:"
msgstr "Kafka コネクターは、以下の 3 つのストラテジーをサポートします。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:358
msgid "`latest` commits the record offset received by the Kafka consumer as soon as the associated message is acknowledged (if the offset is higher than the previously committed offset).  This strategy provides at-least-once delivery if the channel processes the message without performing any asynchronous processing.  This strategy should not be used in high load environment, as offset commit is expensive. However, it reduces the risk of duplicates."
msgstr "`latest` は、関連するメッセージが確認応答されるとすぐに、Kafka コンシューマーが受信したレコードオフセットをコミットします (オフセットが以前にコミットされたオフセットよりも大きい場合)。このストラテジーは、チャネルが非同期処理を実行せずにメッセージを処理する場合、少なくとも 1 回の配信を提供します。オフセットコミットはコストがかかるため、このストラテジーは高負荷環境では使用しないでください。ただし、これにより、重複のリスクは軽減されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:364
msgid "`ignore` performs no commit. This strategy is the default strategy when the consumer is explicitly configured with `enable.auto.commit` to true.  It delegates the offset commit to the underlying Kafka client.  When `enable.auto.commit` is `true` this strategy **DOES NOT** guarantee at-least-once delivery.  SmallRye Reactive Messaging processes records asynchronously, so offsets may be committed for records that have been polled but not yet processed.  In case of a failure, only records that were not committed yet will be re-processed."
msgstr "`ignore` はコミットを実行しません。このストラテジーは、コンシューマーが `enable.auto.commit` を true に明示的に設定されている場合のデフォルトのストラテジーです。これは、オフセットコミットを基盤となる Kafka クライアントに委任します。`enable.auto.commit` が `true` の場合、このストラテジーは少なくとも 1 回の配信を**保証しません**。SmallRye Reactive Messaging はレコードを非同期で処理するため、ポーリングされたがまだ処理されていないレコードに対してオフセットがコミットされる場合があります。エラーが発生した場合、まだコミットされていないレコードのみが再処理されます。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:369
msgid "The Kafka connector disables the Kafka auto commit when it is not explicitly enabled. This behavior differs from the traditional Kafka consumer.  If high throughput is important for you, and you are not limited by the downstream, we recommend to either:"
msgstr "Kafka コネクターは、明示的に有効にされていない場合、Kafka 自動コミットを無効にします。この動作は、従来の Kafka コンシューマーとは異なります。高スループットが重要であり、ダウンストリームに制限されていない場合は、次のいずれかをお勧めします。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:371
msgid "use the `throttled` policy,"
msgstr "`throttled` ポリシーの使用"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:372
msgid "or set `enable.auto.commit` to true and annotate the consuming method with `@Acknowledgment(Acknowledgment.Strategy.NONE)`."
msgstr "または、`enable.auto.commit` を true に設定し、消費メソッドに `@Acknowledgment(Acknowledgment.Strategy.NONE)` のアノテーションを付けます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:376
msgid "Smallrye Reactive Messaging enables implementing custom commit strategies.  See https://smallrye.io/smallrye-reactive-messaging/latest/kafka/receiving-kafka-records/#acknowledgement[SmallRye Reactive Messaging documentation] for more information."
msgstr "Smallrye Reactive Messaging を使用すると、カスタム コミット戦略を実装できます。 詳細については、https://smallrye.io/smallrye-reactive-messaging/latest/kafka/recoming-kafka-records/#acknowledgement[SmallRye Reactive Messaging のドキュメント] を参照してください。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:378
#, no-wrap
msgid "Error Handling Strategies"
msgstr "エラー処理ストラテジー"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:381
msgid "If a message produced from a Kafka record is nacked, a failure strategy is applied. The Kafka connector supports three strategies:"
msgstr "Kafka レコードから生成されたメッセージが nack された場合、エラーストラテジーが適用されます。Kafka コネクターは、次の 3 つのストラテジーをサポートしています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:383
msgid "`fail`: fail the application, no more records will be processed (default strategy). The offset of the record that has not been processed correctly is not committed."
msgstr "`fail`: アプリケーションを失敗させ、それ以上のレコードは処理されません (デフォルトストラテジー)。正しく処理されなかったレコードのオフセットはコミットされません。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:384
msgid "`ignore`: the failure is logged, but the processing continue. The offset of the record that has not been processed correctly is committed."
msgstr "`ignore`: エラーはログに記録されますが、処理は続行されます。正しく処理されなかったレコードのオフセットがコミットされます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:385
msgid "`dead-letter-queue`: the offset of the record that has not been processed correctly is committed, but the record is written to a Kafka dead letter topic."
msgstr "`dead-letter-queue`: 正しく処理されなかったレコードのオフセットはコミットされますが、レコードは Kafka デッドレタートピックに書き込まれます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:387
msgid "The strategy is selected using the `failure-strategy` attribute."
msgstr "ストラテジーは `failure-strategy` 属性を使用して選択します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:389
msgid "In the case of `dead-letter-queue`, you can configure the following attributes:"
msgstr "`dead-letter-queue` の場合、以下の属性を設定することができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:391
msgid "`dead-letter-queue.topic`: the topic to use to write the records not processed correctly, default is `dead-letter-topic-$channel`, with `$channel` being the name of the channel."
msgstr "`dead-letter-queue.topic`: 正しく処理されなかったレコードを書き込むために使用するトピック。デフォルトは `dead-letter-topic-$channel` で、`$channel` はチャンネルの名前になります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:392
msgid "`dead-letter-queue.key.serializer`: the serializer used to write the record key on the dead letter queue. By default, it deduces the serializer from the key deserializer."
msgstr "`dead-letter-queue.key.serializer`: デッドレターキューにレコードキーを書き込むために使用されるシリアライザー。デフォルトでは、キーデシリアライザーからシリアライザーを推測します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:393
msgid "`dead-letter-queue.value.serializer`: the serializer used to write the record value on the dead letter queue. By default, it deduces the serializer from the value deserializer."
msgstr "`dead-letter-queue.value.serializer`: デッドレターキューにレコード値を書き込むために使用されるシリアライザー。デフォルトでは、値デシリアライザーからシリアライザーを推測します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:395
msgid "The record written on the dead letter queue contains a set of additional headers about the original record:"
msgstr "デッドレターキューに書き込まれたレコードには、元のレコードに関する一連の追加ヘッダーが含まれています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:397
#, no-wrap
msgid "*dead-letter-reason*: the reason of the failure\n"
msgstr "*dead-letter-reason*: 失敗の理由\n"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:398
#, no-wrap
msgid "*dead-letter-cause*: the cause of the failure if any\n"
msgstr "*dead-letter-cause*: エラーの原因 (エラーがある場合)\n"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:399
#, no-wrap
msgid "*dead-letter-topic*: the original topic of the record\n"
msgstr "*dead-letter-topic*: 記録の元のトピック\n"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:400
#, no-wrap
msgid "*dead-letter-partition*: the original partition of the record (integer mapped to String)\n"
msgstr "*dead-letter-partition*: レコードの元のパーティション (String にマップされた integer)\n"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:401
#, no-wrap
msgid "*dead-letter-offset*: the original offset of the record (long mapped to String)\n"
msgstr "*dead-letter-offset*: レコードの元のオフセット (String にマップされた long)\n"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:404
msgid "Smallrye Reactive Messaging enables implementing custom failure strategies.  See https://smallrye.io/smallrye-reactive-messaging/latest/kafka/receiving-kafka-records/#acknowledgement[SmallRye Reactive Messaging documentation] for more information."
msgstr "Smallrye Reactive Messaging を使用すると、カスタム 失敗戦略を実装できます。 詳細については、https://smallrye.io/smallrye-reactive-messaging/latest/kafka/recoming-kafka-records/#acknowledgement[SmallRye Reactive Messaging のドキュメント] を参照してください。"

#. type: Title ====
#: upstream/_versions/3.0/guides/kafka.adoc:405
#, no-wrap
msgid "Retrying processing"
msgstr "処理のリトライ"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:408
msgid "You can combine Reactive Messaging with https://github.com/smallrye/smallrye-fault-tolerance[SmallRye Fault Tolerance], and retry processing if it failed:"
msgstr "Reactive Messaging を https://github.com/smallrye/smallrye-fault-tolerance[SmallRye Fault Tolerance] と組み合わせて、失敗した場合は処理をリトライできます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:416
#, no-wrap
msgid ""
"@Incoming(\"kafka\")\n"
"@Retry(delay = 10, maxRetries = 5)\n"
"public void consume(String v) {\n"
"   // ... retry if this method throws an exception\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:419
msgid "You can configure the delay, the number of retries, the jitter, etc."
msgstr "遅延、再試行回数、ジッターなどを設定できます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:421
msgid "If your method returns a `Uni` or `CompletionStage`, you need to add the `@NonBlocking` annotation:"
msgstr "メソッドが `Uni` または `CompletionStage` を返す場合は、`@NonBlocking` アノテーションを追加する必要があります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:430
#, no-wrap
msgid ""
"@Incoming(\"kafka\")\n"
"@Retry(delay = 10, maxRetries = 5)\n"
"@NonBlocking\n"
"public Uni<String> consume(String v) {\n"
"   // ... retry if this method throws an exception or the returned Uni produce a failure\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:435
msgid "The `@NonBlocking` annotation is only required with SmallRye Fault Tolerance 5.1.0 and earlier.  Starting with SmallRye Fault Tolerance 5.2.0 (available since Quarkus 2.1.0.Final), it is not necessary.  See https://smallrye.io/docs/smallrye-fault-tolerance/5.2.0/usage/extra.html#_non_compatible_mode[SmallRye Fault Tolerance documentation] for more information."
msgstr "`@NonBlocking`アノテーションは、 SmallRye Fault Tolerance 5.1.0 以前でのみ必要です。SmallRye Fault Tolerance 5.2.0 以降 (Quarkus 2.1.0.Final 以降で使用可能) では必要ありません。詳細は、 https://smallrye.io/docs/smallrye-fault-tolerance/5.2.0/usage/extra.html#_non_compatible_mode[SmallRye Fault Tolerance documentation] を参照してください。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:439
msgid "The incoming messages are acknowledged only once the processing completes successfully.  So, it commits the offset after the successful processing.  If the processing still fails, even after all retries, the message is _nacked_ and the failure strategy is applied."
msgstr "着信メッセージは、処理が正常に完了したときにのみ確認応答されます。したがって、着信メッセージは、処理が成功した後にオフセットをコミットします。それでも処理が失敗する場合は、すべての再試行後でも、メッセージは _nack_ され、エラーストラテジーが適用されます。"

#. type: Title ====
#: upstream/_versions/3.0/guides/kafka.adoc:440
#, no-wrap
msgid "Handling Deserialization Failures"
msgstr "デシリアライゼーション失敗時の処理"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:444
msgid "When a deserialization failure occurs, you can intercept it and provide a failure strategy.  To achieve this, you need to create a bean implementing `DeserializationFailureHandler<T>` interface:"
msgstr "デシリアライゼーションがエラーが発生したとき、それをインターセプトしてエラーストラテジーを提供することができます。これを実現するには、`DeserializationFailureHandler<T>` インターフェイスを実装した Bean を作成する必要があります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:451
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"@Identifier(\"failure-retry\") // Set the name of the failure handler\n"
"public class MyDeserializationFailureHandler\n"
"    implements DeserializationFailureHandler<JsonObject> { // Specify the expected type\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:460
#, no-wrap
msgid ""
"    @Override\n"
"    public JsonObject decorateDeserialization(Uni<JsonObject> deserialization, String topic, boolean isKey,\n"
"            String deserializer, byte[] data, Headers headers) {\n"
"        return deserialization\n"
"                    .onFailure().retry().atMost(3)\n"
"                    .await().atMost(Duration.ofMillis(200));\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:463
msgid "To use this failure handler, the bean must be exposed with the `@Identifier` qualifier and the connector configuration must specify the attribute `mp.messaging.incoming.$channel.[key|value]-deserialization-failure-handler` (for key or value deserializers)."
msgstr "このエラーハンドラーを使用するには、Bean を `@Identifier` 修飾子で公開し、コネクター設定で属性 `mp.messaging.incoming.$channel.[key|value]-deserialization-failure-handler` を指定する必要があります (キーまたは値のデシリアライザー用)。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:466
msgid "The handler is called with details of the deserialization, including the action represented as `Uni<T>`.  On the deserialization `Uni` failure strategies like retry, providing a fallback value or applying timeout can be implemented."
msgstr "ハンドラーは、`Uni<T>` として表されるアクションを含む、デシリアライゼーションの詳細とともに呼び出されます。再試行などのデシリアライゼーション `Uni` エラーストラテジーでは、フォールバック値の提供やタイムアウトの適用を実装することができます。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:467
#, no-wrap
msgid "Consumer Groups"
msgstr "コンシューマーグループ"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:474
msgid "In Kafka, a consumer group is a set of consumers which cooperate to consume data from a topic.  A topic is divided into a set of partitions.  The partitions of a topic are assigned among the consumers in the group, effectively allowing to scale consumption throughput.  Note that each partition is assigned to a single consumer from a group.  However, a consumer can be assigned multiple partitions if the number of partitions is greater than the number of consumer in the group."
msgstr "Kafka では、コンシューマーグループは、トピックからのデータを消費するために協力する一連のコンシューマーです。トピックは一連のパーティションに分割されます。トピックのパーティションは、グループ内のコンシューマー間で割り当てられ、消費スループットを効果的にスケーリングできます。各パーティションは、グループからの単一のコンシューマーに割り当てられることに注意してください。ただし、パーティションの数がグループ内のコンシューマーの数よりも多い場合は、コンシューマーに複数のパーティションを割り当てることができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:476
msgid "Let's explore briefly different producer/consumer patterns and how to implement them using Quarkus:"
msgstr "ここでは、さまざまなプロデューサー/コンシューマーパターンと、Quarkus を使用したその実装方法について簡単に説明します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:478
#, no-wrap
msgid "*Single consumer thread inside a consumer group*\n"
msgstr "*コンシューマーグループ内の単一のコンシューマースレッド*\n"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:482
msgid "This is the default behavior of an application subscribing to a Kafka topic: Each Kafka connector will create a single consumer thread and place it inside a single consumer group.  Consumer group id defaults to the application name as set by the `quarkus.application.name` configuration property.  It can also be set using the `kafka.group.id` property."
msgstr "これは、Kafka トピックをサブスクライブするアプリケーションのデフォルトの動作です。各 Kafka コネクターは、単一のコンシューマースレッドを作成し、それを単一のコンシューマーグループ内に配置します。コンシューマグループ ID のデフォルトは、`quarkus.application.name` 設定プロパティーで設定されたアプリケーション名です。これは、`kafka.group.id` プロパティーを使用して設定することもできます。"

#. type: Named 'alt' AttributeList argument for macro 'image'
#: upstream/_versions/3.0/guides/kafka.adoc:483
#: upstream/_versions/3.0/guides/kafka.adoc:491
#: upstream/_versions/3.0/guides/kafka.adoc:498
#: upstream/_versions/3.0/guides/kafka.adoc:506
#, no-wrap
msgid "Architecture,"
msgstr "アーキテクチャ"

#. type: Target for macro image
#: upstream/_versions/3.0/guides/kafka.adoc:483
#, no-wrap
msgid "kafka-one-app-one-consumer.png"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:486
#, no-wrap
msgid "*Multiple consumer threads inside a consumer group*\n"
msgstr "*コンシューマーグループ内の複数のコンシューマースレッド*\n"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:490
msgid "For a given application instance, the number of consumers inside the consumer group can be configured using `mp.messaging.incoming.$channel.partitions` property.  The partitions of the subscribed topic will be divided among the consumer threads.  Note that if the `partitions` value exceed the number of partitions of the topic, some consumer threads won't be assigned any partitions."
msgstr "特定のアプリケーションインスタンスの場合、コンシューマーグループ内のコンシューマーの数は、`mp.messaging.incoming.$channel.partitions` プロパティーを使用して設定できます。サブスクライブされたトピックのパーティションは、コンシューマースレッド間で分割されます。`partitions` の値がトピックのパーティションの数を超える場合、一部のコンシューマスレッドにはパーティションが割り当てられないことに注意してください。"

#. type: Target for macro image
#: upstream/_versions/3.0/guides/kafka.adoc:491
#, no-wrap
msgid "kafka-one-app-two-consumers.png"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:494
#, no-wrap
msgid "*Multiple consumer applications inside a consumer group*\n"
msgstr "*コンシューマーグループ内の複数のコンシューマーアプリケーション*\n"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:497
msgid "Similar to the previous example, multiple instances of an application can subscribe to a single consumer group, configured via `mp.messaging.incoming.$channel.group.id` property, or left default to the application name.  This in turn will divide partitions of the topic among application instances."
msgstr "前の例と同様に、アプリケーションの複数のインスタンスは、`mp.messaging.incoming.$channel.group.id` プロパティーを介して設定された単一のコンシューマーグループにサブスクライブすることも、アプリケーション名をデフォルトのままにすることもできます。これにより、トピックのパーティションがアプリケーションインスタンス間で分割されます。"

#. type: Target for macro image
#: upstream/_versions/3.0/guides/kafka.adoc:498
#, no-wrap
msgid "kafka-two-app-one-consumer-group.png"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:501
#, no-wrap
msgid "*Pub/Sub: Multiple consumer groups subscribed to a topic*\n"
msgstr "*Pub/Sub: トピックにサブスクライブしている複数のコンシューマーグループ*\n"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:505
msgid "Lastly different applications can subscribe independently to same topics using different *consumer group ids*.  For example, messages published to a topic called _orders_ can be consumed independently on two consumer applications, one with `mp.messaging.incoming.orders.group.id=invoicing` and second with `mp.messaging.incoming.orders.group.id=shipping`.  Different consumer groups can thus scale independently according to the message consumption requirements."
msgstr "最後に、異なるアプリケーションは、異なる *コンシューマーグループ ID* を使用して同じトピックに個別にサブスクライブすることができます。たとえば、_orders_ というトピックに公開されたメッセージは、2 つのコンシューマーアプリケーションで個別に消費することができます。1 つは `mp.messaging.incoming.orders.group.id=invoicing` で、もう 1 つは `mp.messaging.incoming.orders.group.id=shipping` で消費されます。したがって、さまざまなコンシューマーグループが、メッセージの消費要件に応じて独立してスケーリングすることができます。"

#. type: Target for macro image
#: upstream/_versions/3.0/guides/kafka.adoc:506
#, no-wrap
msgid "kafka-two-app-two-consumer-groups.png"
msgstr ""

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:514
msgid "A common business requirement is to consume and process Kafka records in order.  The Kafka broker preserves order of records inside a partition and not inside a topic.  Therefore, it is important to think about how records are partitioned inside a topic.  The default partitioner uses record key hash to compute the partition for a record, or when the key is not defined, chooses a partition randomly per batch or records."
msgstr "一般的なビジネス要件は、Kafka レコードを順番に消費して処理することです。Kafka ブローカーは、トピック内ではなく、パーティション内のレコードの順序を保持します。したがって、レコードがトピック内でどのようにパーティショニングされるかを考えることが重要となります。デフォルトのパーティショナーは、レコードキーハッシュを使用してレコードのパーティションを計算するか、キーが定義されていない場合は、バッチまたはレコードごとにランダムにパーティションを選択します。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:517
msgid "During normal operation, a Kafka consumer preserves the order of records inside each partition assigned to it.  Smallrye Reactive Messaging keeps this order for processing, unless `@Blocking(ordered = false)` is used (see <<blocking-processing>>)."
msgstr "通常の操作中、Kafka コンシューマーは、割り当てられた各パーティション内のレコードの順序を保持します。Smallrye Reactive Messaging は、`@Blocking(ordered = false)` が使用されていない限り、この順序を処理のために保持します (<<blocking-processing>>を参照)。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:519
msgid "Note that due to consumer rebalances, Kafka consumers only guarantee at-least-once processing of single records, meaning that uncommitted records _can_ be processed again by consumers."
msgstr "コンシューマーのリバランスにより、Kafka コンシューマーは、単一レコードの少なくとも 1 回の処理のみを保証します。つまり、コミットされていないレコードは、コンシューマーによって再度処理 _できます_ 。"

#. type: Title ====
#: upstream/_versions/3.0/guides/kafka.adoc:521
#, no-wrap
msgid "Consumer Rebalance Listener"
msgstr "コンシューマーリバランスリスナー"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:528
msgid "Inside a consumer group, as new group members arrive and old members leave, the partitions are re-assigned so that each member receives a proportional share of the partitions.  This is known as rebalancing the group.  To handle offset commit and assigned partitions yourself, you can provide a consumer rebalance listener.  To achieve this, implement the `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` interface and expose it as a CDI bean with the `@Idenfier` qualifier.  A common use case is to store offset in a separate data store to implement exactly-once semantic, or starting the processing at a specific offset."
msgstr "コンシューマーグループ内では、新しいグループメンバーが到着し、古いメンバーが離れると、パーティションが再割り当てされ、各メンバーにパーティションが比例配分されます。これは、グループのリバランスとして知られています。オフセットコミットとパーティション割り当てを自分で処理するために、コンシューマーリバランスリスナーを提供することができます。これを実現するには、`io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` インターフェイスを実装し、`@Idenfier` 修飾子を使用して CDI Bean として公開します。一般的な使用例として、オフセットを別のデータストアに格納して exactly-once セマンティックを実装したり、特定のオフセットで処理を開始したりすることが挙げられます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:532
msgid "The listener is invoked every time the consumer topic/partition assignment changes.  For example, when the application starts, it invokes the `partitionsAssigned` callback with the initial set of topics/partitions associated with the consumer.  If, later, this set changes, it calls the `partitionsRevoked` and `partitionsAssigned` callbacks again, so you can implement custom logic."
msgstr "リスナーは、コンシューマートピック/パーティションの割り当てが変更されるたびに呼び出されます。たとえば、アプリケーションが起動すると、コンシューマーに関連付けられたトピック/パーティションの初期セットを使用して `partitionsAssigned` コールバックが呼び出されます。後でこのセットが変更された場合、`partitionsRevoked` および `partitionsAssigned` コールバックが再度呼び出されるため、カスタムロジックを実装することができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:535
msgid "Note that the rebalance listener methods are called from the Kafka polling thread and **will** block the caller thread until completion.  That’s because the rebalance protocol has synchronization barriers, and using asynchronous code in a rebalance listener may be executed after the synchronization barrier."
msgstr "リバランスリスナーメソッドは Kafka ポーリングスレッドから呼び出され、完了するまで呼び出し元のスレッドを**ブロック**することに注意してください。これは、リバランスプロトコルに同期バリアがあり、リバランスリスナーで非同期コードを使用すると、同期バリアの後に実行される可能性があるためです。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:537
msgid "When topics/partitions are assigned or revoked from a consumer, it pauses the message delivery and resumes once the rebalance completes."
msgstr "トピック/パーティションがコンシューマーから割り当てられるか取り消されると、メッセージの配信が一時停止され、リバランスが完了すると再開されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:541
msgid "If the rebalance listener handles offset commit on behalf of the user (using the `NONE` commit strategy), the rebalance listener must commit the offset synchronously in the partitionsRevoked callback.  We also recommend applying the same logic when the application stops."
msgstr "リバランスリスナーがユーザーに代わってオフセットコミットを処理する場合 ( `NONE` コミットストラテジーを使用)、リバランスリスナーは partitionsRevoked コールバックでオフセットを同期的にコミットする必要があります。また、アプリケーションが停止したときに同じロジックを適用することをお勧めします。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:543
msgid "Unlike the `ConsumerRebalanceListener` from Apache Kafka, the `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` methods pass the Kafka Consumer and the set of topics/partitions."
msgstr "Apache Kafka の `ConsumerRebalanceListener` とは異なり、`io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` メソッドは、Kafka コンシューマーとトピック/パーティションのセットを渡します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:547
msgid "In the following example we set up a consumer that always starts on messages from at most 10 minutes ago (or offset 0).  First we need to provide a bean that implements `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` and is annotated with `io.smallrye.common.annotation.Identifier`.  We then must configure our inbound connector to use this bean."
msgstr "以下の例では、最大 10 分前 (またはオフセット 0) からのメッセージで常に開始するコンシューマーを設定します。まず、 `io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener` を実装し、 `io.smallrye.common.annotation.Identifier` でアノテーションが付けられた Bean を提供する必要があります。次に、この Bean を使用するようにインバウンドコネクターを設定する必要があります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:551
#: upstream/_versions/3.0/guides/kafka.adoc:601
#, no-wrap
msgid "package inbound;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:557
#, no-wrap
msgid ""
"import io.smallrye.common.annotation.Identifier;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaConsumerRebalanceListener;\n"
"import org.apache.kafka.clients.consumer.Consumer;\n"
"import org.apache.kafka.clients.consumer.OffsetAndTimestamp;\n"
"import org.apache.kafka.clients.consumer.TopicPartition;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:563
#, no-wrap
msgid ""
"import jakarta.enterprise.context.ApplicationScoped;\n"
"import java.util.Collection;\n"
"import java.util.HashMap;\n"
"import java.util.Map;\n"
"import java.util.logging.Logger;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:567
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"@Identifier(\"rebalanced-example.rebalancer\")\n"
"public class KafkaRebalancedConsumerRebalanceListener implements KafkaConsumerRebalanceListener {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:569
#, no-wrap
msgid "    private static final Logger LOGGER = Logger.getLogger(KafkaRebalancedConsumerRebalanceListener.class.getName());\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:581
#, no-wrap
msgid ""
"    /**\n"
"     * When receiving a list of partitions, will search for the earliest offset within 10 minutes\n"
"     * and seek the consumer to it.\n"
"     *\n"
"     * @param consumer   underlying consumer\n"
"     * @param partitions set of assigned topic partitions\n"
"     */\n"
"    @Override\n"
"    public void onPartitionsAssigned(Consumer<?, ?> consumer, Collection<TopicPartition> partitions) {\n"
"        long now = System.currentTimeMillis();\n"
"        long shouldStartAt = now - 600_000L; //10 minute ago\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:594
#, no-wrap
msgid ""
"        Map<TopicPartition, Long> request = new HashMap<>();\n"
"        for (TopicPartition partition : partitions) {\n"
"            LOGGER.info(\"Assigned \" + partition);\n"
"            request.put(partition, shouldStartAt);\n"
"        }\n"
"        Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(request);\n"
"        for (Map.Entry<TopicPartition, OffsetAndTimestamp> position : offsets.entrySet()) {\n"
"            long target = position.getValue() == null ? 0L : position.getValue().offset();\n"
"            LOGGER.info(\"Seeking position \" + target + \" for \" + position.getKey());\n"
"            consumer.seek(position.getKey(), target);\n"
"        }\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:605
#, no-wrap
msgid ""
"import io.smallrye.reactive.messaging.kafka.IncomingKafkaRecord;\n"
"import org.eclipse.microprofile.reactive.messaging.Acknowledgment;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:609
#, no-wrap
msgid ""
"import jakarta.enterprise.context.ApplicationScoped;\n"
"import java.util.concurrent.CompletableFuture;\n"
"import java.util.concurrent.CompletionStage;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:612
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class KafkaRebalancedConsumer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:620
#, no-wrap
msgid ""
"    @Incoming(\"rebalanced-example\")\n"
"    @Acknowledgment(Acknowledgment.Strategy.NONE)\n"
"    public CompletionStage<Void> consume(IncomingKafkaRecord<Integer, String> message) {\n"
"        // We don't need to ACK messages because in this example,\n"
"        // we set offset during consumer rebalance\n"
"        return CompletableFuture.completedFuture(null);\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:626
msgid "To configure the inbound connector to use the provided listener, we either set the consumer rebalance listener’s identifier: `mp.messaging.incoming.rebalanced-example.consumer-rebalance-listener.name=rebalanced-example.rebalancer`"
msgstr "提供されたリスナーを使用するようにインバウンドコネクターを設定するには、コンシューマリバランスリスナーの識別子を設定します: `mp.messaging.incoming.rebalanced-example.consumer-rebalance-listener.name=rebalanced-example.rebalancer`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:628
msgid "Or have the listener’s name be the same as the group id:"
msgstr "または、リスナーの名前をグループ ID と同じにします:"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:630
msgid "`mp.messaging.incoming.rebalanced-example.group.id=rebalanced-example.rebalancer`"
msgstr "`mp.messaging.incoming.rebalanced-example.group.id=rebalanced-example.rebalancer`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:632
msgid "Setting the consumer rebalance listener’s name takes precedence over using the group id."
msgstr "コンシューマーリバランスリスナーの名前の設定は、グループ ID の使用よりも優先されます。"

#. type: Title ====
#: upstream/_versions/3.0/guides/kafka.adoc:633
#, no-wrap
msgid "Using unique consumer groups"
msgstr "一意のコンシューマーグループの活用"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:636
msgid "If you want to process all the records from a topic (from its beginning), you need:"
msgstr "あるトピックの (先頭からの) すべてのレコードを処理したい場合は、以下を実行してください。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:638
msgid "to set `auto.offset.reset = earliest`"
msgstr "`auto.offset.reset = earliest` の設定"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:639
msgid "assign your consumer to a consumer group not used by any other application."
msgstr "他のアプリケーションで使用されていないコンシューマーグループへのコンシューマーの割り当て"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:642
msgid "Quarkus generates a UUID that changes between two executions (including in dev mode).  So, you are sure no other consumer uses it, and you receive a new unique group id every time your application starts."
msgstr "Quarkus は、実行のたびに変更される UUID を生成します (dev モードを含む)。したがって、他のコンシューマーがそれを使用していないことを確認すると、アプリケーションが起動するたびに新しい一意のグループ ID を受け取ることになります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:644
msgid "You can use that generated UUID as the consumer group as follows:"
msgstr "その生成された UUID をコンシューマーグループとして、以下のように使用することができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:649
#, no-wrap
msgid ""
"mp.messaging.incoming.your-channel.auto.offset.reset=earliest\n"
"mp.messaging.incoming.your-channel.group.id=${quarkus.uuid}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:652
msgid "If the `group.id` attribute is not set, it defaults the `quarkus.application.name` configuration property."
msgstr "`group.id` 属性が設定されていない場合、`quarkus.application.name` 設定プロパティーがデフォルトになります。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:653
#, no-wrap
msgid "Receiving Kafka Records in Batches"
msgstr "バッチでの Kafka レコードの受信"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:657
msgid "By default, incoming methods receive each Kafka record individually.  Under the hood, Kafka consumer clients poll the broker constantly and receive records in batches, presented inside the `ConsumerRecords` container."
msgstr "デフォルトでは、着信メソッドは各 Kafka レコードを個別に受信します。内部的には、Kafka コンシューマークライアントはブローカーを絶えずポーリングし、 `ConsumerRecords` コンテナー内に表示されるレコードをバッチで受信します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:659
msgid "In *batch* mode, your application can receive all the records returned by the consumer *poll* in one go."
msgstr "*バッチ* モードでは、アプリケーションは、コンシューマー *ポーリング* から返されたすべてのレコードを一度に受信できます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:661
msgid "To achieve this you need to specify a compatible container type to receive all the data:"
msgstr "これを実現するには、すべてのデータを受信するための互換性のあるコンテナータイプを指定する必要があります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:670
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public void consume(List<Double> prices) {\n"
"    for (double price : prices) {\n"
"        // process price\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:674
msgid "The incoming method can also receive `Message<List<Payload>>`, `KafkaRecordBatch<Key, Payload>` `ConsumerRecords<Key, Payload>` types.  They give access to record details such as offset or timestamp:"
msgstr "着信メソッドは、`Message<List<Payload>>`、`KafkaRecordBatch<Key, Payload>` `ConsumerRecords<Key, Payload>` タイプを受信することもできます。これらは、オフセットやタイムスタンプなどのレコードの詳細へのアクセスを提供します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:687
#, no-wrap
msgid ""
"@Incoming(\"prices\")\n"
"public CompletionStage<Void> consumeMessage(KafkaRecordBatch<String, Double> records) {\n"
"    for (KafkaRecord<String, Double> record : records) {\n"
"        String payload = record.getPayload();\n"
"        String topic = record.getTopic();\n"
"        // process messages\n"
"    }\n"
"    // ack will commit the latest offsets (per partition) of the batch.\n"
"    return records.ack();\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:692
msgid "Note that the successful processing of the incoming record batch will commit the latest offsets for each partition received inside the batch.  The configured commit strategy will be applied for these records only."
msgstr "着信レコードバッチの処理が成功すると、バッチ内で受信した各パーティションの最新のオフセットがコミットされることに注意してください。設定されたコミットストラテジーは、これらのレコードにのみ適用されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:694
msgid "Conversely, if the processing throws an exception, all messages are _nacked_, applying the failure strategy for all the records inside the batch."
msgstr "逆に、処理が例外をスローした場合、すべてのメッセージは _nack_ され、バッチ内のすべてのレコードにエラーストラテジーが適用されます。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:699
msgid "Quarkus autodetects batch types for incoming channels and sets batch configuration automatically.  You can configure batch mode explicitly with `mp.messaging.incoming.$channel.batch` property."
msgstr "Quarkus は、着信チャネルのバッチタイプを自動検出し、バッチ設定を自動的に設定します。`mp.messaging.incoming.$channel.batch` プロパティーを使用して、バッチモードを明示的に設定できます。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:701
#, no-wrap
msgid "Stateful processing with Checkpointing"
msgstr "チェックポイントによるステートフル処理"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:706
msgid "The `checkpoint` commit strategy is an experimental feature and can change in the future."
msgstr "`checkpoint` コミットストラテジーは実験的な API であり、将来変更される可能性があります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:724
#: upstream/_versions/3.0/guides/kafka.adoc:824
#: upstream/_versions/3.0/guides/kafka.adoc:2325
#: upstream/_versions/3.0/guides/kafka.adoc:2373
#: upstream/_versions/3.0/guides/kafka.adoc:2414
#: upstream/_versions/3.0/guides/kafka.adoc:2432
#: upstream/_versions/3.0/guides/kafka.adoc:2462
#: upstream/_versions/3.0/guides/kafka.adoc:2494
#: upstream/_versions/3.0/guides/kafka.adoc:2513
#: upstream/_versions/3.0/guides/kafka.adoc:2558
#: upstream/_versions/3.0/guides/kafka.adoc:2601
#: upstream/_versions/3.0/guides/kafka.adoc:2642
#: upstream/_versions/3.0/guides/kafka.adoc:2749
#, no-wrap
msgid "package org.acme;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:726
#: upstream/_versions/3.0/guides/kafka.adoc:2327
#: upstream/_versions/3.0/guides/kafka.adoc:2375
#: upstream/_versions/3.0/guides/kafka.adoc:2603
#, no-wrap
msgid "import java.util.concurrent.CompletionStage;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:731
#, no-wrap
msgid ""
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
"import org.eclipse.microprofile.reactive.messaging.Message;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:734
#, no-wrap
msgid ""
"import io.smallrye.reactive.messaging.kafka.KafkaRecord;\n"
"import io.smallrye.reactive.messaging.kafka.commit.CheckpointMetadata;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:737
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class MeanCheckpointConsumer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:742
#, no-wrap
msgid ""
"    @Incoming(\"prices\")\n"
"    public CompletionStage<Void> consume(Message<Double> record) {\n"
"        // Get the `CheckpointMetadata` from the incoming message\n"
"        CheckpointMetadata<AveragePrice> checkpoint = CheckpointMetadata.fromMessage(record);\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:746
#, no-wrap
msgid ""
"        // `CheckpointMetadata` allows transforming the processing state\n"
"        // Applies the given function, starting from the value `0.0` when no previous state exists\n"
"        checkpoint.transform(new AveragePrice(), average -> average.update(record.getPayload()), /* persistOnAck */ true);\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:751
#, no-wrap
msgid ""
"        // `persistOnAck` flag set to true, ack will persist the processing state\n"
"        // associated with the latest offset (per partition).\n"
"        return record.ack();\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:755
#, no-wrap
msgid ""
"    static class AveragePrice {\n"
"        long count;\n"
"        double mean;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:762
#, no-wrap
msgid ""
"        AveragePrice update(double newPrice) {\n"
"            mean += ((newPrice - mean) / ++count);\n"
"            return this;\n"
"        }\n"
"    }\n"
"}\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:801
#, no-wrap
msgid ""
"mp.messaging.incoming.prices.group.id=prices-checkpoint\n"
"# ...\n"
"mp.messaging.incoming.prices.commit-strategy=checkpoint\n"
"mp.messaging.incoming.prices.checkpoint.state-store=quarkus-redis\n"
"mp.messaging.incoming.prices.checkpoint.state-type=org.acme.MeanCheckpointConsumer.AveragePrice\n"
"# ...\n"
"# if using a named redis client\n"
"mp.messaging.incoming.prices.checkpoint.quarkus-redis.client-name=my-redis\n"
"quarkus.redis.my-redis.hosts=redis://localhost:7000\n"
"quarkus.redis.my-redis.password=<redis-pwd>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:817
#, no-wrap
msgid ""
"mp.messaging.incoming.prices.group.id=prices-checkpoint\n"
"# ...\n"
"mp.messaging.incoming.prices.commit-strategy=checkpoint\n"
"mp.messaging.incoming.prices.checkpoint.state-store=quarkus-hibernate-reactive\n"
"mp.messaging.incoming.prices.checkpoint.state-type=org.acme.AveragePriceEntity\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:826
#: upstream/_versions/3.0/guides/kafka.adoc:2416
#: upstream/_versions/3.0/guides/kafka.adoc:2496
#, no-wrap
msgid "import jakarta.persistence.Entity;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:828
#, no-wrap
msgid "import io.quarkus.smallrye.reactivemessaging.kafka.CheckpointEntity;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:833
#, no-wrap
msgid ""
"@Entity\n"
"public class AveragePriceEntity extends CheckpointEntity {\n"
"    public long count;\n"
"    public double mean;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:839
#, no-wrap
msgid ""
"    public AveragePriceEntity update(double newPrice) {\n"
"        mean += ((newPrice - mean) / ++count);\n"
"        return this;\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:843
msgid "`quarkus-hibernate-orm`: Uses the xref:hibernate-orm.adoc[`quarkus-hibernate-orm`] extension to persist processing states.  It is similar to the previous state store, but it uses Hibernate ORM instead of Hibernate Reactive."
msgstr "`quarkus-hibernate-orm` : link:hibernate-orm.html[`quarkus-hibernate-orm`] エクステンションを使用して、処理状態を永続化します。先ほどのステートストアと似ていますが、Hibernate Reactiveの代わりにHibernate ORMを使用します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:845
msgid "When configured, it can use a named `persistence-unit` for the checkpointing state store:"
msgstr "設定されている場合、チェックポイントの状態保存に名前付き `persistence-unit` を使用することができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:859
#, no-wrap
msgid ""
"mp.messaging.incoming.prices.commit-strategy=checkpoint\n"
"mp.messaging.incoming.prices.checkpoint.state-store=quarkus-hibernate-orm\n"
"mp.messaging.incoming.prices.checkpoint.state-type=org.acme.AveragePriceEntity\n"
"mp.messaging.incoming.prices.checkpoint.quarkus-hibernate-orm.persistence-unit=prices\n"
"# ... Setup \"prices\" persistence unit\n"
"quarkus.datasource.\"prices\".db-kind=postgresql\n"
"quarkus.datasource.\"prices\".username=<your username>\n"
"quarkus.datasource.\"prices\".password=<your password>\n"
"quarkus.datasource.\"prices\".jdbc.url=jdbc:postgresql://localhost:5432/hibernate_orm_test\n"
"quarkus.hibernate-orm.\"prices\".datasource=prices\n"
"quarkus.hibernate-orm.\"prices\".packages=org.acme\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:863
msgid "For instructions on how to implement custom state stores, see https://smallrye.io/smallrye-reactive-messaging/3.22.0/kafka/receiving-kafka-records/#implementing-state-stores[Implementing State Stores]."
msgstr "カスタムステートストアの実装方法については、https://smallrye.io/smallrye-reactive-messaging/3.22.0/kafka/receiving-kafka-records/#implementing-state-stores[Implementing State Stores]を参照してください。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:864
#, no-wrap
msgid "Sending messages to Kafka"
msgstr "Kafka へのメッセージの送信"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:867
msgid "Configuration for the Kafka connector outgoing channels is similar to that of incoming:"
msgstr "Kafka コネクターの送信チャネルの設定は、受信の設定と似ています。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:873
#, no-wrap
msgid ""
"%prod.kafka.bootstrap.servers=kafka:9092 <1>\n"
"mp.messaging.outgoing.prices-out.connector=smallrye-kafka <2>\n"
"mp.messaging.outgoing.prices-out.topic=prices <3>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:878
msgid "Configure the broker location for the production profile. You can configure it globally or per channel using `mp.messaging.outgoing.$channel.bootstrap.servers` property.  In dev mode and when running tests, <<kafka-dev-services>> automatically starts a Kafka broker.  When not provided, this property defaults to `localhost:9092`."
msgstr "プロダクションプロファイルのブローカーの場所を設定します。`mp.messaging.outgoing.$channel.bootstrap.servers` プロパティーを使用して、グローバルまたはチャネルごとに設定できます。dev モードとテスト実行時には、<<kafka-dev-services>> が自動的に Kafka ブローカーを開始します。指定しない場合、このプロパティーのデフォルトは `localhost:9092` になります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:879
msgid "Configure the connector to manage the `prices-out` channel."
msgstr "`prices-out` チャネルを管理するためのコネクターを設定します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:880
msgid "By default, the topic name is same as the channel name. You can configure the topic attribute to override it."
msgstr "デフォルトでは、トピック名はチャネル名と同じです。トピック属性を設定することで、それを上書きすることができます。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:885
msgid "Inside application configuration, channel names are unique.  Therefore, if you'd like to configure an incoming and outgoing channel on the same topic, you will need to name channels differently (like in the examples of this guide, `mp.messaging.incoming.prices` and `mp.messaging.outgoing.prices-out`)."
msgstr "アプリケーション設定内では、チャネル名は一意です。したがって、同じトピックで着信チャネルと送信チャネルを設定する場合は、チャネルに異なる名前を付ける必要があります (たとえば、このガイドの例のように、`mp.messaging.incoming.prices` と `mp.messaging.outgoing.prices-out` など)。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:889
msgid "Then, your application can generate messages and publish them to the `prices-out` channel.  It can use `double` payloads as in the following snippet:"
msgstr "次に、アプリケーションはメッセージを生成し、それらを `prices-out` チャネルに公開できます。以下のスニペットのように、`double` ペイロードを使用することができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:894
#, no-wrap
msgid ""
"import io.smallrye.mutiny.Multi;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:898
#, no-wrap
msgid ""
"import jakarta.enterprise.context.ApplicationScoped;\n"
"import java.time.Duration;\n"
"import java.util.Random;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:901
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class KafkaPriceProducer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:903
#: upstream/_versions/3.0/guides/kafka.adoc:1215
#, no-wrap
msgid "    private final Random random = new Random();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:911
#, no-wrap
msgid ""
"    @Outgoing(\"prices-out\")\n"
"    public Multi<Double> generate() {\n"
"        // Build an infinite stream of random prices\n"
"        // It emits a price every second\n"
"        return Multi.createFrom().ticks().every(Duration.ofSeconds(1))\n"
"            .map(x -> random.nextDouble());\n"
"    }\n"
msgstr ""

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:918
msgid "You should not call methods annotated with `@Incoming` and/or `@Outgoing` directly from your code. They are invoked by the framework. Having user code invoking them would not have the expected outcome."
msgstr "コードから直接 `@Incoming` や `@Outgoing` のアノテーションが付けられたメソッドを呼び出さないでください。これらはフレームワークによって呼び出されます。ユーザーコードがそれらを呼び出すと、期待された結果にはなりません。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:922
msgid "Note that the `generate` method returns a `Multi<Double>`, which implements the Reactive Streams `Publisher` interface.  This publisher will be used by the framework to generate messages and send them to the configured Kafka topic."
msgstr "`generate` メソッドは `Multi<Double>` を返すことに注意してください。これは、Reactive Streams `Publisher` インターフェイスを実装します。このパブリッシャーは、メッセージを生成し、設定された Kafka トピックに送信するためにフレームワークによって使用されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:924
msgid "Instead of returning a payload, you can return a `io.smallrye.reactive.messaging.kafka.Record` to send key/value pairs:"
msgstr "ペイロードを返す代わりに、`io.smallrye.reactive.messaging.kafka.Record` を返して、キーと値のペアを送信できます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:932
#, no-wrap
msgid ""
"@Outgoing(\"out\")\n"
"public Multi<Record<String, Double>> generate() {\n"
"    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))\n"
"        .map(x -> Record.of(\"my-key\", random.nextDouble()));\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:935
msgid "Payload can be wrapped inside `org.eclipse.microprofile.reactive.messaging.Message` to have more control on the written records:"
msgstr "ペイロードを `org.eclipse.microprofile.reactive.messaging.Message` 内にラップして、書き込まれたレコードをより詳細に制御できます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:948
#, no-wrap
msgid ""
"@Outgoing(\"generated-price\")\n"
"public Multi<Message<Double>> generate() {\n"
"    return Multi.createFrom().ticks().every(Duration.ofSeconds(1))\n"
"            .map(x -> Message.of(random.nextDouble())\n"
"                    .addMetadata(OutgoingKafkaRecordMetadata.<String>builder()\n"
"                            .withKey(\"my-key\")\n"
"                            .withTopic(\"my-key-prices\")\n"
"                            .withHeaders(new RecordHeaders().add(\"my-header\", \"value\".getBytes()))\n"
"                            .build()));\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:953
msgid "`OutgoingKafkaRecordMetadata` allows to set metadata attributes of the Kafka record, such as `key`, `topic`, `partition` or `timestamp`.  One use case is to dynamically select the destination topic of a message.  In this case, instead of configuring the topic inside your application configuration file, you need to use the outgoing metadata to set the name of the topic."
msgstr "`OutgoingKafkaRecordMetadata` を使用すると、Kafka レコードのメタデータ属性 (`key`、`topic`、`partition`、`timestamp` など) を設定できます。1 つの使用例は、メッセージの宛先トピックを動的に選択することです。この場合、アプリケーション設定ファイル内でトピックを設定する代わりに、送信メタデータを使用してトピックの名前を設定する必要があります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:956
msgid "Other than method signatures returning a Reactive Stream `Publisher` (`Multi` being an implementation of `Publisher`), outgoing method can also return single message.  In this case the producer will use this method as generator to create an infinite stream."
msgstr "Reactive Stream `Publisher` (`Multi` が `Publisher` の実装) を返すメソッドシグネチャー以外に、送信メソッドは単一のメッセージを返すこともできます。この場合、プロデューサーはこのメソッドをジェネレーターとして使用して、無限のストリームを作成します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:960
#, no-wrap
msgid "@Outgoing(\"prices-out\") T generate(); // T excluding void\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:962
#, no-wrap
msgid "@Outgoing(\"prices-out\") Message<T> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:964
#, no-wrap
msgid "@Outgoing(\"prices-out\") Uni<T> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:966
#, no-wrap
msgid "@Outgoing(\"prices-out\") Uni<Message<T>> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:968
#, no-wrap
msgid "@Outgoing(\"prices-out\") CompletionStage<T> generate();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:970
#, no-wrap
msgid "@Outgoing(\"prices-out\") CompletionStage<Message<T>> generate();\n"
msgstr ""

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:972
#, no-wrap
msgid "Sending messages with @Emitter"
msgstr "@Emitter を使ったメッセージの送信"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:975
msgid "Sometimes, you need to have an imperative way of sending messages."
msgstr "時には、命令的な方法でメッセージを送ることが必要になる場合もあります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:978
msgid "For example, if you need to send a message to a stream when receiving a POST request inside a REST endpoint.  In this case, you cannot use `@Outgoing` because your method has parameters."
msgstr "たとえば、REST エンドポイント内で POST リクエストを受信した際に、ストリームにメッセージを送信する必要があるとします。この場合、メソッドにパラメーターがあるため、`@Outgoing` を使用することはできません。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:980
msgid "For this, you can use an `Emitter`."
msgstr "この場合には `Emitter` が利用できます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:985
#: upstream/_versions/3.0/guides/kafka.adoc:2335
#: upstream/_versions/3.0/guides/kafka.adoc:2383
#: upstream/_versions/3.0/guides/kafka.adoc:2610
#, no-wrap
msgid ""
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.eclipse.microprofile.reactive.messaging.Emitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:991
#: upstream/_versions/3.0/guides/kafka.adoc:1036
#: upstream/_versions/3.0/guides/kafka.adoc:1070
#, no-wrap
msgid ""
"import jakarta.inject.Inject;\n"
"import jakarta.ws.rs.POST;\n"
"import jakarta.ws.rs.Path;\n"
"import jakarta.ws.rs.Consumes;\n"
"import jakarta.ws.rs.core.MediaType;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:998
#, no-wrap
msgid ""
"    @Inject\n"
"    @Channel(\"price-create\")\n"
"    Emitter<Double> priceEmitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1005
#, no-wrap
msgid ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        CompletionStage<Void> ack = priceEmitter.send(price);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1008
msgid "Sending a payload returns a `CompletionStage`, completed when the message is acked. If the message transmission fails, the `CompletionStage` is completed exceptionally with the reason of the nack."
msgstr "ペイロードを送信すると、メッセージが確認されたときに完了する `CompletionStage` が返されます。メッセージの送信が失敗した場合、nack の理由を伴って例外扱いで `CompletionStage` が完了します。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:1012
msgid "The `Emitter` configuration is done the same way as the other stream configuration used by `@Incoming` and `@Outgoing`."
msgstr "`Emitter` の設定は、`@Incoming` と `@Outgoing` で使用される他のストリーム設定と同じ方法で行われます。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:1021
msgid "Using the `Emitter` you are sending messages from your imperative code to reactive messaging.  These messages are stored in a queue until they are sent.  If the Kafka producer client can't keep up with messages trying to be sent over to Kafka, this queue can become a memory hog and you may even run out of memory.  You can use `@OnOverflow` to configure back-pressure strategy.  It lets you configure the size of the queue (default is 256) and the strategy to apply when the buffer size is reached. Available strategies are `DROP`, `LATEST`, `FAIL`, `BUFFER`, `UNBOUNDED_BUFFER` and `NONE`."
msgstr "`Emitter` を使用すると、命令型コードから Reactive Messaging にメッセージを送信します。これらのメッセージは送信されるまでキューに保存されます。Kafka プロデューサークライアントが Kafka に送信しようとするメッセージに対応できない場合、このキューはメモリを大量に消費し、メモリ不足になる可能性があります。 `@OnOverflow` を使用して、バックプレッシャーストラテジーを設定することができます。これにより、キューのサイズ（デフォルトは 256）およびバッファーサイズに達したときに適用するストラテジーを設定できます。利用可能なストラテジーは、`DROP`、`LATEST`、`FAIL`、`BUFFER`、`UNBOUNDED_BUFFER` および `NONE` です。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1024
msgid "With the `Emitter` API, you can also encapsulate the outgoing payload inside `Message<T>`. As with the previous examples, `Message` lets you handle the ack/nack cases differently."
msgstr "`Emitter` API を使用すると、`Message<T>` 内に送信ペイロードをカプセル化することもできます。前出の例のように、`Message` では、ack/nack のケースを異なる方法で処理することができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1030
#, no-wrap
msgid ""
"import java.util.concurrent.CompletableFuture;\n"
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.eclipse.microprofile.reactive.messaging.Emitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1041
#, no-wrap
msgid "    @Inject @Channel(\"price-create\") Emitter<Double> priceEmitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1056
#, no-wrap
msgid ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public void addPrice(Double price) {\n"
"        priceEmitter.send(Message.of(price)\n"
"            .withAck(() -> {\n"
"                // Called when the message is acked\n"
"                return CompletableFuture.completedFuture(null);\n"
"            })\n"
"            .withNack(throwable -> {\n"
"                // Called when the message is nacked\n"
"                return CompletableFuture.completedFuture(null);\n"
"            }));\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1060
msgid "If you prefer using Reactive Stream APIs, you can use `MutinyEmitter` that will return `Uni<Void>` from the `send` method.  You can therefore use Mutiny APIs for handling downstream messages and errors."
msgstr "Reactive Stream API を使いたい場合は、`send` メソッドから `Uni<Void>` を返す `MutinyEmitter` を使用することができます。これにより、Mutiny API を使用してダウンストリームのメッセージとエラーを処理することができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1064
#: upstream/_versions/3.0/guides/kafka.adoc:1252
#: upstream/_versions/3.0/guides/kafka.adoc:2647
#, no-wrap
msgid "import org.eclipse.microprofile.reactive.messaging.Channel;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1072
#, no-wrap
msgid "import io.smallrye.reactive.messaging.MutinyEmitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1079
#, no-wrap
msgid ""
"    @Inject\n"
"    @Channel(\"price-create\")\n"
"    MutinyEmitter<Double> priceEmitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1088
#, no-wrap
msgid ""
"    @POST\n"
"    @Consumes(MediaType.TEXT_PLAIN)\n"
"    public Uni<String> addPrice(Double price) {\n"
"        return quoteRequestEmitter.send(price)\n"
"                .map(x -> \"ok\")\n"
"                .onFailure().recoverWithItem(\"ko\");\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1092
msgid "It is also possible to block on sending the event to the emitter with the `sendAndAwait` method.  It will only return from the method when the event is acked or nacked by the receiver."
msgstr "`sendAndAwait` メソッドを使用して、イベントをエミッターに送信することをブロックすることもできます。受信者がイベントを ack または nack したときのみ、このメソッドから戻ります。"

#. type: Block title
#: upstream/_versions/3.0/guides/kafka.adoc:1094
#, no-wrap
msgid "Deprecation"
msgstr "非推奨"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:1097
msgid "The `io.smallrye.reactive.messaging.annotations.Emitter`, `io.smallrye.reactive.messaging.annotations.Channel` and `io.smallrye.reactive.messaging.annotations.OnOverflow` classes are now deprecated and replaced by:"
msgstr "`io.smallrye.reactive.messaging.annotations.Emitter`、`io.smallrye.reactive.messaging.annotations.Channel`、`io.smallrye.reactive.messaging.annotations.OnOverflow` クラスは現在非推奨となっており、以下のように置き換えられています。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:1099
msgid "`org.eclipse.microprofile.reactive.messaging.Emitter`"
msgstr "`org.eclipse.microprofile.reactive.messaging.Emitter`"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:1100
msgid "`org.eclipse.microprofile.reactive.messaging.Channel`"
msgstr "`org.eclipse.microprofile.reactive.messaging.Channel`"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:1101
msgid "`org.eclipse.microprofile.reactive.messaging.OnOverflow`"
msgstr "`org.eclipse.microprofile.reactive.messaging.OnOverflow`"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:1103
msgid "The new `Emitter.send` method returns a `CompletionStage` completed when the produced message is acknowledged."
msgstr "新しい `Emitter.send` メソッドは、生成されたメッセージが確認応答されると、`CompletionStage` の完了を返します。"

#. type: Block title
#: upstream/_versions/3.0/guides/kafka.adoc:1106
#, no-wrap
msgid "Depreciation"
msgstr "非推奨"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:1109
msgid "`MutinyEmitter#send(Message msg)` method is deprecated in favor of following methods receiving `Message` for emitting:"
msgstr "MutinyEmitter#send(Message msg)` メソッドは非推奨となり、以下のメソッドが `Message` を受信して発信するようになりました。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1117
msgid "More information on how to use `Emitter` can be found in https://smallrye.io/smallrye-reactive-messaging/latest/concepts/emitter/[SmallRye Reactive Messaging – Emitters and Channels]"
msgstr "`Emitter` の使用方法の詳細については、https://smallrye.io/smallrye-reactive-messaging/latest/concepts/emitter/[SmallRye Reactive Messaging – Emitters and Channels] を参照してください。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1118
#, no-wrap
msgid "Write Acknowledgement"
msgstr "確認応答の書き込み"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1122
msgid "When Kafka broker receives a record, its acknowledgement can take time depending on the configuration.  Also, it stores in-memory the records that cannot be written."
msgstr "Kafka ブローカーがレコードを受信すると、設定に応じてその確認応答に時間がかかることがあります。また、書き込めないレコードをインメモリーに保存します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1125
msgid "By default, the connector does wait for Kafka to acknowledge the record to continue the processing (acknowledging the received Message).  You can disable this by setting the `waitForWriteCompletion` attribute to `false`."
msgstr "デフォルトでは、コネクターは Kafka がレコードを確認応答するのを待ち、処理を続行します (受信したメッセージの確認応答)。これを無効にするには、`waitForWriteCompletion` 属性を `false` に設定します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1127
msgid "Note that the `acks` attribute has a huge impact on the record acknowledgement."
msgstr "`acks` 属性は、レコードの確認応答に大きく影響することに注意してください。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1129
msgid "If a record cannot be written, the message is nacked."
msgstr "レコードを書き込めない場合は、メッセージは nack になります。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1130
#, no-wrap
msgid "Backpressure"
msgstr "バックプレッシャー"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1134
msgid "The Kafka outbound connector handles back-pressure, monitoring the number of in-flight messages waiting to be written to the Kafka broker.  The number of in-flight messages is configured using the `max-inflight-messages` attribute and defaults to 1024."
msgstr "Kafka アウトバウンドコネクターはバックプレッシャーを処理し、Kafka ブローカーへの書き込みを待機しているインフライトメッセージの数を監視します。インフライトメッセージの数は、`max-inflight-messages` 属性を使用して設定され、デフォルトは 1024 になります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1139
msgid "The connector only sends that amount of messages concurrently.  No other messages will be sent until at least one in-flight message gets acknowledged by the broker.  Then, the connector writes a new message to Kafka when one of the broker’s in-flight messages get acknowledged.  Be sure to configure Kafka’s `batch.size` and `linger.ms` accordingly."
msgstr "コネクターは、その量のメッセージのみを同時に送信します。少なくとも 1 つのインフライトメッセージがブローカーによって確認応答されるまで、他のメッセージは送信されません。次に、ブローカーのインフライトメッセージの 1 つが確認応答されると、コネクターは Kafka に新しいメッセージを書き込みます。それに応じて、Kafka の `batch.size` と `linger.ms` を設定してください。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1142
msgid "You can also remove the limit of in-flight messages by setting `max-inflight-messages` to `0`.  However, note that the Kafka producer may block if the number of requests reaches `max.in.flight.requests.per.connection`."
msgstr "`max-inflight-messages` を `0` に設定することで、インフライトメッセージの制限を解除することもできます。ただし、リクエスト数が `max.in.flight.requests.per.connection` に達すると、Kafka プロデューサーがブロックする可能性があることに注意してください。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1143
#, no-wrap
msgid "Retrying message dispatch"
msgstr "メッセージディスパッチの再試行"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1148
msgid "When the Kafka producer receives an error from the server, if it is a transient, recoverable error, the client will retry sending the batch of messages.  This behavior is controlled by `retries` and `retry.backoff.ms` parameters.  In addition to this, SmallRye Reactive Messaging will retry individual messages on recoverable errors, depending on the `retries` and `delivery.timeout.ms` parameters."
msgstr "Kafka プロデューサーがサーバーからエラーを受信した場合、それが一時的な回復可能なエラーである場合、クライアントはメッセージのバッチの送信を再試行します。この動作は、`retries` および `retry.backoff.ms` パラメーターによって制御されます。これに加えて、SmallRye Reactive Messaging は、`retries` および `delivery.timeout.ms` パラメーターに応じて、回復可能なエラーで個々のメッセージを再試行します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1151
msgid "Note that while having retries in a reliable system is a best practice, the `max.in.flight.requests.per.connection` parameter defaults to `5`, meaning that the order of the messages is not guaranteed.  If the message order is a must for your use case, setting `max.in.flight.requests.per.connection` to `1` will make sure a single batch of messages is sent at a time, in the expense of limiting the throughput of the producer."
msgstr "信頼性の高いシステムにおいては再試行するのがベストプラクティスですが、`max.in.flight.requests.per.connection` パラメーターのデフォルトは `5` で、これはメッセージの順序が保証されていないことを意味する点に注意してください。使用例でメッセージの順序が必須である場合、`max.in.flight.requests.per.connection` を `1` に設定すると、一度に送信されるメッセージのバッチが 1 つになり、その分プロデューサーのスループットが制限されることになります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1153
msgid "For applying retry mechanism on processing errors, see the section on <<retrying-processing>>."
msgstr "エラーの処理に再試行メカニズムを適用する場合は、 <<処理のリトライ>> のセクションを参照してください。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1154
#, no-wrap
msgid "Handling Serialization Failures"
msgstr "シリアライゼーション失敗時の処理"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1158
msgid "For Kafka producer client serialization failures are not recoverable, thus the message dispatch is not retried. In these cases you may need to apply a failure strategy for the serializer.  To achieve this, you need to create a bean implementing `SerializationFailureHandler<T>` interface:"
msgstr "Kafka プロデューサーの場合、クライアントのシリアライゼーションのエラーは回復できないため、メッセージディスパッチは再試行されません。このような場合、シリアライザーのエラーストラテジーを適用する必要があるかもしれません。これを実現するには、`SerializationFailureHandler<T>` インターフェイスを実装する Bean を作成する必要があります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1165
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"@Identifier(\"failure-fallback\") // Set the name of the failure handler\n"
"public class MySerializationFailureHandler\n"
"    implements SerializationFailureHandler<JsonObject> { // Specify the expected type\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1174
#, no-wrap
msgid ""
"    @Override\n"
"    public byte[] decorateSerialization(Uni<byte[]> serialization, String topic, boolean isKey,\n"
"        String serializer, Object data, Headers headers) {\n"
"        return serialization\n"
"                    .onFailure().retry().atMost(3)\n"
"                    .await().indefinitely();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1177
msgid "To use this failure handler, the bean must be exposed with the `@Identifier` qualifier and the connector configuration must specify the attribute `mp.messaging.outgoing.$channel.[key|value]-serialization-failure-handler` (for key or value serializers)."
msgstr "このエラーハンドラーを使用するには、Bean を `@Identifier` 修飾子で公開し、コネクター設定で属性 `mp.messaging.outgoing.$channel.[key|value]-serialization-failure-handler` を指定する必要があります (キーまたは値のデシリアライザー用)。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1180
msgid "The handler is called with details of the serialization, including the action represented as `Uni<byte[]>`.  Note that the method must await on the result and return the serialized byte array."
msgstr "ハンドラーは、`Uni<byte[]>` として表されるアクションを含むシリアライゼーションの詳細とともに呼び出されます。メソッドは結果を待機し、シリアライズされたバイト配列を返す必要があることに注意してください。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1181
#, no-wrap
msgid "In-memory channels"
msgstr "インメモリーチャンネル"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1186
msgid "In some use cases, it is convenient to use the messaging patterns to transfer messages inside the same application.  When you don't connect a channel to a messaging backend like Kafka, everything happens in-memory, and the streams are created by chaining methods together.  Each chain is still a reactive stream and enforces the back-pressure protocol."
msgstr "ユースケースによっては、メッセージングパターンを使って同じアプリケーション内でメッセージを転送することが便利な場合があります。Kafka のようなメッセージングバックエンドにチャネルを接続しない場合、すべてがインメモリーで行われ、ストリームはメソッドをチェーンすることで作成されます。各チェーンは依然としてリアクティブストリームであり、バックプレッシャープロトコルが適用されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1190
msgid "The framework verifies that the producer/consumer chain is complete, meaning that if the application writes messages into an in-memory channel (using a method with only `@Outgoing`, or an `Emitter`), it must also consume the messages from within the application (using a method with only `@Incoming` or using an unmanaged stream)."
msgstr "フレームワークは、プロデューサー/コンシューマーチェーンが完全であることを確認します。つまり、アプリケーションがメッセージをインメモリーチャネルに書き込む場合 (`@Outgoing` のみを持つメソッド、または `Emitter` を使用)、アプリケーション内からメッセージを消費する必要もあります (`@Incoming` のみを持つメソッド、またはアンマネージドストリームを使用)。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1192
#, no-wrap
msgid "Broadcasting messages on multiple consumers"
msgstr "複数のコンシューマーでのメッセージのブロードキャスト"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1197
msgid "By default, a channel can be linked to a single consumer, using `@Incoming` method or `@Channel` reactive stream.  At application startup, channels are verified to form a chain of consumers and producers with single consumer and producer.  You can override this behavior by setting `mp.messaging.$channel.broadcast=true` on a channel."
msgstr "デフォルトでは、`@Incoming` メソッドまたは `@Channel` リアクティブストリームを使用して、チャネルを単一のコンシューマーにリンクすることができます。アプリケーションの起動時に、チャネルが検証され、単一のコンシューマーとプロデューサーを持つコンシューマーとプロデューサーのチェーンが形成されます。この動作は、チャネルで `mp.messaging.$channel.broadcast=true` を設定することで、オーバーライドすることができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1199
msgid "In case of in-memory channels, `@Broadcast` annotation can be used on the `@Outgoing` method. For example,"
msgstr "インメモリーチャネルの場合、`@Broadcast` アノテーションを `@Outgoing` メソッドで使用できます。以下に例を示します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1203
#, no-wrap
msgid "import java.util.Random;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1208
#: upstream/_versions/3.0/guides/kafka.adoc:1319
#: upstream/_versions/3.0/guides/kafka.adoc:1347
#, no-wrap
msgid ""
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1210
#, no-wrap
msgid "import io.smallrye.reactive.messaging.annotations.Broadcast;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1213
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class MultipleConsumer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1221
#, no-wrap
msgid ""
"    @Outgoing(\"in-memory-channel\")\n"
"    @Broadcast\n"
"    double generate() {\n"
"        return random.nextDouble();\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1226
#, no-wrap
msgid ""
"    @Incoming(\"in-memory-channel\")\n"
"    void consumeAndLog(double price) {\n"
"        System.out.println(price);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1233
#, no-wrap
msgid ""
"    @Incoming(\"in-memory-channel\")\n"
"    @Outgoing(\"prices2\")\n"
"    double consumeAndSend(double price) {\n"
"        return price;\n"
"    }\n"
"}\n"
msgstr ""

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:1239
msgid "Reciprocally, multiple producers on the same channel can be merged by setting `mp.messaging.incoming.$channel.merge=true`.  On the `@Incoming` methods, you can control how multiple channels are merged using the `@Merge` annotation."
msgstr "反対に、`mp.messaging.incoming.$channel.merge=true` を設定することにより、同じチャネル上の複数のプロデューサーをマージすることができます。`@Incoming` メソッドでは、`@Merge` アノテーションを使用して複数のチャネルをマージする方法を制御できます。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1241
#, no-wrap
msgid "Kafka Transactions"
msgstr "Kafka トランザクション"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1246
msgid "Kafka transactions enable atomic writes to multiple Kafka topics and partitions.  The Kafka connector provides `KafkaTransactions` custom emitter for writing Kafka records inside a transaction.  It can be injected as a regular emitter `@Channel`:"
msgstr "Kafka トランザクションにより、複数の Kafka トピックおよびパーティションへのアトミックな書き込みが可能になります。Kafka コネクターは、トランザクション内に Kafka レコードを書き込むための `KafkaTransactions` カスタムエミッターを提供します。これは、通常のエミッター `@Channel` として注入することができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1256
#, no-wrap
msgid ""
"import io.smallrye.mutiny.Uni;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaRecord;\n"
"import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1259
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class KafkaTransactionalProducer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1262
#, no-wrap
msgid ""
"    @Channel(\"tx-out-example\")\n"
"    KafkaTransactions<String> txProducer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1271
#, no-wrap
msgid ""
"    public Uni<Void> emitInTransaction() {\n"
"        return txProducer.withTransaction(emitter -> {\n"
"            emitter.send(KafkaRecord.of(1, \"a\"));\n"
"            emitter.send(KafkaRecord.of(2, \"b\"));\n"
"            emitter.send(KafkaRecord.of(3, \"c\"));\n"
"            return Uni.createFrom().voidItem();\n"
"        });\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1276
msgid "The function given to the `withTransaction` method receives a `TransactionalEmitter` for producing records, and returns a `Uni` that provides the result of the transaction."
msgstr "`withTransaction` メソッドに指定された関数は、レコードの生成用に `TransactionalEmitter` を受け取り、トランザクションの結果を提供する `Uni` を返します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1278
msgid "If the processing completes successfully, the producer is flushed and the transaction is committed."
msgstr "処理が正常に完了すると、プロデューサーはフラッシュされ、トランザクションはコミットされます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1279
msgid "If the processing throws an exception, returns a failing `Uni`, or marks the `TransactionalEmitter` for abort, the transaction is aborted."
msgstr "処理が例外を投げるか、失敗した `Uni` を返すか、あるいは `TransactionalEmitter` に中止のマークを付けると、トランザクションは中止されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1283
msgid "Kafka transactional producers require configuring `acks=all` client property, and a unique id for `transactional.id`, which implies `enable.idempotence=true`.  When Quarkus detects the use of `KafkaTransactions` for an outgoing channel it configures these properties on the channel, providing a default value of `\"${quarkus.application.name}-${channelName}\"` for `transactional.id` property."
msgstr "Kafka トランザクションプロデューサーでは、`acks=all` クライアントプロパティーと `transactional.id` の一意の ID を設定する必要があります。これは、`enable.idempotence=true` を意味します。Quarkus が送信チャネルの `KafkaTransactions` の使用を検出すると、チャンネルでこれらのプロパティーを設定し、`transactional.id` プロパティーに `\"${quarkus.application.name}-${channelName}\"` のデフォルト値を提供します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1285
msgid "Note that for production use the `transactional.id` must be unique across all application instances."
msgstr "本番環境で使用する場合、`transactional.id` はすべてのアプリケーションインスタンスで一意である必要があることに注意してください。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:1293
msgid "While a normal message emitter would support concurrent calls to `send` methods and consequently queues outgoing messages to be written to Kafka, a `KafkaTransactions` emitter only supports one transaction at a time.  A transaction is considered in progress from the call to the `withTransaction` until the returned `Uni` results in success or failure.  While a transaction is in progress, subsequent calls to the `withTransaction`, including nested ones inside the given function, will throw `IllegalStateException`."
msgstr "通常のメッセージエミッターは `send` メソッドへの同時呼び出しをサポートし、結果として Kafka に書き込まれる送信メッセージをキューに入れますが、`KafkaTransactions` エミッターは一度に 1 つのトランザクションのみをサポートします。トランザクションは、`withTransaction` の呼び出しから、返された `Uni` が成功または失敗するまで進行中であると見なされます。トランザクションの進行中に、指定された関数内のネストされたものを含む `withTransaction` への後続の呼び出しは、`IllegalStateException` をスローします。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:1297
msgid "Note that in Reactive Messaging, the execution of processing methods, is already serialized, unless `@Blocking(ordered = false)` is used.  If `withTransaction` can be called concurrently, for example from a REST endpoint, it is recommended to limit the concurrency of the execution.  This can be done using the `@Bulkhead` annotation from link:https://quarkus.io/guides/smallrye-fault-tolerance[_Microprofile Fault Tolerance_]."
msgstr "Reactive Messaging では、`@Blocking(ordered = false)` が使用されていない限り、処理メソッドの実行はすでにシリアライズされていることに注意してください。たとえば、REST エンドポイントから `withTransaction` を同時に呼び出すことができる場合は、実行の同時性を制限することをお勧めします。これは、 link:https://quarkus.io/guides/smallrye-fault-tolerance[_Microprofile Fault Tolerance_] の `@Bulkhead` アノテーションを使用して実行できます。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:1299
msgid "An example usage can be found in <<chaining-kafka-transactions-with-hibernate-reactive-transactions>>."
msgstr "使用例については、<<chaining-kafka-transactions-with-hibernate-reactive-transactions>> を参照してください。"

#. type: Title ====
#: upstream/_versions/3.0/guides/kafka.adoc:1301
#, no-wrap
msgid "Transaction-aware consumers"
msgstr "トランザクションを意識したコンシューマー"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1304
msgid "If you'd like to consume records only written and committed inside a Kafka transaction you need to configure the `isolation.level` property on the incoming channel as such:"
msgstr "Kafka トランザクション内で書き込まれ、コミットされたレコードのみを使用する場合は、着信チャネルの `isolation.level` プロパティーを以下のように設定する必要があります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1308
#, no-wrap
msgid "mp.messaging.incoming.prices-in.isolation.level=read_committed\n"
msgstr ""

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:1310
#, no-wrap
msgid "Processing Messages"
msgstr "メッセージの処理"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1314
msgid "Applications streaming data often need to consume some events from a topic, process them and publish the result to a different topic.  A processor method can be simply implemented using both the `@Incoming` and `@Outgoing` annotations:"
msgstr "多くの場合、データをストリーミングするアプリケーションは、トピックからいくつかのイベントを消費し、それらを処理して、結果を別のトピックに公開する必要があります。プロセッサーメソッドは、`@Incoming` アノテーションと `@Outgoing` アノテーションの両方を使用して簡単に実装することができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1324
#: upstream/_versions/3.0/guides/kafka.adoc:1352
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class PriceProcessor {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1326
#: upstream/_versions/3.0/guides/kafka.adoc:1354
#: upstream/_versions/3.0/guides/kafka.adoc:1565
#, no-wrap
msgid "    private static final double CONVERSION_RATE = 0.88;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1332
#, no-wrap
msgid ""
"    @Incoming(\"price-in\")\n"
"    @Outgoing(\"price-out\")\n"
"    public double process(double price) {\n"
"        return price * CONVERSION_RATE;\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1338
msgid "The parameter of the `process` method is the incoming message payload, whereas the return value will be used as the outgoing message payload.  Previously mentioned signatures for parameter and return types are also supported, such as `Message<T>`, `Record<K, V>`, etc."
msgstr "`process` メソッドのパラメーターは着信メッセージのペイロードですが、戻り値は送信メッセージのペイロードとして使用されます。`Message<T>` や `Record<K, V>` など、前述のパラメーターとリターンタイプのシグネチャーもサポートされています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1340
msgid "You can apply asynchronous stream processing by consuming and returning reactive stream `Multi<T>` type:"
msgstr "リアクティブストリーム `Multi<T>` タイプを消費して返すことにより、非同期ストリーム処理を適用することができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1349
#, no-wrap
msgid "import io.smallrye.mutiny.Multi;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1360
#, no-wrap
msgid ""
"    @Incoming(\"price-in\")\n"
"    @Outgoing(\"price-out\")\n"
"    public Multi<Double> process(Multi<Integer> prices) {\n"
"        return prices.filter(p -> p > 100).map(p -> p * CONVERSION_RATE);\n"
"    }\n"
msgstr ""

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1364
#, no-wrap
msgid "Propagating Record Key"
msgstr "レコードキーの伝播"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1367
msgid "When processing messages, you can propagate incoming record key to the outgoing record."
msgstr "メッセージを処理するときに、着信レコードキーを送信レコードに伝播できます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1370
msgid "Enabled with `mp.messaging.outgoing.$channel.propagate-record-key=true` configuration, record key propagation produces the outgoing record with the same _key_ as the incoming record."
msgstr "`mp.messaging.outgoing.$channel.propagate-record-key=true` の設定で有効にすると、レコードキーの伝播が受信レコードと同じ _key_ を持つ送信レコードを生成します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1373
msgid "If the outgoing record already contains a _key_, it *won't be overridden* by the incoming record key.  If the incoming record does have a _null_ key, the `mp.messaging.outgoing.$channel.key` property is used."
msgstr "送信レコードにすでに _key_ が含まれている場合、着信レコードキーによって *オーバーライドされません* 。着信レコードに _null_ キーがある場合は、`mp.messaging.outgoing.$channel.key` プロパティーが使用されます。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1374
#, no-wrap
msgid "Exactly-Once Processing"
msgstr "Exactly-Once 処理"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1378
msgid "Kafka Transactions allows managing consumer offsets inside a transaction, together with produced messages.  This enables coupling a consumer with a transactional producer in a _consume-transform-produce_ pattern, also known as *exactly-once processing*."
msgstr "Kafka Transactions を使用すると、生成されたメッセージとともに、トランザクション内のコンシューマーオフセットを管理できます。これにより、コンシューマーとトランザクションプロデューサーを _consume-transform-produce_ パターンでカップリングすることができます。これは *exactly-once 処理* としても知られています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1380
msgid "The `KafkaTransactions` custom emitter provides a way to apply exactly-once processing to an incoming Kafka message inside a transaction."
msgstr "`KafkaTransactions` カスタムエミッターは、トランザクション内の着信 Kafka メッセージに exactly-once 処理を適用する方法を提供します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1382
msgid "The following example includes a batch of Kafka records inside a transaction."
msgstr "次の例には、トランザクション内の Kafka レコードのバッチが含まれています。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1390
#, no-wrap
msgid ""
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
"import org.eclipse.microprofile.reactive.messaging.OnOverflow;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1395
#, no-wrap
msgid ""
"import io.smallrye.mutiny.Uni;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaRecord;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaRecordBatch;\n"
"import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1398
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class KafkaExactlyOnceProcessor {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1402
#, no-wrap
msgid ""
"    @Channel(\"prices-out\")\n"
"    @OnOverflow(value = OnOverflow.Strategy.BUFFER, bufferSize = 500) // <3>\n"
"    KafkaTransactions<Integer> txProducer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1412
#, no-wrap
msgid ""
"    @Incoming(\"prices-in\")\n"
"    public Uni<Void> emitInTransaction(KafkaRecordBatch<String, Integer> batch) { // <1>\n"
"        return txProducer.withTransactionAndAck(batch, emitter -> { // <2>\n"
"            for (KafkaRecord<String, Integer> record : batch) {\n"
"                emitter.send(KafkaRecord.of(record.getKey(), record.getPayload() + 1)); // <3>\n"
"            }\n"
"            return Uni.createFrom().voidItem();\n"
"        });\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1418
msgid "It is recommended to use exactly-once processing along with the batch consumption mode.  While it is possible to use it with a single Kafka message, it'll have a significant performance impact."
msgstr "バッチ消費モードと一緒に exactly-once 処理を使用することが推奨されます。単一の Kafka メッセージで使用することは可能ですが、パフォーマンスに大きな影響を与えることになります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1419
msgid "The consumed `KafkaRecordBatch` message is passed to the `KafkaTransactions#withTransactionAndAck` in order to handle the offset commits and message acks."
msgstr "消費された `KafkaRecordBatch` メッセージは、オフセットコミットとメッセージ ack を処理するために、`KafkaTransactions#withTransactionAndAck` に渡されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1422
msgid "The `send` method writes records to Kafka inside the transaction, without waiting for send receipt from the broker.  Messages pending to be written to Kafka will be buffered, and flushed before committing the transaction.  It is therefore recommended configuring the `@OnOverflow` `bufferSize` in order to fit enough messages, for example the `max.poll.records`, maximum amount of records returned in a batch."
msgstr "`send` メソッドは、ブローカーからの送信受信を待たずに、トランザクション内で Kafka にレコードを書き込みます。Kafka への書き込みが保留されているメッセージはバッファーリングされ、トランザクションをコミットする前にフラッシュされます。したがって、十分なメッセージ (たとえば、バッチで返されるレコードの最大量である `max.poll.records`) に適合するように、`@OnOverflow` `bufferSize` を設定することを推奨します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1424
msgid "If the processing completes successfully, _before committing the transaction_, the topic partition offsets of the given batch message will be committed to the transaction."
msgstr "_トランザクションをコミットする前に_ 処理が正常に完了すると、指定されたバッチメッセージのトピックパーティションオフセットがトランザクションにコミットされます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1425
msgid "If the processing needs to abort, _after aborting the transaction_, the consumer's position is reset to the last committed offset, effectively resuming the consumption from that offset. If no consumer offset has been committed to a topic-partition, the consumer's position is reset to the beginning of the topic-partition, _even if the offset reset policy is `latest`_."
msgstr "_トランザクションを中止した後に_ 、処理を中止する必要がある場合、コンシューマーの位置は最後にコミットされたオフセットにリセットされ、そのオフセットから消費を効果的に再開します。トピックパーティションにコンシューマーオフセットがコミットされていない場合は、_オフセットリセットポリシーが `latest` であっても_、コンシューマーの位置はトピックパーティションの先頭にリセットされます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1428
msgid "When using exactly-once processing, consumed message offset commits are handled by the transaction and therefore the application should not commit offsets through other means.  The consumer should have `enable.auto.commit=false` (the default) and set explicitly `commit-strategy=ignore`:"
msgstr "exactly-once 処理を使用する場合、消費されたメッセージオフセットコミットはトランザクションによって処理されるため、アプリケーションは他の方法でオフセットをコミットしてはいけません。コンシューマーには `enable.auto.commit=false` (デフォルト) があり、明示的に `commit-strategy=ignore` を設定する必要があります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1433
#, no-wrap
msgid ""
"mp.messaging.incoming.prices-in.commit-strategy=ignore\n"
"mp.messaging.incoming.prices-in.failure-strategy=ignore\n"
msgstr ""

#. type: Title ====
#: upstream/_versions/3.0/guides/kafka.adoc:1435
#, no-wrap
msgid "Error handling for the exactly-once processing"
msgstr "exactly-once 処理のエラー処理"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1439
msgid "The `Uni` returned from the `KafkaTransactions#withTransaction` will yield a failure if the transaction fails and is aborted.  The application can choose to handle the error case, but if a failing `Uni` is returned from the `@Incoming` method, the incoming channel will effectively fail and stop the reactive stream."
msgstr "`KafkaTransactions#withTransaction` から返された `Uni` は、トランザクションが失敗して中止された場合に失敗します。アプリケーションはエラーケースの処理を選択できますが、失敗した `Uni` が `@Incoming` メソッドから返された場合、着信チャネルは事実上失敗し、リアクティブストリームを停止します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1443
msgid "The `KafkaTransactions#withTransactionAndAck` method acks and nacks the message but will *not* return a failing `Uni`.  Nacked messages will be handled by the failure strategy of the incoming channel, (see <<error-handling>>).  Configuring `failure-strategy=ignore` simply resets the Kafka consumer to the last committed offsets and resumes the consumption from there."
msgstr "`KafkaTransactions#withTransactionAndAck` メソッドはメッセージを確認して nack しますが、失敗した `Uni` を *返しません* 。nack されたメッセージは、着信チャネルのエラーストラテジーによって処理されます (<<error-handling>> を参照)。`failure-strategy=ignore` を設定すると、Kafka コンシューマーは最後にコミットされたオフセットにリセットされ、そこから消費が再開されます。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:1446
#, no-wrap
msgid "Accessing Kafka clients directly"
msgstr "Kafka クライアントへの直接アクセス"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1450
msgid "In rare cases, you may need to access the underlying Kafka clients.  `KafkaClientService` provides thread-safe access to `Producer` and `Consumer`."
msgstr "まれに、基盤となる Kafka クライアントにアクセスしなければならない場合があります。`KafkaClientService` は、`Producer` と `Consumer` へのスレッドセーフなアクセスを提供します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1456
#, no-wrap
msgid ""
"import jakarta.enterprise.context.ApplicationScoped;\n"
"import jakarta.enterprise.event.Observes;\n"
"import jakarta.inject.Inject;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1458
#, no-wrap
msgid "import org.apache.kafka.clients.producer.ProducerRecord;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1463
#, no-wrap
msgid ""
"import io.quarkus.runtime.StartupEvent;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaClientService;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaConsumer;\n"
"import io.smallrye.reactive.messaging.kafka.KafkaProducer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1466
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class PriceSender {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1469
#, no-wrap
msgid ""
"    @Inject\n"
"    KafkaClientService clientService;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1476
#, no-wrap
msgid ""
"    void onStartup(@Observes StartupEvent startupEvent) {\n"
"        KafkaProducer<String, Double> producer = clientService.getProducer(\"generated-price\");\n"
"        producer.runOnSendingThread(client -> client.send(new ProducerRecord<>(\"prices\", 2.4)))\n"
"            .await().indefinitely();\n"
"    }\n"
"}\n"
msgstr ""

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:1481
msgid "The `KafkaClientService` is an experimental API and can change in the future."
msgstr "`KafkaClientService` は実験的な API であり、将来変更される可能性があります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1484
msgid "You can also get the Kafka configuration injected to your application and create Kafka producer, consumer and admin clients directly:"
msgstr "Kafka 設定をアプリケーションに注入して、Kafka プロデューサー、コンシューマー、および管理クライアントを直接作成することもできます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1491
#, no-wrap
msgid ""
"import io.smallrye.common.annotation.Identifier;\n"
"import org.apache.kafka.clients.admin.AdminClient;\n"
"import org.apache.kafka.clients.admin.AdminClientConfig;\n"
"import org.apache.kafka.clients.admin.KafkaAdminClient;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1497
#, no-wrap
msgid ""
"import jakarta.enterprise.context.ApplicationScoped;\n"
"import jakarta.enterprise.inject.Produces;\n"
"import jakarta.inject.Inject;\n"
"import java.util.HashMap;\n"
"import java.util.Map;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1500
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class KafkaClients {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1504
#, no-wrap
msgid ""
"    @Inject\n"
"    @Identifier(\"default-kafka-broker\")\n"
"    Map<String, Object> config;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1515
#, no-wrap
msgid ""
"    @Produces\n"
"    AdminClient getAdmin() {\n"
"        Map<String, Object> copy = new HashMap<>();\n"
"        for (Map.Entry<String, Object> entry : config.entrySet()) {\n"
"            if (AdminClientConfig.configNames().contains(entry.getKey())) {\n"
"                copy.put(entry.getKey(), entry.getValue());\n"
"            }\n"
"        }\n"
"        return KafkaAdminClient.create(copy);\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1522
msgid "The `default-kafka-broker` configuration map contains all application properties prefixed with `kafka.` or `KAFKA_`.  For more configuration options check out <<kafka-configuration-resolution>>."
msgstr "`default-kafka-broker` 設定マップには、接頭辞 `kafka.` または `KAFKA_` が付いたすべてのアプリケーションプロパティーが含まれています。設定オプションの詳細については、<<kafka-configuration-resolution>> を参照してください。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:1524
#, no-wrap
msgid "JSON serialization"
msgstr "JSON シリアライゼーション"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1527
msgid "Quarkus has built-in capabilities to deal with JSON Kafka messages."
msgstr "Quarkus には、JSON Kafka メッセージを扱う機能が組み込まれています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1529
msgid "Imagine we have a `Fruit` data class as follows:"
msgstr "以下のように `Fruit` のデータクラスがあると想像してみてください。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1533
#, no-wrap
msgid "public class Fruit {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1536
#, no-wrap
msgid ""
"    public String name;\n"
"    public int price;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1539
#, no-wrap
msgid ""
"    public Fruit() {\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1545
#, no-wrap
msgid ""
"    public Fruit(String name, int price) {\n"
"        this.name = name;\n"
"        this.price = price;\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1548
msgid "And we want to use it to receive messages from Kafka, make some price transformation, and send messages back to Kafka."
msgstr "そして、Kafka からメッセージを受信して、何らかの価格変換を行い、Kafka にメッセージを送り返すために使いたいと考えています。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1554
#, no-wrap
msgid ""
"import io.smallrye.reactive.messaging.annotations.Broadcast;\n"
"import org.eclipse.microprofile.reactive.messaging.Incoming;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1563
#, no-wrap
msgid ""
"/**\n"
"* A bean consuming data from the \"fruit-in\" channel and applying some price conversion.\n"
"* The result is pushed to the \"fruit-out\" channel.\n"
"*/\n"
"@ApplicationScoped\n"
"public class FruitProcessor {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1573
#, no-wrap
msgid ""
"    @Incoming(\"fruit-in\")\n"
"    @Outgoing(\"fruit-out\")\n"
"    @Broadcast\n"
"    public Fruit process(Fruit fruit) {\n"
"        fruit.price = fruit.price * CONVERSION_RATE;\n"
"        return fruit;\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1578
msgid "To do this, we will need to set up JSON serialization with Jackson or JSON-B."
msgstr "そのためには、Jackson や JSON-B で JSON シリアライゼーションを設定する必要があります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1580
msgid "With JSON serialization correctly configured, you can also use `Publisher<Fruit>` and `Emitter<Fruit>`."
msgstr "JSON シリアライゼーションが正しく設定されていれば、`Publisher<Fruit>` と `Emitter<Fruit>` も利用できます。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1582
#, no-wrap
msgid "Serializing via Jackson"
msgstr "Jackson を介したシリアライズ"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1587
msgid "Quarkus has built-in support for JSON serialization and deserialization based on Jackson.  It will also <<serialization-generation, generate>> the serializer and deserializer for you, so you do not have to configure anything.  When generation is disabled, you can use the provided `ObjectMapperSerializer` and `ObjectMapperDeserializer` as explained below."
msgstr "Quarkus には、Jackson に基づく JSON シリアライゼーションとデシリアライゼーションのサポートが組み込まれています。また、シリアライザーとデシリアライザーを <<serialization-generation, 生成>> してくれるため、何も設定する必要がありません。生成が無効になっている場合は、以下で説明するように、提供されている `ObjectMapperSerializer` および `ObjectMapperDeserializer` を使用することができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1590
msgid "There is an existing `ObjectMapperSerializer` that can be used to serialize all data objects via Jackson.  You may create an empty subclass if you want to use <<serialization-autodetection>>."
msgstr "Jackson を介してすべてのデータオブジェクトをシリアライズするために使用できる既存の `ObjectMapperSerializer` があります。<<serialization-autodetection>> を使用する場合は、空のサブクラスを作成することができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1594
msgid "By default, the `ObjectMapperSerializer` serializes null as the `\"null\"` String, this can be customized by setting the Kafka configuration property `json.serialize.null-as-null=true` which will serialize null as `null`.  This is handy when using a compacted topic, as `null` is used as a tombstone to know which messages delete during compaction phase."
msgstr "デフォルトでは、`ObjectMapperSerializer` は null を `\"null\"` 文字列としてシリアライズします。これは、null を `null` としてシリアライズする Kafka 設定プロパティー `json.serialize.null-as-null=true` を設定することでカスタマイズできます。これは、圧縮されたトピックを使用する場合に便利です。なぜなら、`null` は、圧縮フェーズで削除されるメッセージを知るためのトゥームストーンとし使用されるからです。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1597
msgid "The corresponding deserializer class needs to be subclassed.  So, let's create a `FruitDeserializer` that extends the `ObjectMapperDeserializer`."
msgstr "対応するデシリアライザークラスはサブクラス化する必要があります。そこで、`ObjectMapperDeserializer` を拡張する `FruitDeserializer` を作成しましょう。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1601
#: upstream/_versions/3.0/guides/kafka.adoc:1632
#, no-wrap
msgid "package com.acme.fruit.jackson;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1603
#: upstream/_versions/3.0/guides/kafka.adoc:2464
#: upstream/_versions/3.0/guides/kafka.adoc:2560
#, no-wrap
msgid "import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1609
#: upstream/_versions/3.0/guides/kafka.adoc:2470
#: upstream/_versions/3.0/guides/kafka.adoc:2566
#, no-wrap
msgid ""
"public class FruitDeserializer extends ObjectMapperDeserializer<Fruit> {\n"
"    public FruitDeserializer() {\n"
"        super(Fruit.class);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1612
msgid "Finally, configure your channels to use the Jackson serializer and deserializer."
msgstr "最後に、Jackson シリアライザーとデシリアライザーを使用するようにチャンネルを設定します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1618
#, no-wrap
msgid ""
"# Configure the Kafka source (we read from it)\n"
"mp.messaging.incoming.fruit-in.topic=fruit-in\n"
"mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jackson.FruitDeserializer\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1622
#, no-wrap
msgid ""
"# Configure the Kafka sink (we write to it)\n"
"mp.messaging.outgoing.fruit-out.topic=fruit-out\n"
"mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1626
msgid "Now, your Kafka messages will contain a Jackson serialized representation of your `Fruit` data object.  In this case, the `deserializer` configuration is not necessary as the <<serialization-autodetection>> is enabled by default."
msgstr "これで、Kafka メッセージには、`Fruit` データオブジェクトの Jackson シリアライズ表現が含まれます。この場合、<<serialization-autodetection>> がデフォルトで有効になっているので、`deserializer` の設定は必要ありません。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1628
msgid "If you want to deserialize a list of fruits, you need to create a deserializer with a Jackson `TypeReference` denoted the generic collection used."
msgstr "fruits のリストをデシリアライズしたい場合は、使用する一般的なコレクションを表す Jackson `TypeReference` を持つデシリアライザーを作成する必要があります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1636
#, no-wrap
msgid ""
"import java.util.List;\n"
"import com.fasterxml.jackson.core.type.TypeReference;\n"
"import io.quarkus.kafka.client.serialization.ObjectMapperDeserializer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1642
#, no-wrap
msgid ""
"public class ListOfFruitDeserializer extends ObjectMapperDeserializer<List<Fruit>> {\n"
"    public ListOfFruitDeserializer() {\n"
"        super(new TypeReference<List<Fruit>>() {});\n"
"    }\n"
"}\n"
msgstr ""

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1645
#, no-wrap
msgid "Serializing via JSON-B"
msgstr "JSON-B を介したシリアライズ"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1648
msgid "First, you need to include the `quarkus-jsonb` extension."
msgstr "まず、`quarkus-jsonb` エクステンションをインクルードする必要があります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1656
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-jsonb</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1662
#, no-wrap
msgid "implementation(\"io.quarkus:quarkus-jsonb\")\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1666
msgid "There is an existing `JsonbSerializer` that can be used to serialize all data objects via JSON-B.  You may create an empty subclass if you want to use <<serialization-autodetection>>."
msgstr "JSON-B を介してすべてのデータオブジェクトをシリアライズするために使用できる既存の `JsonbSerializer` があります。<<serialization-autodetection>> を使用する場合は、空のサブクラスを作成することができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1670
msgid "By default, the `JsonbSerializer` serializes null as the `\"null\"` String, this can be customized by setting the Kafka configuration property `json.serialize.null-as-null=true` which will serialize null as `null`.  This is handy when using a compacted topic, as `null` is used as a tombstone to know which messages delete during compaction phase."
msgstr "デフォルトでは、`JsonbSerializer` は null を `\"null\"` 文字列としてシリアライズします。これは、null を `null` としてシリアライズする Kafka 設定プロパティー `json.serialize.null-as-null=true` を設定することでカスタマイズできます。これは、圧縮されたトピックを使用する場合に便利です。なぜなら、`null` は、圧縮フェーズで削除されるメッセージを知るためのトゥームストーンとし使用されるからです。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1673
msgid "The corresponding deserializer class needs to be subclassed.  So, let's create a `FruitDeserializer` that extends the generic `JsonbDeserializer`."
msgstr "対応するデシリアライザークラスはサブクラス化する必要があります。そこで、一般的な `JsonbDeserializer` を拡張する `FruitDeserializer` を作成しましょう。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1677
#, no-wrap
msgid "package com.acme.fruit.jsonb;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1679
#, no-wrap
msgid "import io.quarkus.kafka.client.serialization.JsonbDeserializer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1685
#, no-wrap
msgid ""
"public class FruitDeserializer extends JsonbDeserializer<Fruit> {\n"
"    public FruitDeserializer() {\n"
"        super(Fruit.class);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1688
msgid "Finally, configure your channels to use the JSON-B serializer and deserializer."
msgstr "最後に、JSON-B シリアライザーとデシリアライザーを使用するようにチャネルを設定します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1695
#, no-wrap
msgid ""
"# Configure the Kafka source (we read from it)\n"
"mp.messaging.incoming.fruit-in.connector=smallrye-kafka\n"
"mp.messaging.incoming.fruit-in.topic=fruit-in\n"
"mp.messaging.incoming.fruit-in.value.deserializer=com.acme.fruit.jsonb.FruitDeserializer\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1700
#, no-wrap
msgid ""
"# Configure the Kafka sink (we write to it)\n"
"mp.messaging.outgoing.fruit-out.connector=smallrye-kafka\n"
"mp.messaging.outgoing.fruit-out.topic=fruit-out\n"
"mp.messaging.outgoing.fruit-out.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1703
msgid "Now, your Kafka messages will contain a JSON-B serialized representation of your `Fruit` data object."
msgstr "これで、Kafka のメッセージには、JSON-B でシリアライズされた `Fruit` データオブジェクトの表現が含まれます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1705
msgid "If you want to deserialize a list of fruits, you need to create a deserializer with a `Type` denoted the generic collection used."
msgstr "fruits のリストをデシリアライズしたい場合は、使用する一般的なコレクションを表す `Type` を持つデシリアライザーを作成する必要があります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1713
#, no-wrap
msgid ""
"package com.acme.fruit.jsonb;\n"
"import java.lang.reflect.Type;\n"
"import java.util.ArrayList;\n"
"import java.util.List;\n"
"import io.quarkus.kafka.client.serialization.JsonbDeserializer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1719
#, no-wrap
msgid ""
"public class ListOfFruitDeserializer extends JsonbDeserializer<List<Fruit>> {\n"
"    public ListOfFruitDeserializer() {\n"
"        super(new ArrayList<MyEntity>() {}.getClass().getGenericSuperclass());\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1723
msgid "If you don't want to create a deserializer for each data object, you can use the generic `io.vertx.kafka.client.serialization.JsonObjectDeserializer` that will deserialize to a `io.vertx.core.json.JsonObject`. The corresponding serializer can also be used: `io.vertx.kafka.client.serialization.JsonObjectSerializer`."
msgstr "各データオブジェクトにデシリアライザーを作成したくない場合は、`io.vertx.core.json.JsonObject` にデシリアライズする汎用の `io.vertx.kafka.client.serialization.JsonObjectDeserializer` を使用することができます。対応するシリアライザーの `io.vertx.kafka.client.serialization.JsonObjectSerializer` も使用できます。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:1724
#, no-wrap
msgid "Avro Serialization"
msgstr "Avro シリアライゼーション"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1727
#: upstream/_versions/3.0/guides/kafka.adoc:1821
msgid "This is described in a dedicated guide: xref:kafka-schema-registry-avro.adoc[Using Apache Kafka with Schema Registry and Avro]."
msgstr "これは、専用ガイド xref:kafka-schema-registry-avro.adoc[Schema RegistryとAvroと共にApache Kafkaを使用] で説明されています。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:1729
#, no-wrap
msgid "Serializer/deserializer autodetection"
msgstr "シリアライザー/デシリアライザーの自動検出"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1733
msgid "When using SmallRye Reactive Messaging with Kafka (`io.quarkus:quarkus-smallrye-reactive-messaging-kafka`), Quarkus can often automatically detect the correct serializer and deserializer class.  This autodetection is based on declarations of `@Incoming` and `@Outgoing` methods, as well as injected ``@Channel``s."
msgstr "SmallRye Reactive Messaging で Kafka (`io.quarkus:quarkus-smallrye-reactive-messaging-kafka`) を使用するときに、Quarkus は多くの場合、正しいシリアライザーとデシリアライザーのクラスを自動的に検出することができます。この自動検出は、`@Incoming` メソッドと `@Outgoing` メソッドの宣言、および注入された ``@Channel`` に基づいています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1735
msgid "For example, if you declare"
msgstr "たとえば、以下のように宣言した場合"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1742
#, no-wrap
msgid ""
"@Outgoing(\"generated-price\")\n"
"public Multi<Integer> generate() {\n"
"    ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1745
msgid "and your configuration indicates that the `generated-price` channel uses the `smallrye-kafka` connector, then Quarkus will automatically set the `value.serializer` to Kafka's built-in `IntegerSerializer`."
msgstr "設定において `generated-price` チャネルが `smallrye-kafka` コネクターを使用することを示している場合、Quarkus は自動的に `value.serializer` を Kafka の組み込みの `IntegerSerializer` に設定します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1747
msgid "Similarly, if you declare"
msgstr "同様に、以下を宣言した場合"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1754
#, no-wrap
msgid ""
"@Incoming(\"my-kafka-records\")\n"
"public void consume(KafkaRecord<Long, byte[]> record) {\n"
"    ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1757
msgid "and your configuration indicates that the `my-kafka-records` channel uses the `smallrye-kafka` connector, then Quarkus will automatically set the `key.deserializer` to Kafka's built-in `LongDeserializer`, as well as the `value.deserializer` to `ByteArrayDeserializer`."
msgstr "設定において `my-kafka-records` チャネルが `smallrye-kafka` コネクターを使用することを示している場合、Quarkus は自動的に `key.deserializer` を Kafka の組み込み `LongDeserializer` に設定し、同様に `value.deserializer` を `ByteArrayDeserializer` に設定します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1759
msgid "Finally, if you declare"
msgstr "最後に、以下を宣言した場合"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1765
#, no-wrap
msgid ""
"@Inject\n"
"@Channel(\"price-create\")\n"
"Emitter<Double> priceEmitter;\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1768
msgid "and your configuration indicates that the `price-create` channel uses the `smallrye-kafka` connector, then Quarkus will automatically set the `value.serializer` to Kafka's built-in `DoubleSerializer`."
msgstr "設定において `price-create` チャネルが `smallrye-kafka` コネクターを使用することを示している場合、Quarkus は自動的に `value.serializer` を Kafka の組み込みの `DoubleSerializer` に設定します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1770
msgid "The full set of types supported by the serializer/deserializer autodetection is:"
msgstr "シリアライザー/デシリアライザーの自動検出でサポートされるタイプの完全なセットは以下のとおりです。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1772
msgid "`short` and `java.lang.Short`"
msgstr "`short` および `java.lang.Short`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1773
msgid "`int` and `java.lang.Integer`"
msgstr "`int` および `java.lang.Integer`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1774
msgid "`long` and `java.lang.Long`"
msgstr "`long` および `java.lang.Long`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1775
msgid "`float` and `java.lang.Float`"
msgstr "`float` および `java.lang.Float`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1776
msgid "`double` and `java.lang.Double`"
msgstr "`double` および`java.lang.Double`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1777
msgid "`byte[]`"
msgstr "`byte[]`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1778
msgid "`java.lang.String`"
msgstr "`java.lang.String`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1779
msgid "`java.util.UUID`"
msgstr "`java.util.UUID`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1780
msgid "`java.nio.ByteBuffer`"
msgstr "`java.nio.ByteBuffer`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1781
msgid "`org.apache.kafka.common.utils.Bytes`"
msgstr "`org.apache.kafka.common.utils.Bytes`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1782
msgid "`io.vertx.core.buffer.Buffer`"
msgstr "`io.vertx.core.buffer.Buffer`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1783
msgid "`io.vertx.core.json.JsonObject`"
msgstr "`io.vertx.core.json.JsonObject`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1784
msgid "`io.vertx.core.json.JsonArray`"
msgstr "`io.vertx.core.json.JsonArray`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1785
msgid "classes for which a direct implementation of `org.apache.kafka.common.serialization.Serializer<T>` / `org.apache.kafka.common.serialization.Deserializer<T>` is present."
msgstr "`org.apache.kafka.common.serialization.Serializer<T>` / `org.apache.kafka.common.serialization.Deserializer<T>` の直接実装があるクラス。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1786
msgid "the implementation needs to specify the type argument `T` as the (de-)serialized type."
msgstr "この実装は、タイプ引数 `T` を (デ) シリアライズタイプとして指定する必要があります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1787
msgid "classes generated from Avro schemas, as well as Avro `GenericRecord`, if Confluent or Apicurio Registry _serde_ is present"
msgstr "Confluent または Apicurio Registry _serde_ が存在する場合、Avro スキーマから生成されるクラスと Avro `GenericRecord` から生成されるクラス"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1788
msgid "in case multiple Avro serdes are present, serializer/deserializer must be configured manually for Avro-generated classes, because autodetection is impossible"
msgstr "複数の Avro serde が存在する場合、自動検出は使用できないため、Avro が生成するクラスに対してシリアライザー/デシリアライザーを手動で設定する必要があります"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1789
msgid "see xref:kafka-schema-registry-avro.adoc[Using Apache Kafka with Schema Registry and Avro] for more information about using Confluent or Apicurio Registry libraries"
msgstr "Confluent または Apicurio Registry ライブラリーの使用に関する詳細は、 xref:kafka-schema-registry-avro.adoc[Schema RegistryとAvroと共にApache Kafkaを使用] を参照してください"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1790
msgid "classes for which a subclass of `ObjectMapperSerializer` / `ObjectMapperDeserializer` is present, as described in <<jackson-serialization>>"
msgstr "<<jackson-serialization>> で説明されているように、`ObjectMapperSerializer` / `ObjectMapperDeserializer` のサブクラスが存在するクラス"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1791
msgid "it is technically not needed to subclass `ObjectMapperSerializer`, but in such case, autodetection isn't possible"
msgstr "技術的には `ObjectMapperSerializer` をサブクラスにする必要はありませんが、その場合は自動検出ができません"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1792
msgid "classes for which a subclass of `JsonbSerializer` / `JsonbDeserializer` is present, as described in <<jsonb-serialization>>"
msgstr "<<jsonb-serialization>> で説明されているように、`JsonbSerializer` / `JsonbDeserializer` のサブクラスが存在するクラス"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1793
msgid "it is technically not needed to subclass `JsonbSerializer`, but in such case, autodetection isn't possible"
msgstr "技術的には `JsonbSerializer` をサブクラスにする必要はありませんが、その場合は自動検出ができません"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1795
msgid "If a serializer/deserializer is set by configuration, it won't be replaced by the autodetection."
msgstr "シリアライザー/デシリアライザーが設定されている場合、自動検出によって置き換えられることはありません。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1798
msgid "In case you have any issues with serializer autodetection, you can switch it off completely by setting `quarkus.reactive-messaging.kafka.serializer-autodetection.enabled=false`.  If you find you need to do this, please file a bug in the link:https://github.com/quarkusio/quarkus/issues[Quarkus issue tracker] so we can fix whatever problem you have."
msgstr "シリアライザーの自動検出に問題がある場合は、`quarkus.reactive-messaging.kafka.serializer-autodetection.enabled=false` を設定することで、これを完全にオフにすることができます。オフにする必要があると認識した場合は、link:https://github.com/quarkusio/quarkus/issues[Quarkus issue tracker] にバグを報告していただければ、どのような問題でも修正することができます。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:1800
#, no-wrap
msgid "JSON Serializer/deserializer generation"
msgstr "JSON シリアライザー/デシリアライザーの生成"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1802
msgid "Quarkus automatically generates serializers and deserializers for channels where:"
msgstr "Quarkus は、以下の場合のチャネルのシリアライザーおよびデシリアライザーを自動的に生成します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1804
msgid "the serializer/deserializer is not configured"
msgstr "シリアライザー/デシリアライザーが設定されていない場合"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1805
msgid "the auto-detection did not find a matching serializer/deserializer"
msgstr "自動検出が、一致するシリアライザー/デシリアライザーを見つけられなかった場合"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1807
msgid "It uses Jackson underneath."
msgstr "これは、水面下で Jackson を使用しています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1809
msgid "This generation can be disabled using:"
msgstr "この生成を無効にするには、以下を使用します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1813
#, no-wrap
msgid "quarkus.reactive-messaging.kafka.serializer-generation.enabled=false\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1817
msgid "Generation does not support collections such as `List<Fruit>`.  Refer to <<jackson-serialization>> to write your own serializer/deserializer for this case."
msgstr "生成は `List<Fruit>` などのコレクションをサポートしません。このケースでは、<<jackson-serialization>> を参照して、独自のシリアライザー/デシリアライザーを作成してください。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:1818
#, no-wrap
msgid "Using Schema Registry"
msgstr "スキーマレジストリーの使用"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:1823
#, no-wrap
msgid "Health Checks"
msgstr "ヘルスチェック"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1827
msgid "Quarkus provides several health checks for Kafka.  These checks are used in combination with the `quarkus-smallrye-health` extension."
msgstr "Quarkusは、Kafkaのヘルスチェックをいくつか提供しています。これらのチェックは、 `quarkus-smallrye-health` エクステンションと組み合わせて使用します。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1828
#, no-wrap
msgid "Kafka Broker Readiness Check"
msgstr "Kafka ブローカー rediness チェック"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1833
msgid "When using the `quarkus-kafka-client` extension, you can enable _readiness_ health check by setting the `quarkus.kafka.health.enabled` property to `true` in your `application.properties`.  This check reports the status of the interaction with a _default_ Kafka broker (configured using `kafka.bootstrap.servers`).  It requires an _admin connection_ with the Kafka broker, and it is disabled by default.  If enabled, when you access the `/q/health/ready` endpoint of your application, you will have information about the connection validation status."
msgstr "`quarkus-kafka-client` エクステンションを使用している場合、`application.properties` で `quarkus.kafka.health.enabled` プロパティーを `true` に設定することで、_readiness_ ヘルスチェックを有効にすることができます。このチェックでは、_default_ Kafka ブローカー (`kafka.bootstrap.servers` を使用して設定) とのインタラクションのステータスが報告されます。これには Kafka ブローカーとの _admin connection_ が必要ですが、これはデフォルトでは無効になっています。有効にすると、アプリケーションの `/q/health/ready` エンドポイントにアクセスしたときに、接続検証のステータスに関する情報が得られます。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1834
#, no-wrap
msgid "Kafka Reactive Messaging Health Checks"
msgstr "Kafka Reactive Messaging ヘルスチェック"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1836
msgid "When using Reactive Messaging and the Kafka connector, each configured channel (incoming or outgoing) provides _startup_, _liveness_ and _readiness_ checks."
msgstr "Reactive Messaging と Kafka コネクターを使用する場合、設定済みの各チャンネル（着信または送信）は、_startup_、_liveness_、および _readiness_ チェックを提供します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1838
msgid "The _startup_ check verifies that the communication with Kafka cluster is established."
msgstr "_startup_ check は、Kafka クラスターとの通信が確立されていることを確認します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1839
msgid "The _liveness_ check captures any unrecoverable failure happening during the communication with Kafka."
msgstr "_liveness_ チェックは、Kafka との通信中に発生する回復不可能なエラーをキャプチャーします。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1840
msgid "The _readiness_ check verifies that the Kafka connector is ready to consume/produce messages to the configured Kafka topics."
msgstr "_readiness_ チェックは、Kafka コネクターが設定済みの Kafka トピックに対してメッセージを消費/生成する準備ができていることを確認します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1842
msgid "For each channel, you can disable the checks using:"
msgstr "チャネルごとに、以下を使用してチェックを無効にできます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1846
#, no-wrap
msgid "# Disable both liveness and readiness checks with `health-enabled=false`:\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1851
#, no-wrap
msgid ""
"# Incoming channel (receiving records form Kafka)\n"
"mp.messaging.incoming.your-channel.health-enabled=false\n"
"# Outgoing channel (writing records to Kafka)\n"
"mp.messaging.outgoing.your-channel.health-enabled=false\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1853
#, no-wrap
msgid "# Disable only the readiness check with `health-readiness-enabled=false`:\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1856
#, no-wrap
msgid ""
"mp.messaging.incoming.your-channel.health-readiness-enabled=false\n"
"mp.messaging.outgoing.your-channel.health-readiness-enabled=false\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1860
msgid "You can configure the `bootstrap.servers` for each channel using `mp.messaging.incoming|outgoing.$channel.bootstrap.servers` property.  Default is `kafka.bootstrap.servers`."
msgstr "`mp.messaging.incoming|outgoing.$channel.bootstrap.servers` プロパティーを使用して、各チャンネルに `bootstrap.servers` を設定できます。デフォルトは `kafka.bootstrap.servers` です。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1864
msgid "Reactive Messaging _startup_ and _readiness_ checks offer two strategies.  The default strategy verifies that an active connection is established with the broker.  This approach is not intrusive as it's based on built-in Kafka client metrics."
msgstr "Reactive Messaging の _startup_ および _readiness_ チェックには、2 つのストラテジーがあります。デフォルトのストラテジーでは、ブローカーとの間にアクティブな接続が確立されていることを確認します。この方法は、組み込みの Kafka クライアントメトリクスに基づいているため、邪魔になることはありません。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1868
msgid "Using the `health-topic-verification-enabled=true` attribute, _startup_ probe uses an _admin client_ to check for the list of topics.  Whereas the _readiness_ probe for an incoming channel checks that at least one partition is assigned for consumption, and for an outgoing channel checks that the topic used by the producer exist in the broker."
msgstr "`health-topic-verification-enabled=true` 属性を使用すると、_startup_ プローブは _admin client_ を使用してトピックのリストをチェックします。_readiness_ プローブの場合、受信チャンネル用は、少なくとも 1 つのパーティションが消費のために割り当てられていることをチェックし、送信チャンネル用は、プロデューサーが使用するトピックがブローカーに存在していることをチェックします。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1871
msgid "Note that to achieve this, an _admin connection_ is required.  You can adjust the timeout for topic verification calls to the broker using the `health-topic-verification-timeout` configuration."
msgstr "これを行うには、_admin connection_ が必要です。`health-topic-verification-timeout` 設定を使用して、ブローカーへのトピック検証呼び出しのタイムアウトを調整することができます。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:1872
#, no-wrap
msgid "Kafka Streams"
msgstr "Kafka Streams"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1875
msgid "This is described in a dedicated guide: xref:kafka-streams.adoc[Using Apache Kafka Streams]."
msgstr "詳細は、専用ガイドの xref:kafka-streams.adoc[Apache Kafka Streamsの使用] で説明されています。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:1876
#, no-wrap
msgid "Using Snappy for message compression"
msgstr "メッセージ圧縮での Snappy の使用"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1879
msgid "On _outgoing_ channels, you can enable Snappy compression by setting the `compression.type` attribute to `snappy`:"
msgstr "_outgoing_ チャンネルでは、 `compression.type` 属性を `snappy` に設定することで、Snappy 圧縮を有効にすることができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1883
#, no-wrap
msgid "mp.messaging.outgoing.fruit-out.compression.type=snappy\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1887
msgid "In JVM mode, it will work out of the box.  However, to compile your application to a native executable, you need to:"
msgstr "JVMモードでは、変更なしで動作します。しかし、アプリケーションをネイティブ実行可能ファイルにコンパイルするには、以下が必要です。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1889
msgid "Uses GraalVM 21.+"
msgstr "GraalVM 21.+ を使用している"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1890
msgid "Add `quarkus.kafka.snappy.enabled=true` to your `application.properties`"
msgstr "`application.properties` に `quarkus.kafka.snappy.enabled=true` を追加している"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1892
msgid "In native mode, Snappy is disabled by default as the use of Snappy requires embedding a native library and unpacking it when the application starts."
msgstr "ネイティブモードでは、Snappyはデフォルトで無効になっています。Snappyを使用するには、ネイティブライブラリを埋め込み、アプリケーションの起動時にそれを展開する必要があるからです。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:1893
#, no-wrap
msgid "Authentication with OAuth"
msgstr "OAuth を使用した認証"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1897
msgid "If your Kafka broker uses OAuth as authentication mechanism, you need to configure the Kafka consumer to enable this authentication process.  First, add the following dependency to your application:"
msgstr "Kafka ブローカーが認証メカニズムとして OAuth を使用している場合は、この認証プロセスを有効にするために Kafka コンシューマーを設定する必要があります。まず、以下の依存関係をアプリケーションに追加します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1905
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.strimzi</groupId>\n"
"    <artifactId>kafka-oauth-client</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1911
#, no-wrap
msgid "implementation(\"io.strimzi:kafka-oauth-client\")\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1915
msgid "This dependency provides the callback handler required to handle the OAuth workflow.  Then, in the `application.properties`, add:"
msgstr "この依存関係は、OAuth ワークフローを処理するために必要なコールバックハンドラーを提供します。そして、`application.properties` で追加します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1925
#, no-wrap
msgid ""
"mp.messaging.connector.smallrye-kafka.security.protocol=SASL_PLAINTEXT\n"
"mp.messaging.connector.smallrye-kafka.sasl.mechanism=OAUTHBEARER\n"
"mp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \\\n"
"  oauth.client.id=\"team-a-client\" \\\n"
"  oauth.client.secret=\"team-a-client-secret\" \\\n"
"  oauth.token.endpoint.uri=\"http://keycloak:8080/auth/realms/kafka-authz/protocol/openid-connect/token\" ;\n"
"mp.messaging.connector.smallrye-kafka.sasl.login.callback.handler.class=io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1927
#, no-wrap
msgid "quarkus.ssl.native=true\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1930
msgid "Update the `oauth.client.id`, `oauth.client.secret` and `oauth.token.endpoint.uri` values."
msgstr "`oauth.client.id`、`oauth.client.secret`、`oauth.token.endpoint.uri` の値を更新します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1932
msgid "OAuth authentication works for both JVM and native modes. Since SSL in not enabled by default in native mode, `quarkus.ssl.native=true` must be added to support JaasClientOauthLoginCallbackHandler, which uses SSL. (See the xref:native-and-ssl.adoc[Using SSL with Native Executables] guide for more details.)"
msgstr "OAuth 認証は、JVM とネイティブモードの両方で動作します。SSL はネイティブモードでデフォルトで有効になっていないため、SSL を使用する JaasClientOauthLoginCallbackHandler をサポートするために、`quarkus.ssl.native=true` を追加する必要があります（詳細は、xref:native-and-ssl.adoc[ネイティブイメージでのSSLの利用] ガイドを参照）。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:1933
#, no-wrap
msgid "Testing a Kafka application"
msgstr "Kafka アプリケーションのテスト"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:1935
#, no-wrap
msgid "Testing without a broker"
msgstr "ブローカーなしでのテスト"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1939
msgid "It can be useful to test the application without having to start a Kafka broker.  To achieve this, you can _switch_ the channels managed by the Kafka connector to _in-memory_."
msgstr "Kafka ブローカーを起動しなくてもアプリケーションをテストできるのは便利です。これを行うには、Kafka コネクターで管理しているチャンネルを _インメモリー_ に _切り替え_ できます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1941
msgid "This approach only works for JVM tests. It cannot be used for native tests (because they do not support injection)."
msgstr "このアプローチは、JVM テストでのみ機能します。インジェクションには対応していないため、ネイティブテストには使用できません。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1943
msgid "Let's say we want to test the following processor application:"
msgstr "以下のプロセッサーアプリケーションをテストするとします。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1948
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class BeverageProcessor {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1960
#, no-wrap
msgid ""
"    @Incoming(\"orders\")\n"
"    @Outgoing(\"beverages\")\n"
"    Beverage process(Order order) {\n"
"        System.out.println(\"Order received \" + order.getProduct());\n"
"        Beverage beverage = new Beverage();\n"
"        beverage.setBeverage(order.getProduct());\n"
"        beverage.setCustomer(order.getCustomer());\n"
"        beverage.setOrderId(order.getOrderId());\n"
"        beverage.setPreparationState(\"RECEIVED\");\n"
"        return beverage;\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1965
msgid "First, add the following test dependency to your application:"
msgstr "まず、以下のテスト依存関係をアプリケーションに追加します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1974
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.smallrye.reactive</groupId>\n"
"    <artifactId>smallrye-reactive-messaging-in-memory</artifactId>\n"
"    <scope>test</scope>\n"
"</dependency>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1980
#, no-wrap
msgid "testImplementation(\"io.smallrye.reactive:smallrye-reactive-messaging-in-memory\")\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:1983
msgid "Then, create a Quarkus Test Resource as follows:"
msgstr "そして、以下のように Quarkus Test Resource を作成します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1987
#, no-wrap
msgid "public class KafkaTestResourceLifecycleManager implements QuarkusTestResourceLifecycleManager {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:1997
#, no-wrap
msgid ""
"    @Override\n"
"    public Map<String, String> start() {\n"
"        Map<String, String> env = new HashMap<>();\n"
"        Map<String, String> props1 = InMemoryConnector.switchIncomingChannelsToInMemory(\"orders\");     // <1>\n"
"        Map<String, String> props2 = InMemoryConnector.switchOutgoingChannelsToInMemory(\"beverages\");  // <2>\n"
"        env.putAll(props1);\n"
"        env.putAll(props2);\n"
"        return env;  // <3>\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2003
#, no-wrap
msgid ""
"    @Override\n"
"    public void stop() {\n"
"        InMemoryConnector.clear();  // <4>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2005
msgid "Switch the incoming channel `orders` (expecting messages from Kafka) to in-memory."
msgstr "(Kafka からのメッセージが想定される) 受信チャンネル `orders` をインメモリーに切り替えます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2006
msgid "Switch the outgoing channel `beverages` (writing messages to Kafka) to in-memory."
msgstr "(Kafka へのメッセージを書き込む) 送信チャネル `beverages` をインメモリーに切り替えます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2007
msgid "Builds and returns a `Map` containing all the properties required to configure the application to use in-memory channels."
msgstr "インメモリーチャネルを使用するためのアプリケーション設定に必要なすべてのプロパティを含む `Map` をビルドして返します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2008
msgid "When the test stops, clear the `InMemoryConnector` (discard all the received and sent messages)"
msgstr "テストが停止したら、`InMemoryConnector` をクリアします (受信したメッセージと送信したメッセージをすべて破棄してください)。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2010
msgid "Create a Quarkus Test using the test resource created above:"
msgstr "上記で作成したテストリソースを使用して Quarkus テストを作成します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2016
#, no-wrap
msgid ""
"@QuarkusTest\n"
"@QuarkusTestResource(KafkaTestResourceLifecycleManager.class)\n"
"class BaristaTest {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2019
#, no-wrap
msgid ""
"    @Inject\n"
"    InMemoryConnector connector; // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2024
#, no-wrap
msgid ""
"    @Test\n"
"    void testProcessOrder() {\n"
"        InMemorySource<Order> ordersIn = connector.source(\"orders\");     // <2>\n"
"        InMemorySink<Beverage> beveragesOut = connector.sink(\"beverages\");  // <3>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2029
#, no-wrap
msgid ""
"        Order order = new Order();\n"
"        order.setProduct(\"coffee\");\n"
"        order.setName(\"Coffee lover\");\n"
"        order.setOrderId(\"1234\");\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2031
#, no-wrap
msgid "        ordersIn.send(order);  // <4>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2033
#, no-wrap
msgid "        await().<List<? extends Message<Beverage>>>until(beveragesOut::received, t -> t.size() == 1); // <5>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2040
#, no-wrap
msgid ""
"        Beverage queuedBeverage = beveragesOut.received().get(0).getPayload();\n"
"        Assertions.assertEquals(Beverage.State.READY, queuedBeverage.getPreparationState());\n"
"        Assertions.assertEquals(\"coffee\", queuedBeverage.getBeverage());\n"
"        Assertions.assertEquals(\"Coffee lover\", queuedBeverage.getCustomer());\n"
"        Assertions.assertEquals(\"1234\", queuedBeverage.getOrderId());\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2044
msgid "Inject the in-memory connector in your test class."
msgstr "テストクラスにインメモリーコネクタ－を注入します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2045
msgid "Retrieve the incoming channel (`orders`) - the channel must have been switched to in-memory in the test resource."
msgstr "受信チャンネルを取得します (`orders`) - テストリソース内でチャンネルがインメモリーに切り替えられている必要があります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2046
msgid "Retrieve the outgoing channel (`beverages`) - the channel must have been switched to in-memory in the test resource."
msgstr "送信チャネルを取得します (`beverages`) - テストリソース内でチャネルがインメモリーに切り替えられている必要があります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2048
msgid "Use the `send` method to send a message to the `orders` channel.  The application will process this message and send a message to `beverages` channel."
msgstr "`send` メソッドを使用して、`orders` チャンネルにメッセージを送信します。アプリケーションはこのメッセージを処理し、`beverages` チャンネルにメッセージを送信します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2049
msgid "Use the `received` method on `beverages` channel to check the messages produced by the application."
msgstr "`beverages` チャンネルで `received` メソッドを使用して、アプリケーションによって生成されたメッセージを確認します。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:2054
msgid "With in-memory channels we were able to test application code processing messages without starting a Kafka broker.  Note that different in-memory channels are independent, and switching channel connector to in-memory does not simulate message delivery between channels configured to the same Kafka topic."
msgstr "インメモリーチャネルを使用すると、Kafka ブローカーを開始せずにメッセージ処理のアプリケーションコードをテストできました。異なるインメモリーチャネルは独立しており、チャネルコネクターをインメモリーに切り替えても、同じ Kafka トピックに設定されたチャネル間でメッセージ配信をシミュレートしないことに注意してください。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:2056
#, no-wrap
msgid "Testing using a Kafka broker"
msgstr "Kafka ブローカーを使用したテスト"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2061
msgid "If you are using <<kafka-dev-services>>, a Kafka broker will be started and available throughout the tests, unless it is disabled in `%test` profile.  While it is possible to connect to this broker using Kafka Clients API, https://smallrye.io/smallrye-reactive-messaging/latest/kafka/test-companion/[Kafka Companion Library] proposes an easier way of interacting with a Kafka broker and, creating consumer, producer and admin actions inside tests."
msgstr "<<kafka-dev-services>> を使用している場合、`%test` プロファイルで無効になっていない限り、Kafka ブローカーが起動し、テスト全体で利用することができます。Kafka Clients API を使用してこのブローカーに接続することは可能ですが、 https://smallrye.io/smallrye-reactive-messaging/latest/kafka/test-companion/[Kafka Companion Library] では、Kafka ブローカーと対話し、テスト内でコンシューマー、プロデューサー、および管理アクションを作成する簡単な方法を提案しています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2063
msgid "For using `KafkaCompanion` API in tests, start by adding the following dependency:"
msgstr "テストで `KafkaCompanion` API を使用するには、以下の依存関係を追加して開始します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2071
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-test-kafka-companion</artifactId>\n"
"    <scope>test</scope>\n"
"</dependency>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2074
msgid "which provides `io.quarkus.test.kafka.KafkaCompanionResource` - an implementation of `io.quarkus.test.common.QuarkusTestResourceLifecycleManager`."
msgstr "これは、`io.quarkus.test.kafka.KafkaCompanionResource` (`io.quarkus.test.common.QuarkusTestResourceLifecycleManager` の実装) を提供します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2076
msgid "Then use `@QuarkusTestResource` to configure the Kafka Companion in tests, for example:"
msgstr "次に、`@QuarkusTestResource` を使用して、テストで Kafka Companion を設定します。以下に例を示します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2080
#, no-wrap
msgid "import static org.junit.jupiter.api.Assertions.assertEquals;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2082
#, no-wrap
msgid "import java.util.UUID;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2085
#, no-wrap
msgid ""
"import org.apache.kafka.clients.producer.ProducerRecord;\n"
"import org.junit.jupiter.api.Test;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2092
#, no-wrap
msgid ""
"import io.quarkus.test.common.QuarkusTestResource;\n"
"import io.quarkus.test.junit.QuarkusTest;\n"
"import io.quarkus.test.kafka.InjectKafkaCompanion;\n"
"import io.quarkus.test.kafka.KafkaCompanionResource;\n"
"import io.smallrye.reactive.messaging.kafka.companion.ConsumerTask;\n"
"import io.smallrye.reactive.messaging.kafka.companion.KafkaCompanion;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2096
#, no-wrap
msgid ""
"@QuarkusTest\n"
"@QuarkusTestResource(KafkaCompanionResource.class)\n"
"public class OrderProcessorTest {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2099
#, no-wrap
msgid ""
"    @InjectKafkaCompanion // <1>\n"
"    KafkaCompanion companion;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2103
#, no-wrap
msgid ""
"    @Test\n"
"    void testProcessor() {\n"
"        companion.produceStrings().usingGenerator(i -> new ProducerRecord<>(\"orders\", UUID.randomUUID().toString())); // <2>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2105
#, no-wrap
msgid "        // Expect that the tested application processes orders from 'orders' topic and write to 'orders-processed' topic\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2111
#, no-wrap
msgid ""
"        ConsumerTask<String, String> orders = companion.consumeStrings().fromTopics(\"orders-processed\", 10); // <3>\n"
"        orders.awaitCompletion(); // <4>\n"
"        assertEquals(10, orders.count());\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2114
msgid "`@InjectKafkaCompanion` injects the `KafkaCompanion` instance, configured to access the Kafka broker created for tests."
msgstr "`@InjectKafkaCompanion` は、テスト用に作成された Kafka ブローカーにアクセスするように設定された `KafkaCompanion` インスタンスを注入します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2115
msgid "Use `KafkaCompanion` to create producer task which writes 10 records to 'orders' topic."
msgstr "`KafkaCompanion` を使用して、10 のレコードを 'orders' トピックに書き込むプロデューサータスクを作成します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2116
msgid "Create consumer task which subscribes to 'orders-processed' topic and consumes 10 records."
msgstr "'orders-processed' トピックをサブスクライブし、10 のレコードを消費するコンシューマータスクを作成します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2117
msgid "Await completion of the consumer task."
msgstr "コンシューマタスクの完了を待ちます。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:2121
msgid "If the Kafka Dev Service is available during tests, `KafkaCompanionResource` uses the created Kafka broker, otherwise it creates a Kafka broker using https://github.com/strimzi/test-container[Strimzi Test Container]."
msgstr "テスト中に Kafka Dev Service が利用可能な場合、`KafkaCompanionResource` は作成された Kafka ブローカーを使用します。そうでない場合は、 https://github.com/strimzi/test-container[Strimzi Test Container] を使用して Kafka ブローカーを作成します。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:2123
msgid "The configuration of the created Kafka broker can be customized using `@ResourceArg`, for example:"
msgstr "作成された Kafka ブローカーの設定は、`@ResourceArg` を使用してカスタマイズすることができます。以下に例を示します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2134
#, no-wrap
msgid ""
"@QuarkusTestResource(value = KafkaCompanionResource.class, initArgs = {\n"
"        @ResourceArg(name = \"strimzi.kafka.image\", value = \"quay.io/strimzi/kafka:0.28.0-kafka-3.0.0\"), // Image name\n"
"        @ResourceArg(name = \"kafka.port\", value = \"9092\"), // Fixed port for kafka, by default it will be exposed on a random port\n"
"        @ResourceArg(name = \"kraft\", value = \"true\"), // Enable Kraft mode\n"
"        @ResourceArg(name = \"num.partitions\", value = \"3\"), // Other custom broker configurations\n"
"})\n"
"public class OrderProcessorTest {\n"
"    // ...\n"
"}\n"
msgstr ""

#. type: Title ====
#: upstream/_versions/3.0/guides/kafka.adoc:2137
#, no-wrap
msgid "Custom test resource"
msgstr "カスタムテストリソース"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:2141
msgid "Alternatively, you can start a Kafka broker in a test resource.  The following snippet shows a test resource starting a Kafka broker using https://www.testcontainers.org/modules/kafka/[Testcontainers]:"
msgstr "あるいは、テストリソースで Kafka ブローカを起動することもできます。次のスニペットは、 https://www.testcontainers.org/modules/kafka/[Testcontainers] を使用して Kafka ブローカを起動するテストリソースを示しています。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2145
#, no-wrap
msgid "public class KafkaResource implements QuarkusTestResourceLifecycleManager {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2147
#, no-wrap
msgid "    private final KafkaContainer kafka = new KafkaContainer();\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2153
#, no-wrap
msgid ""
"    @Override\n"
"    public Map<String, String> start() {\n"
"        kafka.start();\n"
"        return Collections.singletonMap(\"kafka.bootstrap.servers\", kafka.getBootstrapServers());  // <1>\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2159
#, no-wrap
msgid ""
"    @Override\n"
"    public void stop() {\n"
"        kafka.close();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2161
msgid "Configure the Kafka bootstrap location, so the application connects to this broker."
msgstr "アプリケーションがこのブローカーに接続するように、Kafka ブートストラップの場所を設定します。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:2168
#, no-wrap
msgid "Kubernetes Service Bindings"
msgstr "Kubernetes サービスバインディング"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2173
msgid "Quarkus Kafka extension supports xref:deploying-to-kubernetes.adoc[Service Binding Specification for Kubernetes].  You can enable this by adding the `quarkus-kubernetes-service-binding` extension to your application."
msgstr "Quarkus Kafka エクステンションは、xref:deploying-to-kubernetes.adoc[Service Binding Specification for Kubernetes] をサポートしています。アプリケーションに `quarkus-kubernetes-service-binding` エクステンションを追加することで、これを有効にすることができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2175
msgid "When running in appropriately configured Kubernetes clusters, Kafka extension will pull its Kafka broker connection configuration from the service binding available inside the cluster, without the need for user configuration."
msgstr "適切に設定された Kubernetes クラスターで実行すると、Kafka エクステンションはユーザー設定を必要とせずに、クラスター内で利用可能なサービスバインディングから Kafka ブローカー接続設定を取得します。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:2176
#, no-wrap
msgid "Execution model"
msgstr "実行モデル"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2181
msgid "Reactive Messaging invokes user's methods on an I/O thread.  Thus, by default, the methods must not block.  As described in <<blocking-processing>>, you need to add the `@Blocking` annotation on the method if this method will block the caller thread."
msgstr "Reactive Messaging は、I/O スレッドでユーザーのメソッドを呼び出します。したがって、デフォルトではメソッドはブロックされません。<<blocking-processing>> で説明されているように、このメソッドが呼び出し元スレッドをブロックする場合は、メソッドに `@Blocking` アノテーションを追加する必要があります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2183
msgid "See the xref:quarkus-reactive-architecture.adoc[Quarkus Reactive Architecture documentation] for further details on this topic."
msgstr "このトピックの詳細については、xref:quarkus-reactive-architecture.adoc[Quarkus リアクティブアーキテクチャのドキュメント] を参照してください。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:2184
#, no-wrap
msgid "Channel Decorators"
msgstr "チャンネルデコレーター"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2187
msgid "SmallRye Reactive Messaging supports decorating incoming and outgoing channels for implementing cross-cutting concerns such as monitoring, tracing or message interception. For more information on implementing decorators and message interceptors see the http://smallrye.io/smallrye-reactive-messaging/3.19.1/concepts/decorators/[SmallRye Reactive Messaging documentation]."
msgstr "SmallRye Reactive Messagingは、監視、トレース、メッセージのインターセプトなど、横断的な関心事を実装するために、受信および送信チャネルのデコレーターをサポートしています。デコレーターやメッセージインターセプターの実装に関する詳細は、 link:http://smallrye.io/smallrye-reactive-messaging/3.19.1/concepts/decorators/[SmallRye Reactive Messaging のドキュメント] を参照してください。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:2189
#, no-wrap
msgid "Configuration Reference"
msgstr "設定リファレンス"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2192
msgid "More details about the SmallRye Reactive Messaging configuration can be found in the https://smallrye.io/smallrye-reactive-messaging/latest/kafka/kafka/#using-the-kafka-connector[SmallRye Reactive Messaging - Kafka Connector Documentation]."
msgstr "SmallRye Reactive Messaging 設定に関する詳細は、 https://smallrye.io/smallrye-reactive-messaging/smallrye-reactive-messaging/3.1/kafka/kafka.html[SmallRye Reactive Messaging - Kafka Connector Documentation] を参照してください。"

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:2196
msgid "Each channel can be disabled via configuration using:"
msgstr "各チャネルは、以下を使用した設定で無効にできます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2200
#, no-wrap
msgid "mp.messaging.[incoming|outgoing].[channel].enabled=false\n"
msgstr ""

#. type: delimited block =
#: upstream/_versions/3.0/guides/kafka.adoc:2204
msgid "The most important attributes are listed in the tables below:"
msgstr "最も重要な属性を以下の表に記載しています。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:2205
#, no-wrap
msgid "Incoming channel configuration (polling from Kafka)"
msgstr "着信チャネル設定 (Kafka からのポーリング)"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2208
#: upstream/_versions/3.0/guides/kafka.adoc:2247
msgid "The following attributes are configured using:"
msgstr "以下の属性は以下のように設定します:"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2212
#, no-wrap
msgid "mp.messaging.incoming.your-channel-name.attribute=value\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2215
#: upstream/_versions/3.0/guides/kafka.adoc:2254
msgid "Some properties have aliases which can be configured globally:"
msgstr "一部のプロパティには、グローバルに設定可能なエイリアスがあります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2219
#: upstream/_versions/3.0/guides/kafka.adoc:2258
#, no-wrap
msgid "kafka.bootstrap.servers=...\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2222
msgid "You can also pass any property supported by the underlying https://kafka.apache.org/documentation/#consumerconfigs[Kafka consumer]."
msgstr "基盤となる https://kafka.apache.org/documentation/#consumerconfigs[Kafka consumer] でサポートされる任意のプロパティーを渡すこともできます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2224
msgid "For example, to configure the `max.poll.records` property, use:"
msgstr "たとえば、 `max.poll.records` プロパティーを設定するには、次を使用します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2228
#, no-wrap
msgid "mp.messaging.incoming.[channel].max.poll.records=1000\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2231
msgid "Some consumer client properties are configured to sensible default values:"
msgstr "一部のコンシューマクライアントプロパティーは、適切なデフォルト値に設定されています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2233
#: upstream/_versions/3.0/guides/kafka.adoc:2272
msgid "If not set, `reconnect.backoff.max.ms` is set to `10000` to avoid high load on disconnection."
msgstr "設定されていない場合、切断時の高負荷を回避するために、`reconnect.backoff.max.ms` は `10000` に設定されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2235
msgid "If not set, `key.deserializer` is set to `org.apache.kafka.common.serialization.StringDeserializer`."
msgstr "設定されていない場合、`key.deserializer` は `org.apache.kafka.common.serialization.StringDeserializer` に設定されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2237
msgid "The consumer `client.id` is configured according to the number of clients to create using `mp.messaging.incoming.[channel].partitions` property."
msgstr "コンシューマーの `client.id` は、`mp.messaging.incoming.[channel].partitions` プロパティーを使用して作成するクライアントの数に応じて設定されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2239
msgid "If a `client.id` is provided, it is used as-is or suffixed with client index if `partitions` property is set."
msgstr "`client.id` が指定されている場合は、そのまま使用されるか、`partitions` プロパティーが設定されている場合はクライアントインデックスの接尾辞が付けられます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2240
msgid "If a `client.id` is not provided, it is generated as `[client-id-prefix][channel-name][-index]`."
msgstr "`client.id` が指定されていない場合、`[client-id-prefix][channel-name][-index]`. として生成されます。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:2244
#, no-wrap
msgid "Outgoing channel configuration (writing to Kafka)"
msgstr "outgoingチャンネルの設定（Kafkaへの書き込み)"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2251
#, no-wrap
msgid "mp.messaging.outgoing.your-channel-name.attribute=value\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2261
msgid "You can also pass any property supported by the underlying https://kafka.apache.org/documentation/#producerconfigs[Kafka producer]."
msgstr "基盤となる https://kafka.apache.org/documentation/#producerconfigs[Kafka producer] でサポートされている任意のプロパティーを渡すこともできます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2263
msgid "For example, to configure the `max.block.ms` property, use:"
msgstr "たとえば、`max.block.ms` プロパティーを設定するには、次を使用します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2267
#, no-wrap
msgid "mp.messaging.incoming.[channel].max.block.ms=10000\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2270
msgid "Some producer client properties are configured to sensible default values:"
msgstr "一部のプロデューサークライアントプロパティーは、適切なデフォルト値に設定されています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2274
msgid "If not set, `key.serializer` is set to `org.apache.kafka.common.serialization.StringSerializer`."
msgstr "設定されていない場合、`key.serializer` は `org.apache.kafka.common.serialization.StringSerializer` に設定されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2276
msgid "If not set, producer `client.id` is generated as `[client-id-prefix][channel-name]`."
msgstr "設定されていない場合、プロデューサー `client.id` は `[client-id-prefix][channel-name]` として生成されます。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:2280
#, no-wrap
msgid "Kafka Configuration Resolution"
msgstr "Kafka 設定の解決"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2284
msgid "Quarkus exposes all Kafka related application properties, prefixed with `kafka.` or `KAFKA_` inside a configuration map with `default-kafka-broker` name.  This configuration is used to establish the connection with the Kafka broker."
msgstr "Quarkus は、`default-kafka-broker` 名の設定マップ内に接頭辞 `kafka.` または `KAFKA_` が付いたすべての Kafka 関連アプリケーションプロパティーを公開します。この設定は、Kafka ブローカーとの接続を確立するために使用されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2286
msgid "In addition to this default configuration, you can configure the name of the `Map` producer using the `kafka-configuration` attribute:"
msgstr "このデフォルト設定に加えて、`kafka-configuration` 属性を使用して `Map` プロデューサーの名前を設定することができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2291
#, no-wrap
msgid ""
"mp.messaging.incoming.my-channel.connector=smallrye-kafka\n"
"mp.messaging.incoming.my-channel.kafka-configuration=my-configuration\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2295
msgid "In this case, the connector looks for the `Map` associated with the `my-configuration` name.  If `kafka-configuration` is not set, an optional lookup for a `Map` exposed with the channel name (`my-channel` in the previous example) is done."
msgstr "この場合、コネクターは `my-configuration` 名に関連付けられた `Map` を探します。`kafka-configuration` が設定されていない場合、チャネル名 (前の例では `my-channel`) で公開された `Map` のオプションの検索が実行されます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2306
#, no-wrap
msgid ""
"@Produces\n"
"@ApplicationScoped\n"
"@Identifier(\"my-configuration\")\n"
"Map<String, Object> outgoing() {\n"
"    return Map.ofEntries(\n"
"            Map.entry(\"value.serializer\", ObjectMapperSerializer.class.getName())\n"
"    );\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2309
msgid "If `kafka-configuration` is set and no `Map` can be found, the deployment fails."
msgstr "`kafka-configuration` が設定されていて、`Map` が見つからない場合、デプロイメントは失敗します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2311
msgid "Attribute values are resolved as follows:"
msgstr "属性値は次のように解決されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2313
msgid "the attribute is set directly on the channel configuration (`mp.messaging.incoming.my-channel.attribute=value`),"
msgstr "属性はチャネル設定に直接設定されます (`mp.messaging.incoming.my-channel.attribute=value`)。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2314
msgid "if not set, the connector looks for a `Map` with the channel name or the configured `kafka-configuration` (if set) and the value is retrieved from that `Map`"
msgstr "設定されていない場合、コネクターはチャネル名または設定された `kafka-configuration` (設定されている場合) を含む `Map` を検索し、その `Map` から値を取得します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2315
msgid "If the resolved `Map` does not contain the value the default `Map` is used (exposed with the `default-kafka-broker` name)"
msgstr "解決された `Map` に値が含まれていない場合、デフォルトの `Map` が使用されます (`default-kafka-broker` 名で公開)"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:2316
#, no-wrap
msgid "Integrating with Kafka - Common patterns"
msgstr "Kafka との統合 - 一般的なパターン"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:2318
#, no-wrap
msgid "Writing to Kafka from an HTTP endpoint"
msgstr "HTTP エンドポイントから Kafka への書き込み"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2321
msgid "To send messages to Kafka from an HTTP endpoint, inject an `Emitter` (or a `MutinyEmitter`) in your endpoint:"
msgstr "HTTP エンドポイントから Kafka にメッセージを送信するには、エンドポイントに `Emitter` (または `MutinyEmitter`) を注入します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2332
#: upstream/_versions/3.0/guides/kafka.adoc:2380
#, no-wrap
msgid ""
"import jakarta.ws.rs.POST;\n"
"import jakarta.ws.rs.Path;\n"
"import jakarta.ws.rs.Produces;\n"
"import jakarta.ws.rs.core.MediaType;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2338
#: upstream/_versions/3.0/guides/kafka.adoc:2388
#: upstream/_versions/3.0/guides/kafka.adoc:2613
#, no-wrap
msgid ""
"@Path(\"/\")\n"
"public class ResourceSendingToKafka {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2340
#, no-wrap
msgid "    @Channel(\"kafka\") Emitter<String> emitter;          // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2347
#, no-wrap
msgid ""
"    @POST\n"
"    @Produces(MediaType.TEXT_PLAIN)\n"
"    public CompletionStage<Void> send(String payload) { // <2>\n"
"        return emitter.send(payload);                   // <3>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2349
msgid "Inject an `Emitter<String>`"
msgstr "`Emitter<String>` を注入します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2350
msgid "The HTTP method receives the payload and returns a `CompletionStage` completed when the message is written to Kafka"
msgstr "HTTPメソッドはメッセージがKafkaに書き込まれると、ペイロードを受け取り、`CompletionStage` の完了を返します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2351
msgid "Send the message to Kafka, the `send` method returns a `CompletionStage`"
msgstr "メッセージをKafkaに送信し、 `send` メソッドは `CompletionStage` を返却します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2354
msgid "The endpoint sends the passed payload (from a `POST` HTTP request) to the emitter.  The emitter's channel is mapped to a Kafka topic in the `application.properties` file:"
msgstr "エンドポイントは、渡されたペイロードを (`POST` HTTP リクエストから) エミッターに送信します。エミッターのチャネルは、`application.properties` ファイルの Kafka トピックにマップされます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2359
#, no-wrap
msgid ""
"mp.messaging.outgoing.kafka.connector=smallrye-kafka\n"
"mp.messaging.outgoing.kafka.topic=my-topic\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2365
msgid "The endpoint returns a `CompletionStage` indicating the asynchronous nature of the method.  The `emitter.send` method returns a `CompletionStage<Void>` .  The returned future is completed when the message has been written to Kafka.  If the writing fails, the returned `CompletionStage` is completed exceptionally."
msgstr "エンドポイントは、メソッドの非同期性を示す `CompletionStage` を返します。`emitter.send` メソッドは `CompletionStage<Void>` を返します。メッセージが Kafka に書き込まれると、返される future は完了します。書き込みが失敗した場合、返された `CompletionStage` が例外扱いで完了します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2367
msgid "If the endpoint does not return a `CompletionStage`, the HTTP response may be written before the message is sent to Kafka, and so failures won't be reported to the user."
msgstr "エンドポイントが `CompletionStage` を返さない場合、メッセージが Kafka に送信される前に HTTP 応答が書き込まれる可能性があるため、ユーザーに失敗が報告されることはありません。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2369
msgid "If you need to send a Kafka record, use:"
msgstr "Kafka レコードを送信する必要がある場合は、次を使用します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2385
#, no-wrap
msgid "import io.smallrye.reactive.messaging.kafka.Record;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2390
#, no-wrap
msgid "    @Channel(\"kafka\") Emitter<Record<String,String>> emitter;  // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2398
#, no-wrap
msgid ""
"    @POST\n"
"    @Produces(MediaType.TEXT_PLAIN)\n"
"    public CompletionStage<Void> send(String payload) {\n"
"        return emitter.send(Record.of(\"my-key\", payload));    // <2>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2400
msgid "Note the usage of an `Emitter<Record<K, V>>`"
msgstr "`Emitter<Record<K, V>>` の使用法に注意してください"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2401
msgid "Create the record using `Record.of(k, v)`"
msgstr "`Record.of(k, v)` を使用してレコードを作成します"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:2402
#, no-wrap
msgid "Persisting Kafka messages with Hibernate with Panache"
msgstr "Hibernate with Panache での Kafka メッセージの永続化"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2405
msgid "To persist objects received from Kafka into a database, you can use Hibernate with Panache."
msgstr "Kafka から受信したオブジェクトをデータベースに永続化するには、Hibernate with Panache を使用することができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2407
msgid "If you use Hibernate Reactive, look at <<persisting-kafka-messages-with-hibernate-reactive>>."
msgstr "Hibernate Reactive を使用する場合は、<<persisting-kafka-messages-with-hibernate-reactive>> を参照してください。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2410
#: upstream/_versions/3.0/guides/kafka.adoc:2490
msgid "Let's imagine you receive `Fruit` objects.  For simplicity purposes, our `Fruit` class is pretty simple:"
msgstr "`Fruit` オブジェクトを受け取ったと想像してみましょう。簡単にするために、`Fruit` クラスは非常に単純です。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2418
#, no-wrap
msgid "import io.quarkus.hibernate.orm.panache.PanacheEntity;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2421
#: upstream/_versions/3.0/guides/kafka.adoc:2501
#, no-wrap
msgid ""
"@Entity\n"
"public class Fruit extends PanacheEntity {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2423
#: upstream/_versions/3.0/guides/kafka.adoc:2503
#, no-wrap
msgid "    public String name;\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2428
#: upstream/_versions/3.0/guides/kafka.adoc:2509
msgid "To consume `Fruit` instances stored on a Kafka topic, and persist them into a database, you can use the following approach:"
msgstr "Kafka トピックに保存されている `Fruit` インスタンスを消費し、それらをデータベースに永続化するには、次のアプローチを使用できます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2439
#, no-wrap
msgid "import io.smallrye.common.annotation.Blocking;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2442
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class FruitConsumer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2449
#, no-wrap
msgid ""
"    @Incoming(\"fruits\")                                     // <1>\n"
"    @Transactional                                          // <2>\n"
"    public void persistFruits(Fruit fruit) {                // <3>\n"
"        fruit.persist();                                    // <4>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2451
msgid "Configuring the incoming channel. This channel reads from Kafka."
msgstr "着信チャネルの設定。このチャンネルは Kafka から読み取ります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2453
msgid "As we are writing in a database, we must be in a transaction. This annotation starts a new transaction and commits it when the method returns.  Quarkus automatically considers the method as _blocking_. Indeed, writing to a database using classic Hibernate is blocking. So, Quarkus calls the method on a worker thread you can block (and not an I/O thread)."
msgstr "データベースに書き込んでいるので、トランザクション内である必要があります。このアノテーションは新しいトランザクションを開始し、メソッドが返されたときにそれをコミットします。Quarkus は、このメソッドを自動的に _blocking_ と見なします。実際、従来の Hibernate を使用したデータベースへの書き込みはブロックされています。そこで、Quarkus は、ブロックできるワーカースレッド (I/O スレッドではない) でメソッドを呼び出します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2454
msgid "The method receives each Fruit. Note that you would need a deserializer to reconstruct the Fruit instances from the Kafka records."
msgstr "メソッドは各 Fruit を受け取ります。Kafka レコードから Fruit インスタンスを再構築するには、デシリアライザーが必要になることに注意してください。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2455
msgid "Persist the received `fruit` object."
msgstr "受信した `fruit` オブジェクトを永続化します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2458
msgid "As mentioned in <4>, you need a deserializer that can create a `Fruit` from the record.  This can be done using a Jackson deserializer:"
msgstr "上記 <4> で述べたように、レコードから `Fruit` を作成できるデシリアライザーが必要です。これは、Jackson デシリアライザーを使用して実行できます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2473
#: upstream/_versions/3.0/guides/kafka.adoc:2569
msgid "The associated configuration would be:"
msgstr "関連する設定は次のようになります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2478
#: upstream/_versions/3.0/guides/kafka.adoc:2574
#, no-wrap
msgid ""
"mp.messaging.incoming.fruits.connector=smallrye-kafka\n"
"mp.messaging.incoming.fruits.value.deserializer=org.acme.FruitDeserializer\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2482
#: upstream/_versions/3.0/guides/kafka.adoc:2578
msgid "Check <<jackson-serialization>> for more detail about the usage of Jackson with Kafka.  You can also use Avro."
msgstr "Kafka を使用した Jackson の使い方の詳細については、<<jackson-serialization>> を確認してください。また、Avro を使用することもできます。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:2484
#, no-wrap
msgid "Persisting Kafka messages with Hibernate Reactive"
msgstr "Hibernate Reactive を使用した Kafka メッセージの永続化"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2487
msgid "To persist objects received from Kafka into a database, you can use Hibernate Reactive with Panache."
msgstr "Kafka から受信したオブジェクトをデータベースに永続化するには、Hibernate Reactive with Panache を使用することができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2498
#, no-wrap
msgid "import io.quarkus.hibernate.reactive.panache.PanacheEntity;  // <1>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2507
msgid "Make sure to use the reactive variant"
msgstr "必ずリアクティブバリアントを使用してください"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2516
#, no-wrap
msgid ""
"import jakarta.enterprise.context.ApplicationScoped;\n"
"import jakarta.enterprise.context.control.ActivateRequestContext;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2521
#, no-wrap
msgid ""
"import io.quarkus.hibernate.reactive.panache.Panache;\n"
"import io.smallrye.mutiny.Uni;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2524
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class FruitStore {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2527
#, no-wrap
msgid ""
"    @Inject\n"
"    Mutiny.Session session;                    // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2536
#, no-wrap
msgid ""
"    @Incoming(\"in\")\n"
"    @ActivateRequestContext // <2>\n"
"    public Uni<Void> consume(Fruit entity) {\n"
"        return session.withTransaction(t -> {  // <3>\n"
"            return entity.persistAndFlush()    // <4>\n"
"                    .replaceWithVoid();        // <5>\n"
"        }).onTermination().call(() -> session.close()); // <6>\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2540
msgid "Inject the Hibernate Reactive `Session`"
msgstr "Hibernate Reactive `Session` を注入します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2543
msgid "Hibernate Reactive `Session` and `Panache` APIs require an active CDI Request context.  `@ActivateRequestContext` annotation creates a new request context and destroys it when the `Uni` returned from the method completes.  If `Panache` is not used, `Mutiny.SessionFactory` can be injected and used similarly without the need of activating the request context or closing the session manually."
msgstr "Hibernate Reactive `Session` および `Panache` API は、アクティブな CDI リクエストコンテキストを必要とします。 `@ActivateRequestContext` アノテーションは新しいリクエストコンテキストを作成し、メソッドから返された `Uni` が完了すると、それを破棄します。 `Panache` を使用しない場合は、 `Mutiny.SessionFactory` を注入して同様に使用することができ、 リクエストコンテキストをアクティブにしたりセッションを手動で閉じたりする必要はありません。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2544
msgid "Requests a new transaction. The transaction completes when the passed action completes."
msgstr "新しいトランザクションを要求します。渡されたアクションが完了すると、トランザクションが完了します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2545
msgid "Persist the entity. It returns a `Uni<Fruit>`."
msgstr "エンティティーを永続化します。これは `Uni<Fruit>` を返します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2546
msgid "Switch back to a `Uni<Void>`."
msgstr "`Uni<Void>` に切り替えます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2547
msgid "Close the session - this is close the connection with the database. The connection can then be recycled."
msgstr "セッションを閉じる - これは、データベースとの接続を閉じることです。その後、接続を再利用することができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2551
msgid "Unlike with _classic_ Hibernate, you can't use `@Transactional`.  Instead, we use `session.withTransaction` and persist our entity.  The `map` is used to return a `Uni<Void>` and not a `Uni<Fruit>`."
msgstr "_classic_ Hibernate とは異なり、`@Transactional` は使用できません。代わりに、 `session.withTransaction` を使用して、エンティティーを永続化します。 `map` は、 `Uni<Fruit>` ではなく `Uni<Void>` を返すために使用されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2554
msgid "You need a deserializer that can create a `Fruit` from the record.  This can be done using a Jackson deserializer:"
msgstr "レコードから `Fruit` を作成できるデシリアライザーが必要です。これは、Jackson デシリアライザーを使用して実行できます。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:2579
#, no-wrap
msgid "Writing entities managed by Hibernate to Kafka"
msgstr "Hibernate が管理するエンティティーの Kafka への書き込み"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2582
msgid "Let's imagine the following process:"
msgstr "以下のプロセスを想像してみましょう。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2584
msgid "You receive an HTTP request with a payload,"
msgstr "ペイロードを含む HTTP リクエストを受信します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2585
msgid "You create an Hibernate entity instance from this payload,"
msgstr "このペイロードから Hibernate エンティティーインスタンスを作成します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2586
msgid "You persist that entity into a database,"
msgstr "そのエンティティーをデータベースに永続化します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2587
msgid "You send the entity to a Kafka topic"
msgstr "エンティティーを Kafka トピックに送信します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2589
msgid "If you use Hibernate Reactive, look at <<writing-entities-managed-by-hibernate-reactive-to-kafka>>."
msgstr "Hibernate Reactive を使用する場合は、<<writing-entities-managed-by-hibernate-reactive-to-kafka>> を参照してください。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2595
msgid "Because we write to a database, we must run this method in a transaction.  Yet, sending the entity to Kafka happens asynchronously.  The operation returns a `CompletionStage` (or a `Uni` if you use a `MutinyEmitter`) reporting when the operation completes.  We must be sure that the transaction is still running until the object is written.  Otherwise, you may access the object outside the transaction, which is not allowed."
msgstr "データベースに書き込むため、トランザクションでこのメソッドを実行する必要があります。しかし、エンティティーを Kafka に送信することは非同期で行われます。操作が完了すると、操作は `CompletionStage` (または `MutinyEmitter` を使用する場合は `Uni` ) レポートを返します。オブジェクトが書き込まれるまで、トランザクションがまだ実行されていることを確認する必要があります。そうしないと、トランザクションの外側でオブジェクトにアクセスする可能性がありますが、これは許可されていません。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2597
msgid "To implement this process, you need the following approach:"
msgstr "このプロセスを実装するには、次のアプローチが必要です。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2607
#, no-wrap
msgid ""
"import jakarta.transaction.Transactional;\n"
"import jakarta.ws.rs.POST;\n"
"import jakarta.ws.rs.Path;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2615
#, no-wrap
msgid "    @Channel(\"kafka\") Emitter<Fruit> emitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2624
#, no-wrap
msgid ""
"    @POST\n"
"    @Path(\"/fruits\")\n"
"    @Transactional                                                      // <1>\n"
"    public CompletionStage<Void> storeAndSendToKafka(Fruit fruit) {     // <2>\n"
"        fruit.persist();\n"
"        return emitter.send(fruit);                                     // <3>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2626
msgid "As we are writing to the database, make sure we run inside a transaction"
msgstr "データベースに書き込んでいるときは、トランザクション内で実行していることを確認してください"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2627
msgid "The method receives the fruit instance to persist. It returns a `CompletionStage` which is used for the transaction demarcation. The transaction is committed when the return `CompletionStage` completes. In our case, it's when the message is written to Kafka."
msgstr "メソッドは、永続化する fruit インスタンスを受け取ります。そして、トランザクション区切りに使用される `CompletionStage` を返します。トランザクションは、返された `CompletionStage` が完了するとコミットされます。この例の場合は、メッセージが Kafka に書き込まれるときになります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2628
msgid "Send the managed instance to Kafka. Make sure we wait for the message to complete before closing the transaction."
msgstr "マネージドインスタンスを Kafka に送信します。メッセージが完了するのを待ってから、トランザクションを閉じるようにします。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:2630
#, no-wrap
msgid "Writing entities managed by Hibernate Reactive to Kafka"
msgstr "Hibernate Reactive が管理するエンティティーの Kafka への書き込み"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2633
msgid "To send to Kafka entities managed by Hibernate Reactive, we recommend using:"
msgstr "Hibernate Reactive によって管理されている Kafka エンティティーに送信するには、以下を使用することをお勧めします。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2635
msgid "RESTEasy Reactive to serve HTTP requests"
msgstr "HTTP リクエストを処理する RESTEasy Reactive"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2636
msgid "A `MutinyEmitter` to send message to a channel, so it can be easily integrated with the Mutiny API exposed by Hibernate Reactive or Hibernate Reactive with Panache."
msgstr "チャネルにメッセージを送信するための `MutinyEmitter` 。これにより、Hibernate Reactive または Hibernate Reactive with Panache によって公開される Mutiny API と簡単に統合できます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2638
msgid "The following example demonstrates how to receive a payload, store it in the database using Hibernate Reactive with Panache, and send the persisted entity to Kafka:"
msgstr "次の例は、ペイロードを受信し、Hibernate Reactive with Panache を使用してデータベースに保存し、永続化されたエンティティーを Kafka に送信する方法を示しています。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2645
#, no-wrap
msgid ""
"import jakarta.ws.rs.POST;\n"
"import jakarta.ws.rs.Path;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2651
#, no-wrap
msgid ""
"import io.quarkus.hibernate.reactive.panache.Panache;\n"
"import io.smallrye.mutiny.Uni;\n"
"import io.smallrye.reactive.messaging.MutinyEmitter;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2654
#, no-wrap
msgid ""
"@Path(\"/\")\n"
"public class ReactiveGreetingResource {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2656
#, no-wrap
msgid "    @Channel(\"kafka\") MutinyEmitter<Fruit> emitter;     // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2666
#, no-wrap
msgid ""
"    @POST\n"
"    @Path(\"/fruits\")\n"
"    public Uni<Void> sendToKafka(Fruit fruit) {         // <2>\n"
"        return Panache.withTransaction(() ->            // <3>\n"
"            fruit.<Fruit>persist()\n"
"        )\n"
"            .chain(f -> emitter.send(f));               // <4>\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2668
msgid "Inject a `MutinyEmitter` which exposes a Mutiny API. It simplifies the integration with the Mutiny API exposed by Hibernate Reactive with Panache."
msgstr "Mutiny API を公開する `MutinyEmitter` を注入します。これにより、Hibernate Reactive with Panache によって公開された Mutiny API との統合が簡素化されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2669
msgid "The HTTP method receiving the payload returns a `Uni<Void>`. The HTTP response is written when the operation completes (the entity is persisted and written to Kafka)."
msgstr "ペイロードを受信する HTTP メソッドは `Uni<Void>` を返します。HTTP 応答は、操作が完了すると書き込まれます (エンティティーは永続化され、Kafka に書き込まれます)。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2670
msgid "We need to write the entity into the database in a transaction."
msgstr "トランザクションでエンティティーをデータベースに書き込む必要があります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2671
msgid "Once the persist operation completes, we send the entity to Kafka. The `send` method returns a `Uni<Void>`."
msgstr "永続化操作が完了すると、エンティティーを Kafka に送信します。`send` メソッドは `Uni<Void>` を返します。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:2673
#, no-wrap
msgid "Streaming Kafka topics as server-sent events"
msgstr "サーバー送信イベントとしての Kafka トピックのストリーミング"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2676
msgid "Streaming a Kafka topic as server-sent events (SSE) is straightforward:"
msgstr "Kafka トピックをサーバー送信イベント (SSE) としてストリーミングするのは簡単です。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2678
msgid "You inject the channel representing the Kafka topic in your HTTP endpoint"
msgstr "Kafka トピックを表すチャネルを HTTP エンドポイントに注入します"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2679
msgid "You return that channel as a `Publisher` or a `Multi` from the HTTP method"
msgstr "そのチャネルを HTTP メソッドから `Publisher` または `Multi` として返します"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2681
msgid "The following code provides an example:"
msgstr "以下のコードはその一例です。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2686
#: upstream/_versions/3.0/guides/kafka.adoc:2701
#, no-wrap
msgid ""
"@Channel(\"fruits\")\n"
"Multi<Fruit> fruits;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2692
#, no-wrap
msgid ""
"@GET\n"
"@Produces(MediaType.SERVER_SENT_EVENTS)\n"
"public Multi<Fruit> stream() {\n"
"    return fruits;\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2696
msgid "Some environment cuts the SSE connection when there is not enough activity.  The workaround consists of sending _ping_ messages (or empty objects) periodically."
msgstr "一部の環境では、十分なアクティビティーがない場合に SSE 接続が切断されます。回避策として、定期的に _ping_ メッセージ (または空のオブジェクト) を送信することが挙げられます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2704
#, no-wrap
msgid ""
"@Inject\n"
"ObjectMapper mapper;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2714
#, no-wrap
msgid ""
"@GET\n"
"@Produces(MediaType.SERVER_SENT_EVENTS)\n"
"public Multi<String> stream() {\n"
"    return Multi.createBy().merging()\n"
"            .streams(\n"
"                    fruits.map(this::toJson),\n"
"                    emitAPeriodicPing()\n"
"            );\n"
"}\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2719
#, no-wrap
msgid ""
"Multi<String> emitAPeriodicPing() {\n"
"    return Multi.createFrom().ticks().every(Duration.ofSeconds(10))\n"
"            .onItem().transform(x -> \"{}\");\n"
"}\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2727
#, no-wrap
msgid ""
"private String toJson(Fruit f) {\n"
"    try {\n"
"        return mapper.writeValueAsString(f);\n"
"    } catch (JsonProcessingException e) {\n"
"        throw new RuntimeException(e);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2731
msgid "The workaround is a bit more complex as besides sending the fruits coming from Kafka, we need to send pings periodically.  To achieve this we merge the stream coming from Kafka and a periodic stream emitting `{}` every 10 seconds."
msgstr "Kafka からの fruits を送信する以外に、定期的に ping を送信する必要があるため、回避策は少し複雑になっています。これを実現するために、Kafka からのストリームと、10 秒ごとに `{}` を放出する定期的なストリームをマージします。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:2733
#, no-wrap
msgid "Chaining Kafka Transactions with Hibernate Reactive transactions"
msgstr "Kafka トランザクションと Hibernate Reactive トランザクションとのチェーン"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2737
msgid "By chaining a Kafka transaction with a Hibernate Reactive transaction you can send records to a Kafka transaction, perform database updates and commit the Kafka transaction only if the database transaction is successful."
msgstr "Kafka トランザクションを Hibernate Reactive トランザクションとチェーンすることにより、Kafka トランザクションにレコードを送信し、データベースの更新を実行して、データベーストランザクションが成功した場合にのみ Kafka トランザクションをコミットすることができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2739
msgid "The following example demonstrates:"
msgstr "以下の例は、次のことを示しています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2741
msgid "Receive a payload by serving HTTP requests using RESTEasy Reactive,"
msgstr "RESTEasy Reactive を使用して HTTP リクエストを処理することにより、ペイロードを受信します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2742
msgid "Limit concurrency of that HTTP endpoint using Smallrye Fault Tolerance,"
msgstr "Smallrye Fault Tolerance を使用して、その HTTP エンドポイントの同時実行を制限します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2743
msgid "Start a Kafka transaction and send the payload to Kafka record,"
msgstr "Kafka トランザクションを開始し、ペイロードを Kafka レコードに送信します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2744
msgid "Store the payload in the database using Hibernate Reactive with Panache,"
msgstr "Hibernate Reactive with Panache を使用して、ペイロードをデータベースに保存します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2745
msgid "Commit the Kafka transaction only if the entity is persisted successfully."
msgstr "エンティティーが正常に永続化された場合にのみ、Kafka トランザクションをコミットします。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2754
#, no-wrap
msgid ""
"import jakarta.ws.rs.Consumes;\n"
"import jakarta.ws.rs.POST;\n"
"import jakarta.ws.rs.Path;\n"
"import jakarta.ws.rs.core.MediaType;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2758
#: upstream/_versions/3.0/guides/kafka.adoc:2808
#, no-wrap
msgid ""
"import org.eclipse.microprofile.faulttolerance.Bulkhead;\n"
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.hibernate.reactive.mutiny.Mutiny;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2762
#, no-wrap
msgid ""
"import io.quarkus.hibernate.reactive.panache.Panache;\n"
"import io.smallrye.mutiny.Uni;\n"
"import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2765
#: upstream/_versions/3.0/guides/kafka.adoc:2816
#, no-wrap
msgid ""
"@Path(\"/\")\n"
"public class FruitProducer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2767
#, no-wrap
msgid "    @Channel(\"kafka\") KafkaTransactions<Fruit> kafkaTx; // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2781
#, no-wrap
msgid ""
"    @POST\n"
"    @Path(\"/fruits\")\n"
"    @Consumes(MediaType.APPLICATION_JSON)\n"
"    @Bulkhead(1) // <2>\n"
"    public Uni<Void> post(Fruit fruit) { // <3>\n"
"        return kafkaTx.withTransaction(emitter -> { // <4>\n"
"            emitter.send(fruit); // <5>\n"
"            return Panache.withTransaction(() -> { // <6>\n"
"                return fruit.<Fruit>persist(); // <7>\n"
"            });\n"
"        }).replaceWithVoid();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2784
msgid "Inject a `KafkaTransactions` which exposes a Mutiny API. It allows the integration with the Mutiny API exposed by Hibernate Reactive with Panache."
msgstr "Mutiny API を公開する `KafkaTransactions` を注入します。これにより、Hibernate Reactive with Panache によって公開された Mutiny API との統合が可能になります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2785
msgid "Limit the concurrency of the HTTP endpoint to \"1\", preventing starting multiple transactions at a given time."
msgstr "HTTP エンドポイントの同時実行を \"1\" に制限し、特定の時間に複数のトランザクションを開始しないようにします。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2786
msgid "The HTTP method receiving the payload returns a `Uni<Void>`. The HTTP response is written when the operation completes (the entity is persisted and Kafka transaction is committed)."
msgstr "ペイロードを受信する HTTP メソッドは `Uni<Void>` を返します。HTTP 応答は、操作が完了すると書き込まれます (エンティティーは永続化され、Kafka トランザクションはコミットされます)。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2787
#: upstream/_versions/3.0/guides/kafka.adoc:2840
msgid "Begin a Kafka transaction."
msgstr "Kafka トランザクションを開始します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2788
msgid "Send the payload to Kafka inside the Kafka transaction."
msgstr "Kafka トランザクション内でペイロードを Kafka に送信します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2789
msgid "Persist the entity into the database in a Hibernate Reactive transaction."
msgstr "Hibernate Reactive トランザクションでエンティティーをデータベースに永続化します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2791
msgid "Once the persist operation completes, and there is no errors, the Kafka transaction is committed.  The result is omitted and returned as the HTTP response."
msgstr "永続化操作が完了し、エラーが発生しない場合は、Kafka トランザクションがコミットされます。結果は省略され、HTTP 応答として返されます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2794
msgid "In the previous example the database transaction (inner) will commit followed by the Kafka transaction (outer).  If you wish to commit the Kafka transaction first and the database transaction second, you need to nest them in the reverse order."
msgstr "前の例では、データベーストランザクション (内部) がコミットされ、続いて Kafka トランザクション (外部) がコミットされます。最初に Kafka トランザクションをコミットし、次にデータベーストランザクションをコミットしたい場合は、それらを逆の順序でネストする必要があります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2796
msgid "The next example demonstrates that using the Hibernate Reactive API (without Panache):"
msgstr "以下は、Hibernate Reactive API (Panache なし) を使用する場合の例になります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2804
#, no-wrap
msgid ""
"import jakarta.inject.Inject;\n"
"import jakarta.ws.rs.Consumes;\n"
"import jakarta.ws.rs.POST;\n"
"import jakarta.ws.rs.Path;\n"
"import jakarta.ws.rs.core.MediaType;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2813
#, no-wrap
msgid ""
"import io.smallrye.mutiny.Uni;\n"
"import io.smallrye.reactive.messaging.kafka.transactions.KafkaTransactions;\n"
"import io.vertx.mutiny.core.Context;\n"
"import io.vertx.mutiny.core.Vertx;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2818
#, no-wrap
msgid "    @Channel(\"kafka\") KafkaTransactions<Fruit> kafkaTx;\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2820
#, no-wrap
msgid "    @Inject Mutiny.SessionFactory sf; // <1>\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2834
#, no-wrap
msgid ""
"    @POST\n"
"    @Path(\"/fruits\")\n"
"    @Consumes(MediaType.APPLICATION_JSON)\n"
"    @Bulkhead(1)\n"
"    public Uni<Void> post(Fruit fruit) {\n"
"        Context context = Vertx.currentContext(); // <2>\n"
"        return sf.withTransaction(session -> // <3>\n"
"                kafkaTx.withTransaction(emitter -> // <4>\n"
"                        session.persist(fruit).invoke(() -> emitter.send(fruit)) // <5>\n"
"                ).emitOn(context::runOnContext) // <6>\n"
"        );\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2837
msgid "Inject the Hibernate Reactive `SessionFactory`."
msgstr "Hibernate Reactive `SessionFactory` を注入します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2838
msgid "Capture the caller Vert.x context."
msgstr "呼び出し元の Vert.x コンテキストをキャプチャーします。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2839
msgid "Begin a Hibernate Reactive transaction."
msgstr "Hibernate Reactive トランザクションを開始します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2841
msgid "Persist the payload and send the entity to Kafka."
msgstr "ペイロードを永続化し、エンティティーを Kafka に送信します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2843
msgid "The Kafka transaction terminates on the Kafka producer sender thread.  We need to switch to the Vert.x context previously captured in order to terminate the Hibernate Reactive transaction on the same context we started it."
msgstr "Kafka トランザクションは、Kafka プロデューサー送信者スレッドで終了します。開始したのと同じコンテキストで Hibernate Reactive トランザクションを終了するために、以前にキャプチャーした Vert.x コンテキストに切り替える必要があります。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:2844
#, no-wrap
msgid "Logging"
msgstr "ロギング"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2847
msgid "To reduce the amount of log written by the Kafka client, Quarkus sets the level of the following log categories to `WARNING`:"
msgstr "Kafkaクライアントによって書き込まれるログの量を減らすために、Quarkusは以下のログカテゴリーのレベルを `WARNING` に設定しています。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2849
msgid "`org.apache.kafka.clients`"
msgstr "`org.apache.kafka.clients`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2850
msgid "`org.apache.kafka.common.utils`"
msgstr "`org.apache.kafka.common.utils`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2851
msgid "`org.apache.kafka.common.metrics`"
msgstr "`org.apache.kafka.common.metrics`"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2853
msgid "You can override the configuration by adding the following lines to the `application.properties`:"
msgstr "以下の行を `application.properties` に追加することで、設定を上書きすることができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2859
#, no-wrap
msgid ""
"quarkus.log.category.\"org.apache.kafka.clients\".level=INFO\n"
"quarkus.log.category.\"org.apache.kafka.common.utils\".level=INFO\n"
"quarkus.log.category.\"org.apache.kafka.common.metrics\".level=INFO\n"
msgstr ""

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:2861
#, no-wrap
msgid "Connecting to Managed Kafka clusters"
msgstr "マネージド Kafka クラスターへの接続"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2864
msgid "This section explains how to connect to notorious Kafka Cloud Services."
msgstr "このセクションでは、ちょっとクセのある Kafka Cloud Services に接続する方法について説明します。"

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:2865
#, no-wrap
msgid "Azure Event Hub"
msgstr "Azure Event Hub"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2868
msgid "https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-for-kafka-ecosystem-overview[Azure Event Hub] provides an endpoint compatible with Apache Kafka."
msgstr "https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-for-kafka-ecosystem-overview[Azure Event Hub] は、Apache Kafka と互換性のあるエンドポイントを提供します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2872
msgid "Azure Event Hubs for Kafka is not available in the _basic_ tier.  You need at least the _standard_ tier to use Kafka.  See https://azure.microsoft.com/en-us/pricing/details/event-hubs/[Azure Event Hubs Pricing] to see the other options."
msgstr "Azure Event Hubs for Kafka は、_basic_ 層では使用できません。Kafka を使用するには、少なくとも _standard_ 層が必要です。他のオプションについては、 https://azure.microsoft.com/en-us/pricing/details/event-hubs/[Azure Event Hubs Pricing] を参照してください。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2874
msgid "To connect to Azure Event Hub, using the Kafka protocol with TLS, you need the following configuration:"
msgstr "TLS で Kafka プロトコルを使用して Azure Event Hub に接続するには、以下の設定が必要です。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2883
#, no-wrap
msgid ""
"kafka.bootstrap.servers=my-event-hub.servicebus.windows.net:9093 # <1>\n"
"kafka.security.protocol=SASL_SSL\n"
"kafka.sasl.mechanism=PLAIN\n"
"kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \\ # <2>\n"
"    username=\"$ConnectionString\" \\ # <3>\n"
"    password=\"<YOUR.EVENTHUBS.CONNECTION.STRING>\"; # <4>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2885
msgid "The port is `9093`."
msgstr "ポートは `9093` です。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2886
msgid "You need to use the JAAS `PlainLoginModule`."
msgstr "JAAS の `PlainLoginModule` を使用する必要があります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2887
msgid "The username is the `$ConnectionString` string."
msgstr "ユーザー名は `$ConnectionString` 文字列になります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2888
msgid "The Event Hub connection string given by Azure."
msgstr "Azure が提供する Event Hub 接続文字列。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2892
msgid "Replace `<YOUR.EVENTHUBS.CONNECTION.STRING>` with the connection string for your Event Hubs namespace.  For instructions on getting the connection string, see https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-get-connection-string[Get an Event Hubs connection string].  The result would be something like:"
msgstr "`<YOUR.EVENTHUBS.CONNECTION.STRING>` を Event Hubs 名前空間の接続文字列に置き換えます。接続文字列を取得する手順については、 https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-get-connection-string[Get an Event Hubs connection string] を参照してください。結果は、以下のようになります。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2898
#, no-wrap
msgid ""
"kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \\\n"
"    username=\"$ConnectionString\" \\\n"
"    password=\"Endpoint=sb://my-event-hub.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=XXXXXXXXXXXXXXXX\";\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2901
msgid "This configuration can be global (as above), or set in the channel configuration:"
msgstr "この設定は、(上記のように) グローバルにすることも、チャネル設定で設定することもできます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2910
#, no-wrap
msgid ""
"mp.messaging.incoming.$channel.bootstrap.servers=my-event-hub.servicebus.windows.net:9093\n"
"mp.messaging.incoming.$channel.security.protocol=SASL_SSL\n"
"mp.messaging.incoming.$channel.sasl.mechanism=PLAIN\n"
"mp.messaging.incoming.$channel.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \\\n"
"    username=\"$ConnectionString\" \\\n"
"    password=\"Endpoint=sb://my-event-hub.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=...\";\n"
msgstr ""

#. type: Title ===
#: upstream/_versions/3.0/guides/kafka.adoc:2912
#, no-wrap
msgid "Red Hat OpenShift Streams for Apache Kafka"
msgstr "Red Hat OpenShift Streams for Apache Kafka"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2917
msgid "https://cloud.redhat.com/[Red Hat OpenShift Streams for Apache Kafka] provides managed Kafka brokers.  First, follow the instructions from https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3[Getting started with the `rhoas` CLI for Red Hat OpenShift Streams for Apache Kafka] to create your Kafka broker instance.  Make sure you copied the client id and client secret associated with the _ServiceAccount_ you created."
msgstr "https://cloud.redhat.com/[Red Hat OpenShift Streams for Apache Kafka] は、マネージド Kafka ブローカーを提供します。まず、 https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3[Getting started with the `rhoas` CLI for Red Hat OpenShift Streams for Apache Kafka] の指示に従い、Kafka ブローカーインスタンスを作成します。作成した _ServiceAccount_ に関連付けられているクライアント ID とクライアントシークレットをコピーしたことを確認してください。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2919
msgid "Then, you can configure the Quarkus application to connect to the broker as follows:"
msgstr "続いて、以下のようにブローカーに接続するように Quarkus アプリケーションを設定できます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2928
#, no-wrap
msgid ""
"kafka.bootstrap.servers=<connection url> # <1>\n"
"kafka.security.protocol=SASL_SSL\n"
"kafka.sasl.mechanism=PLAIN\n"
"kafka.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \\\n"
"  username=\"${KAFKA_USERNAME}\" \\ # <2>\n"
"  password=\"${KAFKA_PASSWORD}\"; # <3>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2930
msgid "The connection string, given on the admin console, such as `demo-c--bjsv-ldd-cvavkc-a.bf2.kafka.rhcloud.com:443`"
msgstr "管理コンソールに指定されている接続文字列 (例: `demo-c--bjsv-ldd-cvavkc-a.bf2.kafka.rhcloud.com:443`)"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2931
msgid "The kafka username (the client id from the service account)"
msgstr "kafka ユーザー名 (サービスアカウントのクライアント ID)"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2932
msgid "the kafka password (the client secret from the service account)"
msgstr "kafka パスワード (サービスアカウントからのクライアントシークレット)"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2934
msgid "In general, these properties are prefixed using `%prod` to enable them only when running in production mode."
msgstr "一般に、これらのプロパティーには `%prod` という接頭辞を付け、本番モードで動作しているときのみ有効化します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2937
msgid "As explained in https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3[Getting started with the rhoas CLI for Red Hat OpenShift Streams for Apache Kafka], to use Red Hat OpenShift Streams for Apache Kafka, you must create the topic beforehand, create a _Service Account_, and provide permissions to read and write to your topic from that service account.  The authentication data (client id and secret) relates to the service account, which means you can implement fine-grain permissions and restrict access to the topic."
msgstr "https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3[Getting started with the rhoas CLI for Red Hat OpenShift Streams for Apache Kafka] で説明されているように、Red Hat OpenShift Streams for Apache Kafka を使用するには、事前にトピックを作成し、_Service Account_ を作成し、そのサービスアカウントからトピックの読み取りと書き込みを行うためのパーミッションを提供する必要があります。認証データ (クライアント ID とシークレット) はサービスアカウントに関連しています。つまり、詳細なアクセスパーミッションを実装し、トピックへのアクセスを制限できます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2939
msgid "When using Kubernetes, it is recommended to set the client id and secret in a Kubernetes secret:"
msgstr "Kubernetes を使用する場合は、クライアント ID とシークレットを Kubernetes シークレットに設定することをお勧めします。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2949
#, no-wrap
msgid ""
"apiVersion: v1\n"
"kind: Secret\n"
"metadata:\n"
"  name: kafka-credentials\n"
"stringData:\n"
"  KAFKA_USERNAME: \"...\"\n"
"  KAFKA_PASSWORD: \"...\"\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2952
msgid "To allow your Quarkus application to use that secret, add the following line to the `application.properties` file:"
msgstr "Quarkus アプリケーションがそのシークレットを使用できるようにするには、`application.properties` ファイルに以下の行を追加します。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2956
#, no-wrap
msgid "%prod.quarkus.openshift.env.secrets=kafka-credentials\n"
msgstr ""

#. type: Title ====
#: upstream/_versions/3.0/guides/kafka.adoc:2958
#, no-wrap
msgid "Red Hat OpenShift Service Registry"
msgstr "Red Hat OpenShift Service Registry"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2962
msgid "https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-service-registry[Red Hat OpenShift Service Registry] provides fully managed service registry for handling Kafka schemas."
msgstr "https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-service-registry[Red Hat OpenShift Service Registry] は、Kafka スキーマを処理するためのフルマネージドサービスレジストリーを提供します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2966
msgid "You can follow the instructions from https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/ab1894d1-cae0-4d11-b185-81d62b4aabc7#_60472331-fa00-48ec-a621-bbd039500c7d[Getting started with Red Hat OpenShift Service Registry], or use the `rhoas` CLI to create a new service registry instance:"
msgstr "https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/ab1894d1-cae0-4d11-b185-81d62b4aabc7#_60472331-fa00-48ec-a621-bbd039500c7d[Getting started with Red Hat OpenShift Service Registry] の説明に従って、または `rhoas` CLI を使用して、新しいサービスレジストリーのインスタンスを作成することができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2970
#, no-wrap
msgid "rhoas service-registry create --name my-schema-registry\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2975
msgid "Make sure to note the _Registry URL_ of the instance created.  For authentication, you can use the same _ServiceAccount_ you created previously.  You need to make sure that it has the necessary permissions to access the service registry."
msgstr "作成されたインスタンスの _Registry URL_ を書き留めてください。認証には、以前に作成したものと同じ _ServiceAccount_ を使用できます。サービスレジストリーにアクセスするために必要なパーミッションがあることを確認する必要があります。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2977
msgid "For example, using the `rhoas` CLI, you can grant the `MANAGER` role to the service account:"
msgstr "たとえば、`rhoas` CLI を使用して、サービスアカウントに `MANAGER` ロールを付与することができます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2981
#, no-wrap
msgid "rhoas service-registry role add --role manager --service-account [SERVICE_ACCOUNT_CLIENT_ID]\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2984
msgid "Then, you can configure the Quarkus application to connect to the schema registry as follows:"
msgstr "続いて、以下のようにスキーマレジストリーに接続するように Quarkus アプリケーションを設定できます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:2991
#, no-wrap
msgid ""
"mp.messaging.connector.smallrye-kafka.apicurio.registry.url=${RHOAS_SERVICE_REGISTRY_URL} <1>\n"
"mp.messaging.connector.smallrye-kafka.apicurio.auth.service.token.endpoint=${RHOAS_OAUTH_TOKEN_ENDPOINT} <2>\n"
"mp.messaging.connector.smallrye-kafka.apicurio.auth.client.id=${RHOAS_CLIENT_ID} <3>\n"
"mp.messaging.connector.smallrye-kafka.apicurio.auth.client.secret=${RHOAS_CLIENT_ID} <4>\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2993
msgid "The service registry URL, given on the admin console, such as `https://bu98.serviceregistry.rhcloud.com/t/0e95af2c-6e11-475e-82ee-f13bd782df24/apis/registry/v2`"
msgstr "管理コンソールで指定されているサービスレジストリーの URL (例: `https://bu98.serviceregistry.rhcloud.com/t/0e95af2c-6e11-475e-82ee-f13bd782df24/apis/registry/v2`)"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2994
msgid "The OAuth token endpoint URL, such as `https://identity.api.openshift.com/auth/realms/rhoas/protocol/openid-connect/token`"
msgstr "OAuth トークンエンドポイント URL (例: `https://identity.api.openshift.com/auth/realms/rhoas/protocol/openid-connect/token`)"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2995
msgid "The client id (from the service account)"
msgstr "クライアント ID (サービスアカウントから)"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:2996
msgid "The client secret (from the service account)"
msgstr "クライアントシークレット (サービスアカウントから)"

#. type: Title ====
#: upstream/_versions/3.0/guides/kafka.adoc:2997
#, no-wrap
msgid "Binding Red Hat OpenShift managed services to Quarkus application using the Service Binding Operator"
msgstr "Service Binding Operator を使用した Red Hat OpenShift マネージドサービスの Quarkus アプリケーションへのバインド"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:3001
msgid "If your Quarkus application is deployed on a Kubernetes or OpenShift cluster with link:https://github.com/redhat-developer/service-binding-operator[Service Binding Operator] and link:https://github.com/redhat-developer/app-services-operator/tree/main/docs[OpenShift Application Services] operators installed, configurations necessary to access Red Hat OpenShift Streams for Apache Kafka and Service Registry can be injected to the application using xref:deploying-to-kubernetes.adoc#service_binding[Kubernetes Service Binding]."
msgstr "Quarkus アプリケーションが、link:https://github.com/redhat-developer/service-binding-operator[Service Binding Operator] および link:https://github.com/redhat-developer/app-services-operator/tree/main/docs[OpenShift Application Services] オペレーターをインストールした Kubernetes または OpenShift クラスターにデプロイされている場合、Red Hat OpenShift Streams for Apache Kafka と Service Registry へのアクセスに必要な設定は、xref:deploying-to-kubernetes.adoc#service_binding[Kubernetes Service Binding] を使用してアプリケーションに注入することができます。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:3004
msgid "In order to set up the Service Binding, you need first to connect OpenShift managed services to your cluster.  For an OpenShift cluster you can follow the instructions from link:https://github.com/redhat-developer/app-services-guides/tree/main/docs/registry/service-binding-registry#connecting-a-kafka-and-service-registry-instance-to-your-openshift-cluster[Connecting a Kafka and Service Registry instance to your OpenShift cluster]."
msgstr "Service Binding をセットアップするには、最初に OpenShift マネージドサービスをクラスターに接続する必要があります。OpenShift クラスターの場合は、link:https://github.com/redhat-developer/app-services-guides/tree/main/docs/registry/service-binding-registry#connecting-a-kafka-and-service-registry-instance-to-your-openshift-cluster[Connecting a Kafka and Service Registry instance to your OpenShift cluster] の指示に従います。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:3006
msgid "Once you've connected your cluster with the RHOAS Kafka and Service Registry instances, make sure you've granted necessary permissions to the newly created service account."
msgstr "クラスタとRHOAS KafkaおよびService Registryインスタンスを接続したら、新しく作成したサービスアカウントに必要なパーミッションが付与されていることを確認してください。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:3009
msgid "Then, using the xref:deploying-to-kubernetes.adoc#service_binding[Kubernetes Service Binding] extension, you can configure the Quarkus application to generate `ServiceBinding` resources for those services:"
msgstr "次に、xref:deploying-to-kubernetes.adoc#service_binding[Kubernetes Service Binding] 拡張を使用して、これらのサービス用の `ServiceBinding` リソースを生成するように Quarkus アプリケーションを構成できます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:3013
#, no-wrap
msgid "quarkus.kubernetes-service-binding.detect-binding-resources=true\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:3017
#, no-wrap
msgid ""
"quarkus.kubernetes-service-binding.services.kafka.api-version=rhoas.redhat.com/v1alpha1\n"
"quarkus.kubernetes-service-binding.services.kafka.kind=KafkaConnection\n"
"quarkus.kubernetes-service-binding.services.kafka.name=my-kafka\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:3021
#, no-wrap
msgid ""
"quarkus.kubernetes-service-binding.services.serviceregistry.api-version=rhoas.redhat.com/v1alpha1\n"
"quarkus.kubernetes-service-binding.services.serviceregistry.kind=ServiceRegistryConnection\n"
"quarkus.kubernetes-service-binding.services.serviceregistry.name=my-schema-registry\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:3024
msgid "For this example Quarkus build will generate the following `ServiceBinding` resources:"
msgstr "この例では、Quarkus のビルドにより、次の `ServiceBinding` リソースが生成されます。"

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:3044
#, no-wrap
msgid ""
"apiVersion: binding.operators.coreos.com/v1alpha1\n"
"kind: ServiceBinding\n"
"metadata:\n"
"  name: my-app-kafka\n"
"spec:\n"
"  application:\n"
"    group: apps.openshift.io\n"
"    name: my-app\n"
"    version: v1\n"
"    kind: DeploymentConfig\n"
"  services:\n"
"    - group: rhoas.redhat.com\n"
"      version: v1alpha1\n"
"      kind: KafkaConnection\n"
"      name: my-kafka\n"
"  detectBindingResources: true\n"
"  bindAsFiles: true\n"
"---\n"
msgstr ""

#. type: delimited block -
#: upstream/_versions/3.0/guides/kafka.adoc:3062
#, no-wrap
msgid ""
"apiVersion: binding.operators.coreos.com/v1alpha1\n"
"kind: ServiceBinding\n"
"metadata:\n"
"  name: my-app-serviceregistry\n"
"spec:\n"
"  application:\n"
"    group: apps.openshift.io\n"
"    name: my-app\n"
"    version: v1\n"
"    kind: DeploymentConfig\n"
"  services:\n"
"    - group: rhoas.redhat.com\n"
"      version: v1alpha1\n"
"      kind: ServiceRegistryConnection\n"
"      name: my-schema-registry\n"
"  detectBindingResources: true\n"
"  bindAsFiles: true\n"
msgstr ""

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:3066
msgid "You can follow xref:deploying-to-kubernetes.adoc#openshift[Deploying to OpenShift] to deploy your application, including generated `ServiceBinding` resources.  The configuration properties necessary to access the Kafka and Schema Registry instances will be injected to the application automatically at deployment."
msgstr "xref:deploying-to-kubernetes.adoc#openshift[Deploying to OpenShift]に従って、生成した `ServiceBinding` リソースを含むアプリケーションをデプロイすることが可能です。  KafkaとSchema Registryのインスタンスにアクセスするために必要な設定プロパティは、デプロイ時に自動的にアプリケーションに注入されます。"

#. type: Title ==
#: upstream/_versions/3.0/guides/kafka.adoc:3067
#, no-wrap
msgid "Going further"
msgstr "さらに詳しく"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:3071
msgid "This guide has shown how you can interact with Kafka using Quarkus.  It utilizes SmallRye Reactive Messaging to build data streaming applications."
msgstr "このガイドでは、Quarkusを使用してKafkaとやり取りする方法について説明しました。  SmallRye Reactive Messagingを利用して、データストリーミングアプリケーションを構築します。"

#. type: Plain text
#: upstream/_versions/3.0/guides/kafka.adoc:3072
msgid "If you want to go further, check the documentation of https://smallrye.io/smallrye-reactive-messaging[SmallRye Reactive Messaging], the implementation used in Quarkus."
msgstr "さらに詳しく知りたい場合は、Quarkusで使用されている実装、 https://smallrye.io/smallrye-reactive-messaging[SmallRye Reactive Messaging] のドキュメントを確認してください。"
